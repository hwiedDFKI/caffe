<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.15"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>caffe: solver</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
  $(document).ready(initResizable);
/* @license-end */</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">caffe
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.15 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('md_docs_tutorial_solver.html','');});
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="PageDoc"><div class="header">
  <div class="headertitle">
<div class="title">solver </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><hr/>
 <h2>title: Solver / Model Optimization </h2>
<h1>Solver</h1>
<p class="">The solver orchestrates model optimization by coordinating the network's forward inference and backward gradients to form parameter updates that attempt to improve the loss. The responsibilities of learning are divided between the Solver for overseeing the optimization and generating parameter updates and the Net for yielding loss and gradients.</p>
<p class="">The Caffe solvers are:</p>
<ul>
<li>Stochastic Gradient Descent (<code>type: "SGD"</code>),</li>
<li>AdaDelta (<code>type: "AdaDelta"</code>),</li>
<li>Adaptive Gradient (<code>type: "AdaGrad"</code>),</li>
<li>Adam (<code>type: "Adam"</code>),</li>
<li>Nesterov's Accelerated Gradient (<code>type: "Nesterov"</code>) and</li>
<li>RMSprop (<code>type: "RMSProp"</code>)</li>
</ul>
<p class="">The solver</p>
<ol type="1">
<li>scaffolds the optimization bookkeeping and creates the training network for learning and test network(s) for evaluation.</li>
<li>iteratively optimizes by calling forward / backward and updating parameters</li>
<li>(periodically) evaluates the test networks</li>
<li>snapshots the model and solver state throughout the optimization</li>
</ol>
<p class="">where each iteration</p>
<ol type="1">
<li>calls network forward to compute the output and loss</li>
<li>calls network backward to compute the gradients</li>
<li>incorporates the gradients into parameter updates according to the solver method</li>
<li>updates the solver state according to learning rate, history, and method</li>
</ol>
<p class="">to take the weights all the way from initialization to learned model.</p>
<p class="">Like Caffe models, Caffe solvers run in CPU / GPU modes.</p>
<h2>Methods</h2>
<p class="">The solver methods address the general optimization problem of loss minimization. For dataset $$D$$, the optimization objective is the average loss over all $$|D|$$ data instances throughout the dataset</p>
<p class="">$$L(W) = {1}{|D|} ^{|D|} f_W(X^{(i)}) +  r(W)$$</p>
<p class="">where $$f_W(X^{(i)})$$ is the loss on data instance $$X^{(i)}$$ and $$r(W)$$ is a regularization term with weight $$$$. $$|D|$$ can be very large, so in practice, in each solver iteration we use a stochastic approximation of this objective, drawing a mini-batch of $$N &lt;&lt; |D|$$ instances:</p>
<p class="">$$L(W)  {1}{N} ^N f_W(X^{(i)}) +  r(W)$$</p>
<p class="">The model computes $$f_W$$ in the forward pass and the gradient $$ f_W$$ in the backward pass.</p>
<p class="">The parameter update $$ W$$ is formed by the solver from the error gradient $$ f_W$$, the regularization gradient $$ r(W)$$, and other particulars to each method.</p>
<h3>SGD</h3>
<p class=""><b>Stochastic gradient descent</b> (<code>type: "SGD"</code>) updates the weights $$ W $$ by a linear combination of the negative gradient $$  L(W) $$ and the previous weight update $$ V_t $$. The <b>learning rate</b> $$  $$ is the weight of the negative gradient. The <b>momentum</b> $$  $$ is the weight of the previous update.</p>
<p class="">Formally, we have the following formulas to compute the update value $$ V_{t+1} $$ and the updated weights $$ W_{t+1} $$ at iteration $$ t+1 $$, given the previous weight update $$ V_t $$ and current weights $$ W_t $$:</p>
<p class="">$$ V_{t+1} =  V_t -   L(W_t) $$</p>
<p class="">$$ W_{t+1} = W_t + V_{t+1} $$</p>
<p class="">The learning "hyperparameters" ($$$$ and $$$$) might require a bit of tuning for best results. If you're not sure where to start, take a look at the "Rules of thumb" below, and for further information you might refer to Leon Bottou's <a href="http://research.microsoft.com/pubs/192769/tricks-2012.pdf">Stochastic Gradient Descent Tricks</a> [1].</p>
<p class="">[1] L. Bottou. <a href="http://research.microsoft.com/pubs/192769/tricks-2012.pdf">Stochastic Gradient Descent Tricks</a>. <em>Neural Networks: Tricks of the Trade</em>: Springer, 2012.</p>
<h4>Rules of thumb for setting the learning rate $$  $$ and momentum $$  $$</h4>
<p class="">A good strategy for deep learning with SGD is to initialize the learning rate $$  $$ to a value around $$   0.01 = 10^{-2} $$, and dropping it by a constant factor (e.g., 10) throughout training when the loss begins to reach an apparent "plateau", repeating this several times. Generally, you probably want to use a momentum $$  = 0.9 $$ or similar value. By smoothing the weight updates across iterations, momentum tends to make deep learning with SGD both stabler and faster.</p>
<p class="">This was the strategy used by Krizhevsky et al. [1] in their famously winning CNN entry to the ILSVRC-2012 competition, and Caffe makes this strategy easy to implement in a <code>SolverParameter</code>, as in our reproduction of [1] at <code>./examples/imagenet/alexnet_solver.prototxt</code>.</p>
<p class="">To use a learning rate policy like this, you can put the following lines somewhere in your solver prototxt file: </p><pre class="fragment">base_lr: 0.01     # begin training at a learning rate of 0.01 = 1e-2

lr_policy: "step" # learning rate policy: drop the learning rate in "steps"
                  # by a factor of gamma every stepsize iterations

gamma: 0.1        # drop the learning rate by a factor of 10
                  # (i.e., multiply it by a factor of gamma = 0.1)

stepsize: 100000  # drop the learning rate every 100K iterations

max_iter: 350000  # train for 350K iterations total

momentum: 0.9
</pre><p class="">Under the above settings, we'll always use <code>momentum</code> $$  = 0.9 $$. We'll begin training at a <code>base_lr</code> of $$  = 0.01 = 10^{-2} $$ for the first 100,000 iterations, then multiply the learning rate by <code>gamma</code> ($$  $$) and train at $$ ' =   = (0.01) (0.1) = 0.001 = 10^{-3} $$ for iterations 100K-200K, then at $$ '' = 10^{-4} $$ for iterations 200K-300K, and finally train until iteration 350K (since we have <code>max_iter: 350000</code>) at $$ ''' = 10^{-5} $$.</p>
<p class="">Note that the momentum setting $$  $$ effectively multiplies the size of your updates by a factor of $$ {1}{1 - } $$ after many iterations of training, so if you increase $$  $$, it may be a good idea to <b>decrease</b> $$  $$ accordingly (and vice versa).</p>
<p class="">For example, with $$  = 0.9 $$, we have an effective update size multiplier of $$ {1}{1 - 0.9} = 10 $$. If we increased the momentum to $$  = 0.99 $$, we've increased our update size multiplier to 100, so we should drop $$  $$ (<code>base_lr</code>) by a factor of 10.</p>
<p class="">Note also that the above settings are merely guidelines, and they're definitely not guaranteed to be optimal (or even work at all!) in every situation. If learning diverges (e.g., you start to see very large or <code>NaN</code> or <code>inf</code> loss values or outputs), try dropping the <code>base_lr</code> (e.g., <code>base_lr: 0.001</code>) and re-training, repeating this until you find a <code>base_lr</code> value that works.</p>
<p class="">[1] A. Krizhevsky, I. Sutskever, and G. Hinton. <a href="http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf">ImageNet Classification with Deep Convolutional Neural Networks</a>. <em>Advances in Neural Information Processing Systems</em>, 2012.</p>
<h3>AdaDelta</h3>
<p class="">The <b>AdaDelta</b> (<code>type: "AdaDelta"</code>) method (M. Zeiler [1]) is a "robust learning rate method". It is a gradient-based optimization method (like SGD). The update formulas are</p>
<p class="">$$ {align} (v_t)_i &amp;= {{RMS}((v_{t-1})_i)}{{RMS}(  L(W_t) )_{i}} (  L(W_{t'}) )_i \ {RMS}(  L(W_t) )_{i} &amp;= {E[g^2] + } \ E[g^2]_t &amp;= {E[g^2]_{t-1} } + (1-)g_{t}^2 {align} $$</p>
<p class="">and</p>
<p class="">$$ (W_{t+1})_i = (W_t)_i -  (v_t)_i. $$</p>
<p class="">[1] M. Zeiler <a href="http://arxiv.org/pdf/1212.5701.pdf">ADADELTA: AN ADAPTIVE LEARNING RATE METHOD</a>. <em>arXiv preprint</em>, 2012.</p>
<h3>AdaGrad</h3>
<p class="">The <b>adaptive gradient</b> (<code>type: "AdaGrad"</code>) method (Duchi et al. [1]) is a gradient-based optimization method (like SGD) that attempts to "find needles in haystacks in the form of very predictive but rarely seen features," in Duchi et al.'s words. Given the update information from all previous iterations $$ (  L(W) )_{t'} $$ for $$ t'  1, 2, ..., t </p>
</div></div><!-- PageDoc -->
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.15 </li>
  </ul>
</div>
</body>
</html>
