<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.15"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>caffe: caffe::Layer&lt; Dtype &gt; Class Template Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
  $(document).ready(initResizable);
/* @license-end */</script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">caffe
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.15 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('classcaffe_1_1_layer.html','');});
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pro-methods">Protected Member Functions</a> &#124;
<a href="#pro-attribs">Protected Attributes</a> &#124;
<a href="classcaffe_1_1_layer-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">caffe::Layer&lt; Dtype &gt; Class Template Reference<span class="mlabels"><span class="mlabel">abstract</span></span></div>  </div>
</div><!--header-->
<div class="contents">

<p>An interface for the units of computation which can be composed into a <a class="el" href="classcaffe_1_1_net.html" title="Connects Layers together into a directed acyclic graph (DAG) specified by a NetParameter. ">Net</a>.  
 <a href="classcaffe_1_1_layer.html#details">More...</a></p>

<p><code>#include &lt;<a class="el" href="build_2install_2include_2caffe_2layer_8hpp_source.html">layer.hpp</a>&gt;</code></p>

<p>Inherited by <a class="el" href="classcaffe_1_1_accuracy_layer.html">caffe::AccuracyLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_accuracy_layer.html">caffe::AccuracyLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_arg_max_layer.html">caffe::ArgMaxLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_arg_max_layer.html">caffe::ArgMaxLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_base_convolution_layer.html">caffe::BaseConvolutionLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_base_convolution_layer.html">caffe::BaseConvolutionLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_base_data_layer.html">caffe::BaseDataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_base_data_layer.html">caffe::BaseDataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_batch_norm_layer.html">caffe::BatchNormLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_batch_norm_layer.html">caffe::BatchNormLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_batch_reindex_layer.html">caffe::BatchReindexLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_batch_reindex_layer.html">caffe::BatchReindexLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_bias_layer.html">caffe::BiasLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_bias_layer.html">caffe::BiasLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_concat_layer.html">caffe::ConcatLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_concat_layer.html">caffe::ConcatLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_crop_layer.html">caffe::CropLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_crop_layer.html">caffe::CropLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_dummy_data_layer.html">caffe::DummyDataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_dummy_data_layer.html">caffe::DummyDataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_eltwise_layer.html">caffe::EltwiseLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_eltwise_layer.html">caffe::EltwiseLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_embed_layer.html">caffe::EmbedLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_embed_layer.html">caffe::EmbedLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_filter_layer.html">caffe::FilterLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_filter_layer.html">caffe::FilterLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_flatten_layer.html">caffe::FlattenLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_flatten_layer.html">caffe::FlattenLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_h_d_f5_data_layer.html">caffe::HDF5DataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_h_d_f5_data_layer.html">caffe::HDF5DataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_h_d_f5_output_layer.html">caffe::HDF5OutputLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_h_d_f5_output_layer.html">caffe::HDF5OutputLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_im2col_layer.html">caffe::Im2colLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_im2col_layer.html">caffe::Im2colLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_inner_product_layer.html">caffe::InnerProductLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_inner_product_layer.html">caffe::InnerProductLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_input_layer.html">caffe::InputLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_input_layer.html">caffe::InputLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_loss_layer.html">caffe::LossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_loss_layer.html">caffe::LossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_l_r_n_layer.html">caffe::LRNLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_l_r_n_layer.html">caffe::LRNLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_l_s_t_m_unit_layer.html">caffe::LSTMUnitLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_l_s_t_m_unit_layer.html">caffe::LSTMUnitLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_m_v_n_layer.html">caffe::MVNLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_m_v_n_layer.html">caffe::MVNLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_neuron_layer.html">caffe::NeuronLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_neuron_layer.html">caffe::NeuronLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_parameter_layer.html">caffe::ParameterLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_parameter_layer.html">caffe::ParameterLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_pooling_layer.html">caffe::PoolingLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_pooling_layer.html">caffe::PoolingLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_python_layer.html">caffe::PythonLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_python_layer.html">caffe::PythonLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_recurrent_layer.html">caffe::RecurrentLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_recurrent_layer.html">caffe::RecurrentLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_reduction_layer.html">caffe::ReductionLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_reduction_layer.html">caffe::ReductionLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_reshape_layer.html">caffe::ReshapeLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_reshape_layer.html">caffe::ReshapeLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_scale_layer.html">caffe::ScaleLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_scale_layer.html">caffe::ScaleLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_silence_layer.html">caffe::SilenceLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_silence_layer.html">caffe::SilenceLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_slice_layer.html">caffe::SliceLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_slice_layer.html">caffe::SliceLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_softmax_layer.html">caffe::SoftmaxLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_softmax_layer.html">caffe::SoftmaxLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_split_layer.html">caffe::SplitLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_split_layer.html">caffe::SplitLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_s_p_p_layer.html">caffe::SPPLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_s_p_p_layer.html">caffe::SPPLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_tile_layer.html">caffe::TileLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_tile_layer.html">caffe::TileLayer&lt; Dtype &gt;</a>, <a class="el" href="classpascal__multilabel__datalayers_1_1_pascal_multilabel_data_layer_sync.html">pascal_multilabel_datalayers.PascalMultilabelDataLayerSync</a>, <a class="el" href="classpyloss_1_1_euclidean_loss_layer.html">pyloss.EuclideanLossLayer</a>, <a class="el" href="classtest__python__layer_1_1_exception_layer.html">test_python_layer.ExceptionLayer</a>, <a class="el" href="classtest__python__layer_1_1_parameter_layer.html">test_python_layer.ParameterLayer</a>, <a class="el" href="classtest__python__layer_1_1_phase_layer.html">test_python_layer.PhaseLayer</a>, <a class="el" href="classtest__python__layer_1_1_simple_layer.html">test_python_layer.SimpleLayer</a>, and <a class="el" href="classtest__python__layer__with__param__str_1_1_simple_param_layer.html">test_python_layer_with_param_str.SimpleParamLayer</a>.</p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a7b4e4ccea08c7b8b15acc6829d5735f6"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1_layer.html#a7b4e4ccea08c7b8b15acc6829d5735f6">Layer</a> (const <a class="el" href="classcaffe_1_1_layer_parameter.html">LayerParameter</a> &amp;param)</td></tr>
<tr class="separator:a7b4e4ccea08c7b8b15acc6829d5735f6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a18d6bfdb535ab8e96a971dec4ae39a84"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1_layer.html#a18d6bfdb535ab8e96a971dec4ae39a84">SetUp</a> (const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;bottom, const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;top)</td></tr>
<tr class="memdesc:a18d6bfdb535ab8e96a971dec4ae39a84"><td class="mdescLeft">&#160;</td><td class="mdescRight">Implements common layer setup functionality.  <a href="#a18d6bfdb535ab8e96a971dec4ae39a84">More...</a><br /></td></tr>
<tr class="separator:a18d6bfdb535ab8e96a971dec4ae39a84"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a481323a3e0972c682787f2137468c29f"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1_layer.html#a481323a3e0972c682787f2137468c29f">LayerSetUp</a> (const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;bottom, const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;top)</td></tr>
<tr class="memdesc:a481323a3e0972c682787f2137468c29f"><td class="mdescLeft">&#160;</td><td class="mdescRight">Does layer-specific setup: your layer should implement this function as well as Reshape.  <a href="#a481323a3e0972c682787f2137468c29f">More...</a><br /></td></tr>
<tr class="separator:a481323a3e0972c682787f2137468c29f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7fe981e8af8d93d587acf2a952be563d"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1_layer.html#a7fe981e8af8d93d587acf2a952be563d">Reshape</a> (const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;bottom, const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;top)=0</td></tr>
<tr class="memdesc:a7fe981e8af8d93d587acf2a952be563d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Adjust the shapes of top blobs and internal buffers to accommodate the shapes of the bottom blobs.  <a href="#a7fe981e8af8d93d587acf2a952be563d">More...</a><br /></td></tr>
<tr class="separator:a7fe981e8af8d93d587acf2a952be563d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab57d272dabe8c709d2a785eebe72ca57"><td class="memItemLeft" align="right" valign="top">Dtype&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1_layer.html#ab57d272dabe8c709d2a785eebe72ca57">Forward</a> (const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;bottom, const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;top)</td></tr>
<tr class="memdesc:ab57d272dabe8c709d2a785eebe72ca57"><td class="mdescLeft">&#160;</td><td class="mdescRight">Given the bottom blobs, compute the top blobs and the loss.  <a href="#ab57d272dabe8c709d2a785eebe72ca57">More...</a><br /></td></tr>
<tr class="separator:ab57d272dabe8c709d2a785eebe72ca57"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a183d343f5183a4762307f2c5e6ed1e12"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1_layer.html#a183d343f5183a4762307f2c5e6ed1e12">Backward</a> (const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;bottom)</td></tr>
<tr class="memdesc:a183d343f5183a4762307f2c5e6ed1e12"><td class="mdescLeft">&#160;</td><td class="mdescRight">Given the top blob error gradients, compute the bottom blob error gradients.  <a href="#a183d343f5183a4762307f2c5e6ed1e12">More...</a><br /></td></tr>
<tr class="separator:a183d343f5183a4762307f2c5e6ed1e12"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaf4524ce8641a30a8a4784aee1b2b4c8"><td class="memItemLeft" align="right" valign="top"><a id="aaf4524ce8641a30a8a4784aee1b2b4c8"></a>
vector&lt; shared_ptr&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; &gt; &gt; &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1_layer.html#aaf4524ce8641a30a8a4784aee1b2b4c8">blobs</a> ()</td></tr>
<tr class="memdesc:aaf4524ce8641a30a8a4784aee1b2b4c8"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns the vector of learnable parameter blobs. <br /></td></tr>
<tr class="separator:aaf4524ce8641a30a8a4784aee1b2b4c8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adff82274f146e2b6922d0ebac2aaf215"><td class="memItemLeft" align="right" valign="top"><a id="adff82274f146e2b6922d0ebac2aaf215"></a>
const <a class="el" href="classcaffe_1_1_layer_parameter.html">LayerParameter</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1_layer.html#adff82274f146e2b6922d0ebac2aaf215">layer_param</a> () const</td></tr>
<tr class="memdesc:adff82274f146e2b6922d0ebac2aaf215"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns the layer parameter. <br /></td></tr>
<tr class="separator:adff82274f146e2b6922d0ebac2aaf215"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4a1754828dda22cc8daa2f63377f3579"><td class="memItemLeft" align="right" valign="top"><a id="a4a1754828dda22cc8daa2f63377f3579"></a>
virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1_layer.html#a4a1754828dda22cc8daa2f63377f3579">ToProto</a> (<a class="el" href="classcaffe_1_1_layer_parameter.html">LayerParameter</a> *param, bool write_diff=false)</td></tr>
<tr class="memdesc:a4a1754828dda22cc8daa2f63377f3579"><td class="mdescLeft">&#160;</td><td class="mdescRight">Writes the layer parameter to a protocol buffer. <br /></td></tr>
<tr class="separator:a4a1754828dda22cc8daa2f63377f3579"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a899410336f30821644c8bd6c69a070c9"><td class="memItemLeft" align="right" valign="top"><a id="a899410336f30821644c8bd6c69a070c9"></a>
Dtype&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1_layer.html#a899410336f30821644c8bd6c69a070c9">loss</a> (const int top_index) const</td></tr>
<tr class="memdesc:a899410336f30821644c8bd6c69a070c9"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns the scalar loss associated with a top blob at a given index. <br /></td></tr>
<tr class="separator:a899410336f30821644c8bd6c69a070c9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a899b09f4b91ada8545b3a43ee91e0d69"><td class="memItemLeft" align="right" valign="top"><a id="a899b09f4b91ada8545b3a43ee91e0d69"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1_layer.html#a899b09f4b91ada8545b3a43ee91e0d69">set_loss</a> (const int top_index, const Dtype value)</td></tr>
<tr class="memdesc:a899b09f4b91ada8545b3a43ee91e0d69"><td class="mdescLeft">&#160;</td><td class="mdescRight">Sets the loss associated with a top blob at a given index. <br /></td></tr>
<tr class="separator:a899b09f4b91ada8545b3a43ee91e0d69"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8952bff6bc4c2a96d8ea30d8ff65b198"><td class="memItemLeft" align="right" valign="top"><a id="a8952bff6bc4c2a96d8ea30d8ff65b198"></a>
virtual const char *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1_layer.html#a8952bff6bc4c2a96d8ea30d8ff65b198">type</a> () const</td></tr>
<tr class="memdesc:a8952bff6bc4c2a96d8ea30d8ff65b198"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns the layer type. <br /></td></tr>
<tr class="separator:a8952bff6bc4c2a96d8ea30d8ff65b198"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8e5ee0494d85f5f55fc4396537cbc60f"><td class="memItemLeft" align="right" valign="top">virtual int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1_layer.html#a8e5ee0494d85f5f55fc4396537cbc60f">ExactNumBottomBlobs</a> () const</td></tr>
<tr class="memdesc:a8e5ee0494d85f5f55fc4396537cbc60f"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns the exact number of bottom blobs required by the layer, or -1 if no exact number is required.  <a href="#a8e5ee0494d85f5f55fc4396537cbc60f">More...</a><br /></td></tr>
<tr class="separator:a8e5ee0494d85f5f55fc4396537cbc60f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aca3cb2bafaefda5d4760aaebd0b72def"><td class="memItemLeft" align="right" valign="top">virtual int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1_layer.html#aca3cb2bafaefda5d4760aaebd0b72def">MinBottomBlobs</a> () const</td></tr>
<tr class="memdesc:aca3cb2bafaefda5d4760aaebd0b72def"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns the minimum number of bottom blobs required by the layer, or -1 if no minimum number is required.  <a href="#aca3cb2bafaefda5d4760aaebd0b72def">More...</a><br /></td></tr>
<tr class="separator:aca3cb2bafaefda5d4760aaebd0b72def"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af8bdc989053e0363ab032026b46de7c3"><td class="memItemLeft" align="right" valign="top">virtual int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1_layer.html#af8bdc989053e0363ab032026b46de7c3">MaxBottomBlobs</a> () const</td></tr>
<tr class="memdesc:af8bdc989053e0363ab032026b46de7c3"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns the maximum number of bottom blobs required by the layer, or -1 if no maximum number is required.  <a href="#af8bdc989053e0363ab032026b46de7c3">More...</a><br /></td></tr>
<tr class="separator:af8bdc989053e0363ab032026b46de7c3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a64e2ca72c719e4b2f1f9216ccfb0d37f"><td class="memItemLeft" align="right" valign="top">virtual int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1_layer.html#a64e2ca72c719e4b2f1f9216ccfb0d37f">ExactNumTopBlobs</a> () const</td></tr>
<tr class="memdesc:a64e2ca72c719e4b2f1f9216ccfb0d37f"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns the exact number of top blobs required by the layer, or -1 if no exact number is required.  <a href="#a64e2ca72c719e4b2f1f9216ccfb0d37f">More...</a><br /></td></tr>
<tr class="separator:a64e2ca72c719e4b2f1f9216ccfb0d37f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab9e4c8d642e413948b131d851a8462a4"><td class="memItemLeft" align="right" valign="top">virtual int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1_layer.html#ab9e4c8d642e413948b131d851a8462a4">MinTopBlobs</a> () const</td></tr>
<tr class="memdesc:ab9e4c8d642e413948b131d851a8462a4"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns the minimum number of top blobs required by the layer, or -1 if no minimum number is required.  <a href="#ab9e4c8d642e413948b131d851a8462a4">More...</a><br /></td></tr>
<tr class="separator:ab9e4c8d642e413948b131d851a8462a4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac6c03df0b6e40e776c94001e19994a2e"><td class="memItemLeft" align="right" valign="top">virtual int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1_layer.html#ac6c03df0b6e40e776c94001e19994a2e">MaxTopBlobs</a> () const</td></tr>
<tr class="memdesc:ac6c03df0b6e40e776c94001e19994a2e"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns the maximum number of top blobs required by the layer, or -1 if no maximum number is required.  <a href="#ac6c03df0b6e40e776c94001e19994a2e">More...</a><br /></td></tr>
<tr class="separator:ac6c03df0b6e40e776c94001e19994a2e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af452a938bc7596f9b5e9900c8dc4ab3d"><td class="memItemLeft" align="right" valign="top">virtual bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1_layer.html#af452a938bc7596f9b5e9900c8dc4ab3d">EqualNumBottomTopBlobs</a> () const</td></tr>
<tr class="memdesc:af452a938bc7596f9b5e9900c8dc4ab3d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns true if the layer requires an equal number of bottom and top blobs.  <a href="#af452a938bc7596f9b5e9900c8dc4ab3d">More...</a><br /></td></tr>
<tr class="separator:af452a938bc7596f9b5e9900c8dc4ab3d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a50130669e230a168d1f8fbbb8171f054"><td class="memItemLeft" align="right" valign="top">virtual bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1_layer.html#a50130669e230a168d1f8fbbb8171f054">AutoTopBlobs</a> () const</td></tr>
<tr class="memdesc:a50130669e230a168d1f8fbbb8171f054"><td class="mdescLeft">&#160;</td><td class="mdescRight">Return whether "anonymous" top blobs are created automatically by the layer.  <a href="#a50130669e230a168d1f8fbbb8171f054">More...</a><br /></td></tr>
<tr class="separator:a50130669e230a168d1f8fbbb8171f054"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1c0b2bffcd6d57e4bd49f820941badb6"><td class="memItemLeft" align="right" valign="top">virtual bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1_layer.html#a1c0b2bffcd6d57e4bd49f820941badb6">AllowForceBackward</a> (const int bottom_index) const</td></tr>
<tr class="memdesc:a1c0b2bffcd6d57e4bd49f820941badb6"><td class="mdescLeft">&#160;</td><td class="mdescRight">Return whether to allow force_backward for a given bottom blob index.  <a href="#a1c0b2bffcd6d57e4bd49f820941badb6">More...</a><br /></td></tr>
<tr class="separator:a1c0b2bffcd6d57e4bd49f820941badb6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1a3708013b0231e71d725252e10ce6e3"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1_layer.html#a1a3708013b0231e71d725252e10ce6e3">param_propagate_down</a> (const int param_id)</td></tr>
<tr class="memdesc:a1a3708013b0231e71d725252e10ce6e3"><td class="mdescLeft">&#160;</td><td class="mdescRight">Specifies whether the layer should compute gradients w.r.t. a parameter at a particular index given by param_id.  <a href="#a1a3708013b0231e71d725252e10ce6e3">More...</a><br /></td></tr>
<tr class="separator:a1a3708013b0231e71d725252e10ce6e3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9a6fcb843803ed556f0a69cc2864379b"><td class="memItemLeft" align="right" valign="top"><a id="a9a6fcb843803ed556f0a69cc2864379b"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1_layer.html#a9a6fcb843803ed556f0a69cc2864379b">set_param_propagate_down</a> (const int param_id, const bool value)</td></tr>
<tr class="memdesc:a9a6fcb843803ed556f0a69cc2864379b"><td class="mdescLeft">&#160;</td><td class="mdescRight">Sets whether the layer should compute gradients w.r.t. a parameter at a particular index given by param_id. <br /></td></tr>
<tr class="separator:a9a6fcb843803ed556f0a69cc2864379b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7b4e4ccea08c7b8b15acc6829d5735f6"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1_layer.html#a7b4e4ccea08c7b8b15acc6829d5735f6">Layer</a> (const <a class="el" href="classcaffe_1_1_layer_parameter.html">LayerParameter</a> &amp;param)</td></tr>
<tr class="separator:a7b4e4ccea08c7b8b15acc6829d5735f6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a18d6bfdb535ab8e96a971dec4ae39a84"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1_layer.html#a18d6bfdb535ab8e96a971dec4ae39a84">SetUp</a> (const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;bottom, const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;top)</td></tr>
<tr class="memdesc:a18d6bfdb535ab8e96a971dec4ae39a84"><td class="mdescLeft">&#160;</td><td class="mdescRight">Implements common layer setup functionality.  <a href="#a18d6bfdb535ab8e96a971dec4ae39a84">More...</a><br /></td></tr>
<tr class="separator:a18d6bfdb535ab8e96a971dec4ae39a84"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a481323a3e0972c682787f2137468c29f"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1_layer.html#a481323a3e0972c682787f2137468c29f">LayerSetUp</a> (const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;bottom, const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;top)</td></tr>
<tr class="memdesc:a481323a3e0972c682787f2137468c29f"><td class="mdescLeft">&#160;</td><td class="mdescRight">Does layer-specific setup: your layer should implement this function as well as Reshape.  <a href="#a481323a3e0972c682787f2137468c29f">More...</a><br /></td></tr>
<tr class="separator:a481323a3e0972c682787f2137468c29f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7fe981e8af8d93d587acf2a952be563d"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1_layer.html#a7fe981e8af8d93d587acf2a952be563d">Reshape</a> (const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;bottom, const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;top)=0</td></tr>
<tr class="memdesc:a7fe981e8af8d93d587acf2a952be563d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Adjust the shapes of top blobs and internal buffers to accommodate the shapes of the bottom blobs.  <a href="#a7fe981e8af8d93d587acf2a952be563d">More...</a><br /></td></tr>
<tr class="separator:a7fe981e8af8d93d587acf2a952be563d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab57d272dabe8c709d2a785eebe72ca57"><td class="memItemLeft" align="right" valign="top">Dtype&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1_layer.html#ab57d272dabe8c709d2a785eebe72ca57">Forward</a> (const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;bottom, const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;top)</td></tr>
<tr class="memdesc:ab57d272dabe8c709d2a785eebe72ca57"><td class="mdescLeft">&#160;</td><td class="mdescRight">Given the bottom blobs, compute the top blobs and the loss.  <a href="#ab57d272dabe8c709d2a785eebe72ca57">More...</a><br /></td></tr>
<tr class="separator:ab57d272dabe8c709d2a785eebe72ca57"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a183d343f5183a4762307f2c5e6ed1e12"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1_layer.html#a183d343f5183a4762307f2c5e6ed1e12">Backward</a> (const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;bottom)</td></tr>
<tr class="memdesc:a183d343f5183a4762307f2c5e6ed1e12"><td class="mdescLeft">&#160;</td><td class="mdescRight">Given the top blob error gradients, compute the bottom blob error gradients.  <a href="#a183d343f5183a4762307f2c5e6ed1e12">More...</a><br /></td></tr>
<tr class="separator:a183d343f5183a4762307f2c5e6ed1e12"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aaf4524ce8641a30a8a4784aee1b2b4c8"><td class="memItemLeft" align="right" valign="top"><a id="aaf4524ce8641a30a8a4784aee1b2b4c8"></a>
vector&lt; shared_ptr&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; &gt; &gt; &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1_layer.html#aaf4524ce8641a30a8a4784aee1b2b4c8">blobs</a> ()</td></tr>
<tr class="memdesc:aaf4524ce8641a30a8a4784aee1b2b4c8"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns the vector of learnable parameter blobs. <br /></td></tr>
<tr class="separator:aaf4524ce8641a30a8a4784aee1b2b4c8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adff82274f146e2b6922d0ebac2aaf215"><td class="memItemLeft" align="right" valign="top"><a id="adff82274f146e2b6922d0ebac2aaf215"></a>
const <a class="el" href="classcaffe_1_1_layer_parameter.html">LayerParameter</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1_layer.html#adff82274f146e2b6922d0ebac2aaf215">layer_param</a> () const</td></tr>
<tr class="memdesc:adff82274f146e2b6922d0ebac2aaf215"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns the layer parameter. <br /></td></tr>
<tr class="separator:adff82274f146e2b6922d0ebac2aaf215"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab2badafa974783cee8ecc8f666769a0e"><td class="memItemLeft" align="right" valign="top"><a id="ab2badafa974783cee8ecc8f666769a0e"></a>
virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1_layer.html#ab2badafa974783cee8ecc8f666769a0e">ToProto</a> (<a class="el" href="classcaffe_1_1_layer_parameter.html">LayerParameter</a> *param, bool write_diff=false)</td></tr>
<tr class="memdesc:ab2badafa974783cee8ecc8f666769a0e"><td class="mdescLeft">&#160;</td><td class="mdescRight">Writes the layer parameter to a protocol buffer. <br /></td></tr>
<tr class="separator:ab2badafa974783cee8ecc8f666769a0e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a899410336f30821644c8bd6c69a070c9"><td class="memItemLeft" align="right" valign="top"><a id="a899410336f30821644c8bd6c69a070c9"></a>
Dtype&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1_layer.html#a899410336f30821644c8bd6c69a070c9">loss</a> (const int top_index) const</td></tr>
<tr class="memdesc:a899410336f30821644c8bd6c69a070c9"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns the scalar loss associated with a top blob at a given index. <br /></td></tr>
<tr class="separator:a899410336f30821644c8bd6c69a070c9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a899b09f4b91ada8545b3a43ee91e0d69"><td class="memItemLeft" align="right" valign="top"><a id="a899b09f4b91ada8545b3a43ee91e0d69"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1_layer.html#a899b09f4b91ada8545b3a43ee91e0d69">set_loss</a> (const int top_index, const Dtype value)</td></tr>
<tr class="memdesc:a899b09f4b91ada8545b3a43ee91e0d69"><td class="mdescLeft">&#160;</td><td class="mdescRight">Sets the loss associated with a top blob at a given index. <br /></td></tr>
<tr class="separator:a899b09f4b91ada8545b3a43ee91e0d69"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8952bff6bc4c2a96d8ea30d8ff65b198"><td class="memItemLeft" align="right" valign="top"><a id="a8952bff6bc4c2a96d8ea30d8ff65b198"></a>
virtual const char *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1_layer.html#a8952bff6bc4c2a96d8ea30d8ff65b198">type</a> () const</td></tr>
<tr class="memdesc:a8952bff6bc4c2a96d8ea30d8ff65b198"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns the layer type. <br /></td></tr>
<tr class="separator:a8952bff6bc4c2a96d8ea30d8ff65b198"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8e5ee0494d85f5f55fc4396537cbc60f"><td class="memItemLeft" align="right" valign="top">virtual int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1_layer.html#a8e5ee0494d85f5f55fc4396537cbc60f">ExactNumBottomBlobs</a> () const</td></tr>
<tr class="memdesc:a8e5ee0494d85f5f55fc4396537cbc60f"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns the exact number of bottom blobs required by the layer, or -1 if no exact number is required.  <a href="#a8e5ee0494d85f5f55fc4396537cbc60f">More...</a><br /></td></tr>
<tr class="separator:a8e5ee0494d85f5f55fc4396537cbc60f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aca3cb2bafaefda5d4760aaebd0b72def"><td class="memItemLeft" align="right" valign="top">virtual int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1_layer.html#aca3cb2bafaefda5d4760aaebd0b72def">MinBottomBlobs</a> () const</td></tr>
<tr class="memdesc:aca3cb2bafaefda5d4760aaebd0b72def"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns the minimum number of bottom blobs required by the layer, or -1 if no minimum number is required.  <a href="#aca3cb2bafaefda5d4760aaebd0b72def">More...</a><br /></td></tr>
<tr class="separator:aca3cb2bafaefda5d4760aaebd0b72def"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af8bdc989053e0363ab032026b46de7c3"><td class="memItemLeft" align="right" valign="top">virtual int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1_layer.html#af8bdc989053e0363ab032026b46de7c3">MaxBottomBlobs</a> () const</td></tr>
<tr class="memdesc:af8bdc989053e0363ab032026b46de7c3"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns the maximum number of bottom blobs required by the layer, or -1 if no maximum number is required.  <a href="#af8bdc989053e0363ab032026b46de7c3">More...</a><br /></td></tr>
<tr class="separator:af8bdc989053e0363ab032026b46de7c3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a64e2ca72c719e4b2f1f9216ccfb0d37f"><td class="memItemLeft" align="right" valign="top">virtual int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1_layer.html#a64e2ca72c719e4b2f1f9216ccfb0d37f">ExactNumTopBlobs</a> () const</td></tr>
<tr class="memdesc:a64e2ca72c719e4b2f1f9216ccfb0d37f"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns the exact number of top blobs required by the layer, or -1 if no exact number is required.  <a href="#a64e2ca72c719e4b2f1f9216ccfb0d37f">More...</a><br /></td></tr>
<tr class="separator:a64e2ca72c719e4b2f1f9216ccfb0d37f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab9e4c8d642e413948b131d851a8462a4"><td class="memItemLeft" align="right" valign="top">virtual int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1_layer.html#ab9e4c8d642e413948b131d851a8462a4">MinTopBlobs</a> () const</td></tr>
<tr class="memdesc:ab9e4c8d642e413948b131d851a8462a4"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns the minimum number of top blobs required by the layer, or -1 if no minimum number is required.  <a href="#ab9e4c8d642e413948b131d851a8462a4">More...</a><br /></td></tr>
<tr class="separator:ab9e4c8d642e413948b131d851a8462a4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac6c03df0b6e40e776c94001e19994a2e"><td class="memItemLeft" align="right" valign="top">virtual int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1_layer.html#ac6c03df0b6e40e776c94001e19994a2e">MaxTopBlobs</a> () const</td></tr>
<tr class="memdesc:ac6c03df0b6e40e776c94001e19994a2e"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns the maximum number of top blobs required by the layer, or -1 if no maximum number is required.  <a href="#ac6c03df0b6e40e776c94001e19994a2e">More...</a><br /></td></tr>
<tr class="separator:ac6c03df0b6e40e776c94001e19994a2e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af452a938bc7596f9b5e9900c8dc4ab3d"><td class="memItemLeft" align="right" valign="top">virtual bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1_layer.html#af452a938bc7596f9b5e9900c8dc4ab3d">EqualNumBottomTopBlobs</a> () const</td></tr>
<tr class="memdesc:af452a938bc7596f9b5e9900c8dc4ab3d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Returns true if the layer requires an equal number of bottom and top blobs.  <a href="#af452a938bc7596f9b5e9900c8dc4ab3d">More...</a><br /></td></tr>
<tr class="separator:af452a938bc7596f9b5e9900c8dc4ab3d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a50130669e230a168d1f8fbbb8171f054"><td class="memItemLeft" align="right" valign="top">virtual bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1_layer.html#a50130669e230a168d1f8fbbb8171f054">AutoTopBlobs</a> () const</td></tr>
<tr class="memdesc:a50130669e230a168d1f8fbbb8171f054"><td class="mdescLeft">&#160;</td><td class="mdescRight">Return whether "anonymous" top blobs are created automatically by the layer.  <a href="#a50130669e230a168d1f8fbbb8171f054">More...</a><br /></td></tr>
<tr class="separator:a50130669e230a168d1f8fbbb8171f054"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1c0b2bffcd6d57e4bd49f820941badb6"><td class="memItemLeft" align="right" valign="top">virtual bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1_layer.html#a1c0b2bffcd6d57e4bd49f820941badb6">AllowForceBackward</a> (const int bottom_index) const</td></tr>
<tr class="memdesc:a1c0b2bffcd6d57e4bd49f820941badb6"><td class="mdescLeft">&#160;</td><td class="mdescRight">Return whether to allow force_backward for a given bottom blob index.  <a href="#a1c0b2bffcd6d57e4bd49f820941badb6">More...</a><br /></td></tr>
<tr class="separator:a1c0b2bffcd6d57e4bd49f820941badb6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1a3708013b0231e71d725252e10ce6e3"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1_layer.html#a1a3708013b0231e71d725252e10ce6e3">param_propagate_down</a> (const int param_id)</td></tr>
<tr class="memdesc:a1a3708013b0231e71d725252e10ce6e3"><td class="mdescLeft">&#160;</td><td class="mdescRight">Specifies whether the layer should compute gradients w.r.t. a parameter at a particular index given by param_id.  <a href="#a1a3708013b0231e71d725252e10ce6e3">More...</a><br /></td></tr>
<tr class="separator:a1a3708013b0231e71d725252e10ce6e3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9a6fcb843803ed556f0a69cc2864379b"><td class="memItemLeft" align="right" valign="top"><a id="a9a6fcb843803ed556f0a69cc2864379b"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1_layer.html#a9a6fcb843803ed556f0a69cc2864379b">set_param_propagate_down</a> (const int param_id, const bool value)</td></tr>
<tr class="memdesc:a9a6fcb843803ed556f0a69cc2864379b"><td class="mdescLeft">&#160;</td><td class="mdescRight">Sets whether the layer should compute gradients w.r.t. a parameter at a particular index given by param_id. <br /></td></tr>
<tr class="separator:a9a6fcb843803ed556f0a69cc2864379b"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pro-methods"></a>
Protected Member Functions</h2></td></tr>
<tr class="memitem:a576ac6a60b1e99fe383831f52a6cea77"><td class="memItemLeft" align="right" valign="top"><a id="a576ac6a60b1e99fe383831f52a6cea77"></a>
virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1_layer.html#a576ac6a60b1e99fe383831f52a6cea77">Forward_cpu</a> (const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;bottom, const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;top)=0</td></tr>
<tr class="memdesc:a576ac6a60b1e99fe383831f52a6cea77"><td class="mdescLeft">&#160;</td><td class="mdescRight">Using the CPU device, compute the layer output. <br /></td></tr>
<tr class="separator:a576ac6a60b1e99fe383831f52a6cea77"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af3a88d8fb290877b4c7eb37daa3499de"><td class="memItemLeft" align="right" valign="top"><a id="af3a88d8fb290877b4c7eb37daa3499de"></a>
virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1_layer.html#af3a88d8fb290877b4c7eb37daa3499de">Forward_gpu</a> (const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;bottom, const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;top)</td></tr>
<tr class="memdesc:af3a88d8fb290877b4c7eb37daa3499de"><td class="mdescLeft">&#160;</td><td class="mdescRight">Using the GPU device, compute the layer output. Fall back to <a class="el" href="classcaffe_1_1_layer.html#a576ac6a60b1e99fe383831f52a6cea77" title="Using the CPU device, compute the layer output. ">Forward_cpu()</a> if unavailable. <br /></td></tr>
<tr class="separator:af3a88d8fb290877b4c7eb37daa3499de"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a75c9b2a321dc713e0eaef530d02dc37f"><td class="memItemLeft" align="right" valign="top"><a id="a75c9b2a321dc713e0eaef530d02dc37f"></a>
virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1_layer.html#a75c9b2a321dc713e0eaef530d02dc37f">Backward_cpu</a> (const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;bottom)=0</td></tr>
<tr class="memdesc:a75c9b2a321dc713e0eaef530d02dc37f"><td class="mdescLeft">&#160;</td><td class="mdescRight">Using the CPU device, compute the gradients for any parameters and for the bottom blobs if propagate_down is true. <br /></td></tr>
<tr class="separator:a75c9b2a321dc713e0eaef530d02dc37f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6faee52af6250a38d1b879008257f5a7"><td class="memItemLeft" align="right" valign="top"><a id="a6faee52af6250a38d1b879008257f5a7"></a>
virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1_layer.html#a6faee52af6250a38d1b879008257f5a7">Backward_gpu</a> (const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;bottom)</td></tr>
<tr class="memdesc:a6faee52af6250a38d1b879008257f5a7"><td class="mdescLeft">&#160;</td><td class="mdescRight">Using the GPU device, compute the gradients for any parameters and for the bottom blobs if propagate_down is true. Fall back to <a class="el" href="classcaffe_1_1_layer.html#a75c9b2a321dc713e0eaef530d02dc37f" title="Using the CPU device, compute the gradients for any parameters and for the bottom blobs if propagate_...">Backward_cpu()</a> if unavailable. <br /></td></tr>
<tr class="separator:a6faee52af6250a38d1b879008257f5a7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a55c8036130225fbc874a986bdf4b27e2"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1_layer.html#a55c8036130225fbc874a986bdf4b27e2">CheckBlobCounts</a> (const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;bottom, const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;top)</td></tr>
<tr class="separator:a55c8036130225fbc874a986bdf4b27e2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a04eb2a3d1d59c64cd64c233217d5d6fc"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1_layer.html#a04eb2a3d1d59c64cd64c233217d5d6fc">SetLossWeights</a> (const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;top)</td></tr>
<tr class="separator:a04eb2a3d1d59c64cd64c233217d5d6fc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a576ac6a60b1e99fe383831f52a6cea77"><td class="memItemLeft" align="right" valign="top"><a id="a576ac6a60b1e99fe383831f52a6cea77"></a>
virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1_layer.html#a576ac6a60b1e99fe383831f52a6cea77">Forward_cpu</a> (const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;bottom, const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;top)=0</td></tr>
<tr class="memdesc:a576ac6a60b1e99fe383831f52a6cea77"><td class="mdescLeft">&#160;</td><td class="mdescRight">Using the CPU device, compute the layer output. <br /></td></tr>
<tr class="separator:a576ac6a60b1e99fe383831f52a6cea77"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af3a88d8fb290877b4c7eb37daa3499de"><td class="memItemLeft" align="right" valign="top"><a id="af3a88d8fb290877b4c7eb37daa3499de"></a>
virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1_layer.html#af3a88d8fb290877b4c7eb37daa3499de">Forward_gpu</a> (const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;bottom, const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;top)</td></tr>
<tr class="memdesc:af3a88d8fb290877b4c7eb37daa3499de"><td class="mdescLeft">&#160;</td><td class="mdescRight">Using the GPU device, compute the layer output. Fall back to <a class="el" href="classcaffe_1_1_layer.html#a576ac6a60b1e99fe383831f52a6cea77" title="Using the CPU device, compute the layer output. ">Forward_cpu()</a> if unavailable. <br /></td></tr>
<tr class="separator:af3a88d8fb290877b4c7eb37daa3499de"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a75c9b2a321dc713e0eaef530d02dc37f"><td class="memItemLeft" align="right" valign="top"><a id="a75c9b2a321dc713e0eaef530d02dc37f"></a>
virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1_layer.html#a75c9b2a321dc713e0eaef530d02dc37f">Backward_cpu</a> (const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;bottom)=0</td></tr>
<tr class="memdesc:a75c9b2a321dc713e0eaef530d02dc37f"><td class="mdescLeft">&#160;</td><td class="mdescRight">Using the CPU device, compute the gradients for any parameters and for the bottom blobs if propagate_down is true. <br /></td></tr>
<tr class="separator:a75c9b2a321dc713e0eaef530d02dc37f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6faee52af6250a38d1b879008257f5a7"><td class="memItemLeft" align="right" valign="top"><a id="a6faee52af6250a38d1b879008257f5a7"></a>
virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1_layer.html#a6faee52af6250a38d1b879008257f5a7">Backward_gpu</a> (const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;top, const vector&lt; bool &gt; &amp;propagate_down, const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;bottom)</td></tr>
<tr class="memdesc:a6faee52af6250a38d1b879008257f5a7"><td class="mdescLeft">&#160;</td><td class="mdescRight">Using the GPU device, compute the gradients for any parameters and for the bottom blobs if propagate_down is true. Fall back to <a class="el" href="classcaffe_1_1_layer.html#a75c9b2a321dc713e0eaef530d02dc37f" title="Using the CPU device, compute the gradients for any parameters and for the bottom blobs if propagate_...">Backward_cpu()</a> if unavailable. <br /></td></tr>
<tr class="separator:a6faee52af6250a38d1b879008257f5a7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a55c8036130225fbc874a986bdf4b27e2"><td class="memItemLeft" align="right" valign="top">virtual void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1_layer.html#a55c8036130225fbc874a986bdf4b27e2">CheckBlobCounts</a> (const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;bottom, const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;top)</td></tr>
<tr class="separator:a55c8036130225fbc874a986bdf4b27e2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a04eb2a3d1d59c64cd64c233217d5d6fc"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1_layer.html#a04eb2a3d1d59c64cd64c233217d5d6fc">SetLossWeights</a> (const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;top)</td></tr>
<tr class="separator:a04eb2a3d1d59c64cd64c233217d5d6fc"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pro-attribs"></a>
Protected Attributes</h2></td></tr>
<tr class="memitem:a7ed12bb2df25c887e41d7ea9557fc701"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classcaffe_1_1_layer_parameter.html">LayerParameter</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1_layer.html#a7ed12bb2df25c887e41d7ea9557fc701">layer_param_</a></td></tr>
<tr class="separator:a7ed12bb2df25c887e41d7ea9557fc701"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1d04ad7f595a82a1c811f102d68b8a19"><td class="memItemLeft" align="right" valign="top">Phase&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1_layer.html#a1d04ad7f595a82a1c811f102d68b8a19">phase_</a></td></tr>
<tr class="separator:a1d04ad7f595a82a1c811f102d68b8a19"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8d6998a5f8ca95990976021de743dd21"><td class="memItemLeft" align="right" valign="top">vector&lt; shared_ptr&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1_layer.html#a8d6998a5f8ca95990976021de743dd21">blobs_</a></td></tr>
<tr class="separator:a8d6998a5f8ca95990976021de743dd21"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab1db6c32fa71343dac868b07288eb45e"><td class="memItemLeft" align="right" valign="top">vector&lt; bool &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1_layer.html#ab1db6c32fa71343dac868b07288eb45e">param_propagate_down_</a></td></tr>
<tr class="separator:ab1db6c32fa71343dac868b07288eb45e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5fbf5ce7385b2da3d8edc7eec3822ac7"><td class="memItemLeft" align="right" valign="top">vector&lt; Dtype &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classcaffe_1_1_layer.html#a5fbf5ce7385b2da3d8edc7eec3822ac7">loss_</a></td></tr>
<tr class="separator:a5fbf5ce7385b2da3d8edc7eec3822ac7"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><h3>template&lt;typename Dtype&gt;<br />
class caffe::Layer&lt; Dtype &gt;</h3>

<p class="">An interface for the units of computation which can be composed into a <a class="el" href="classcaffe_1_1_net.html" title="Connects Layers together into a directed acyclic graph (DAG) specified by a NetParameter. ">Net</a>. </p>
<p class=""><a class="el" href="classcaffe_1_1_layer.html" title="An interface for the units of computation which can be composed into a Net. ">Layer</a>s must implement a Forward function, in which they take their input (bottom) <a class="el" href="classcaffe_1_1_blob.html" title="A wrapper around SyncedMemory holders serving as the basic computational unit through which Layers...">Blob</a>s (if any) and compute their output <a class="el" href="classcaffe_1_1_blob.html" title="A wrapper around SyncedMemory holders serving as the basic computational unit through which Layers...">Blob</a>s (if any). They may also implement a Backward function, in which they compute the error gradients with respect to their input <a class="el" href="classcaffe_1_1_blob.html" title="A wrapper around SyncedMemory holders serving as the basic computational unit through which Layers...">Blob</a>s, given the error gradients with their output <a class="el" href="classcaffe_1_1_blob.html" title="A wrapper around SyncedMemory holders serving as the basic computational unit through which Layers...">Blob</a>s. </p>
</div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="a7b4e4ccea08c7b8b15acc6829d5735f6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7b4e4ccea08c7b8b15acc6829d5735f6">&#9670;&nbsp;</a></span>Layer() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Dtype&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classcaffe_1_1_layer.html">caffe::Layer</a>&lt; Dtype &gt;::<a class="el" href="classcaffe_1_1_layer.html">Layer</a> </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classcaffe_1_1_layer_parameter.html">LayerParameter</a> &amp;&#160;</td>
          <td class="paramname"><em>param</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">explicit</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p class="">You should not implement your own constructor. Any set up code should go to <a class="el" href="classcaffe_1_1_layer.html#a18d6bfdb535ab8e96a971dec4ae39a84" title="Implements common layer setup functionality. ">SetUp()</a>, where the dimensions of the bottom blobs are provided to the layer. </p>

</div>
</div>
<a id="a7b4e4ccea08c7b8b15acc6829d5735f6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7b4e4ccea08c7b8b15acc6829d5735f6">&#9670;&nbsp;</a></span>Layer() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Dtype&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classcaffe_1_1_layer.html">caffe::Layer</a>&lt; Dtype &gt;::<a class="el" href="classcaffe_1_1_layer.html">Layer</a> </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classcaffe_1_1_layer_parameter.html">LayerParameter</a> &amp;&#160;</td>
          <td class="paramname"><em>param</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">explicit</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p class="">You should not implement your own constructor. Any set up code should go to <a class="el" href="classcaffe_1_1_layer.html#a18d6bfdb535ab8e96a971dec4ae39a84" title="Implements common layer setup functionality. ">SetUp()</a>, where the dimensions of the bottom blobs are provided to the layer. </p>

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="a1c0b2bffcd6d57e4bd49f820941badb6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1c0b2bffcd6d57e4bd49f820941badb6">&#9670;&nbsp;</a></span>AllowForceBackward() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Dtype&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual bool <a class="el" href="classcaffe_1_1_layer.html">caffe::Layer</a>&lt; Dtype &gt;::AllowForceBackward </td>
          <td>(</td>
          <td class="paramtype">const int&#160;</td>
          <td class="paramname"><em>bottom_index</em></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Return whether to allow force_backward for a given bottom blob index. </p>
<p class="">If AllowForceBackward(i) == false, we will ignore the force_backward setting and backpropagate to blob i only if it needs gradient information (as is done when force_backward == false). </p>

<p>Reimplemented in <a class="el" href="classcaffe_1_1_l_s_t_m_unit_layer.html#a9c46167bc8b96b28196bc24a5515b531">caffe::LSTMUnitLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_l_s_t_m_unit_layer.html#a9c46167bc8b96b28196bc24a5515b531">caffe::LSTMUnitLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_recurrent_layer.html#a8d91610cc8b9615a1db4f07fe5590a37">caffe::RecurrentLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_recurrent_layer.html#a8d91610cc8b9615a1db4f07fe5590a37">caffe::RecurrentLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_weighted_euclidean_loss_layer.html#a6b996834a2a27bb8d2d9b48873b6cd65">caffe::WeightedEuclideanLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_weighted_euclidean_loss_layer.html#a6b996834a2a27bb8d2d9b48873b6cd65">caffe::WeightedEuclideanLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_euclidean_loss_layer.html#a76dd3fde9f09cb9840f05ee035b5a2c5">caffe::EuclideanLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_euclidean_loss_layer.html#a76dd3fde9f09cb9840f05ee035b5a2c5">caffe::EuclideanLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_contrastive_loss_layer.html#af0f16d5119ac6118b670c1966c38fd7d">caffe::ContrastiveLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_contrastive_loss_layer.html#af0f16d5119ac6118b670c1966c38fd7d">caffe::ContrastiveLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_loss_layer.html#a36d35155bfe0de53a79c517f33759612">caffe::LossLayer&lt; Dtype &gt;</a>, and <a class="el" href="classcaffe_1_1_loss_layer.html#a36d35155bfe0de53a79c517f33759612">caffe::LossLayer&lt; Dtype &gt;</a>.</p>

</div>
</div>
<a id="a1c0b2bffcd6d57e4bd49f820941badb6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1c0b2bffcd6d57e4bd49f820941badb6">&#9670;&nbsp;</a></span>AllowForceBackward() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Dtype&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual bool <a class="el" href="classcaffe_1_1_layer.html">caffe::Layer</a>&lt; Dtype &gt;::AllowForceBackward </td>
          <td>(</td>
          <td class="paramtype">const int&#160;</td>
          <td class="paramname"><em>bottom_index</em></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Return whether to allow force_backward for a given bottom blob index. </p>
<p class="">If AllowForceBackward(i) == false, we will ignore the force_backward setting and backpropagate to blob i only if it needs gradient information (as is done when force_backward == false). </p>

<p>Reimplemented in <a class="el" href="classcaffe_1_1_l_s_t_m_unit_layer.html#a9c46167bc8b96b28196bc24a5515b531">caffe::LSTMUnitLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_l_s_t_m_unit_layer.html#a9c46167bc8b96b28196bc24a5515b531">caffe::LSTMUnitLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_recurrent_layer.html#a8d91610cc8b9615a1db4f07fe5590a37">caffe::RecurrentLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_recurrent_layer.html#a8d91610cc8b9615a1db4f07fe5590a37">caffe::RecurrentLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_weighted_euclidean_loss_layer.html#a6b996834a2a27bb8d2d9b48873b6cd65">caffe::WeightedEuclideanLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_weighted_euclidean_loss_layer.html#a6b996834a2a27bb8d2d9b48873b6cd65">caffe::WeightedEuclideanLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_euclidean_loss_layer.html#a76dd3fde9f09cb9840f05ee035b5a2c5">caffe::EuclideanLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_euclidean_loss_layer.html#a76dd3fde9f09cb9840f05ee035b5a2c5">caffe::EuclideanLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_contrastive_loss_layer.html#af0f16d5119ac6118b670c1966c38fd7d">caffe::ContrastiveLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_contrastive_loss_layer.html#af0f16d5119ac6118b670c1966c38fd7d">caffe::ContrastiveLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_loss_layer.html#a36d35155bfe0de53a79c517f33759612">caffe::LossLayer&lt; Dtype &gt;</a>, and <a class="el" href="classcaffe_1_1_loss_layer.html#a36d35155bfe0de53a79c517f33759612">caffe::LossLayer&lt; Dtype &gt;</a>.</p>

</div>
</div>
<a id="a50130669e230a168d1f8fbbb8171f054"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a50130669e230a168d1f8fbbb8171f054">&#9670;&nbsp;</a></span>AutoTopBlobs() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Dtype&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual bool <a class="el" href="classcaffe_1_1_layer.html">caffe::Layer</a>&lt; Dtype &gt;::AutoTopBlobs </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Return whether "anonymous" top blobs are created automatically by the layer. </p>
<p class="">If this method returns true, <a class="el" href="classcaffe_1_1_net.html#ae9fcfaabc89165d6c0cb4b14b4c6b584" title="Initialize a network with a NetParameter. ">Net::Init</a> will create enough "anonymous" top blobs to fulfill the requirement specified by <a class="el" href="classcaffe_1_1_layer.html#a64e2ca72c719e4b2f1f9216ccfb0d37f" title="Returns the exact number of top blobs required by the layer, or -1 if no exact number is required...">ExactNumTopBlobs()</a> or <a class="el" href="classcaffe_1_1_layer.html#ab9e4c8d642e413948b131d851a8462a4" title="Returns the minimum number of top blobs required by the layer, or -1 if no minimum number is required...">MinTopBlobs()</a>. </p>

<p>Reimplemented in <a class="el" href="classcaffe_1_1_loss_layer.html#ae98a9942cdb1c67e09d45cc2d876618e">caffe::LossLayer&lt; Dtype &gt;</a>, and <a class="el" href="classcaffe_1_1_loss_layer.html#ae98a9942cdb1c67e09d45cc2d876618e">caffe::LossLayer&lt; Dtype &gt;</a>.</p>
<div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="classcaffe_1_1_layer_a50130669e230a168d1f8fbbb8171f054_icgraph.png" border="0" usemap="#classcaffe_1_1_layer_a50130669e230a168d1f8fbbb8171f054_icgraph" alt=""/></div>
<map name="classcaffe_1_1_layer_a50130669e230a168d1f8fbbb8171f054_icgraph" id="classcaffe_1_1_layer_a50130669e230a168d1f8fbbb8171f054_icgraph">
<area shape="rect" id="node2" href="classcaffe_1_1_net.html#ae9fcfaabc89165d6c0cb4b14b4c6b584" title="Initialize a network with a NetParameter. " alt="" coords="235,5,341,32"/>
</map>
</div>

</div>
</div>
<a id="a50130669e230a168d1f8fbbb8171f054"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a50130669e230a168d1f8fbbb8171f054">&#9670;&nbsp;</a></span>AutoTopBlobs() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Dtype&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual bool <a class="el" href="classcaffe_1_1_layer.html">caffe::Layer</a>&lt; Dtype &gt;::AutoTopBlobs </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Return whether "anonymous" top blobs are created automatically by the layer. </p>
<p class="">If this method returns true, <a class="el" href="classcaffe_1_1_net.html#ae9fcfaabc89165d6c0cb4b14b4c6b584" title="Initialize a network with a NetParameter. ">Net::Init</a> will create enough "anonymous" top blobs to fulfill the requirement specified by <a class="el" href="classcaffe_1_1_layer.html#a64e2ca72c719e4b2f1f9216ccfb0d37f" title="Returns the exact number of top blobs required by the layer, or -1 if no exact number is required...">ExactNumTopBlobs()</a> or <a class="el" href="classcaffe_1_1_layer.html#ab9e4c8d642e413948b131d851a8462a4" title="Returns the minimum number of top blobs required by the layer, or -1 if no minimum number is required...">MinTopBlobs()</a>. </p>

<p>Reimplemented in <a class="el" href="classcaffe_1_1_loss_layer.html#ae98a9942cdb1c67e09d45cc2d876618e">caffe::LossLayer&lt; Dtype &gt;</a>, and <a class="el" href="classcaffe_1_1_loss_layer.html#ae98a9942cdb1c67e09d45cc2d876618e">caffe::LossLayer&lt; Dtype &gt;</a>.</p>

</div>
</div>
<a id="a183d343f5183a4762307f2c5e6ed1e12"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a183d343f5183a4762307f2c5e6ed1e12">&#9670;&nbsp;</a></span>Backward() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Dtype&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcaffe_1_1_layer.html">caffe::Layer</a>&lt; Dtype &gt;::Backward </td>
          <td>(</td>
          <td class="paramtype">const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;&#160;</td>
          <td class="paramname"><em>top</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const vector&lt; bool &gt; &amp;&#160;</td>
          <td class="paramname"><em>propagate_down</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;&#160;</td>
          <td class="paramname"><em>bottom</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Given the top blob error gradients, compute the bottom blob error gradients. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">top</td><td>the output blobs, whose diff fields store the gradient of the error with respect to themselves </td></tr>
    <tr><td class="paramname">propagate_down</td><td>a vector with equal length to bottom, with each index indicating whether to propagate the error gradients down to the bottom blob at the corresponding index </td></tr>
    <tr><td class="paramname">bottom</td><td>the input blobs, whose diff fields will store the gradient of the error with respect to themselves after Backward is run</td></tr>
  </table>
  </dd>
</dl>
<p>The Backward wrapper calls the relevant device wrapper function (Backward_cpu or Backward_gpu) to compute the bottom blob diffs given the top blob diffs.</p>
<p class="">Your layer should implement Backward_cpu and (optionally) Backward_gpu. </p>

</div>
</div>
<a id="a183d343f5183a4762307f2c5e6ed1e12"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a183d343f5183a4762307f2c5e6ed1e12">&#9670;&nbsp;</a></span>Backward() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Dtype &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcaffe_1_1_layer.html">caffe::Layer</a>&lt; Dtype &gt;::Backward </td>
          <td>(</td>
          <td class="paramtype">const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;&#160;</td>
          <td class="paramname"><em>top</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const vector&lt; bool &gt; &amp;&#160;</td>
          <td class="paramname"><em>propagate_down</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;&#160;</td>
          <td class="paramname"><em>bottom</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Given the top blob error gradients, compute the bottom blob error gradients. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">top</td><td>the output blobs, whose diff fields store the gradient of the error with respect to themselves </td></tr>
    <tr><td class="paramname">propagate_down</td><td>a vector with equal length to bottom, with each index indicating whether to propagate the error gradients down to the bottom blob at the corresponding index </td></tr>
    <tr><td class="paramname">bottom</td><td>the input blobs, whose diff fields will store the gradient of the error with respect to themselves after Backward is run</td></tr>
  </table>
  </dd>
</dl>
<p>The Backward wrapper calls the relevant device wrapper function (Backward_cpu or Backward_gpu) to compute the bottom blob diffs given the top blob diffs.</p>
<p class="">Your layer should implement Backward_cpu and (optionally) Backward_gpu. </p>

</div>
</div>
<a id="a55c8036130225fbc874a986bdf4b27e2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a55c8036130225fbc874a986bdf4b27e2">&#9670;&nbsp;</a></span>CheckBlobCounts() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Dtype&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual void <a class="el" href="classcaffe_1_1_layer.html">caffe::Layer</a>&lt; Dtype &gt;::CheckBlobCounts </td>
          <td>(</td>
          <td class="paramtype">const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;&#160;</td>
          <td class="paramname"><em>bottom</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;&#160;</td>
          <td class="paramname"><em>top</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">protected</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p class="">Called by the parent <a class="el" href="classcaffe_1_1_layer.html" title="An interface for the units of computation which can be composed into a Net. ">Layer</a>'s SetUp to check that the number of bottom and top Blobs provided as input match the expected numbers specified by the {ExactNum,Min,Max}{Bottom,Top}Blobs() functions. </p>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="classcaffe_1_1_layer_a55c8036130225fbc874a986bdf4b27e2_cgraph.png" border="0" usemap="#classcaffe_1_1_layer_a55c8036130225fbc874a986bdf4b27e2_cgraph" alt=""/></div>
<map name="classcaffe_1_1_layer_a55c8036130225fbc874a986bdf4b27e2_cgraph" id="classcaffe_1_1_layer_a55c8036130225fbc874a986bdf4b27e2_cgraph">
<area shape="rect" id="node2" href="classcaffe_1_1_layer.html#a8e5ee0494d85f5f55fc4396537cbc60f" title="Returns the exact number of bottom blobs required by the layer, or &#45;1 if no exact number is required..." alt="" coords="259,5,461,47"/>
<area shape="rect" id="node3" href="classcaffe_1_1_layer.html#a8952bff6bc4c2a96d8ea30d8ff65b198" title="Returns the layer type. " alt="" coords="298,71,422,98"/>
<area shape="rect" id="node4" href="classcaffe_1_1_layer.html#aca3cb2bafaefda5d4760aaebd0b72def" title="Returns the minimum number of bottom blobs required by the layer, or &#45;1 if no minimum number is requi..." alt="" coords="263,122,457,149"/>
<area shape="rect" id="node5" href="classcaffe_1_1_layer.html#af8bdc989053e0363ab032026b46de7c3" title="Returns the maximum number of bottom blobs required by the layer, or &#45;1 if no maximum number is requi..." alt="" coords="261,173,459,199"/>
<area shape="rect" id="node6" href="classcaffe_1_1_layer.html#a64e2ca72c719e4b2f1f9216ccfb0d37f" title="Returns the exact number of top blobs required by the layer, or &#45;1 if no exact number is required..." alt="" coords="269,224,451,265"/>
<area shape="rect" id="node7" href="classcaffe_1_1_layer.html#ab9e4c8d642e413948b131d851a8462a4" title="Returns the minimum number of top blobs required by the layer, or &#45;1 if no minimum number is required..." alt="" coords="273,290,447,317"/>
<area shape="rect" id="node8" href="classcaffe_1_1_layer.html#ac6c03df0b6e40e776c94001e19994a2e" title="Returns the maximum number of top blobs required by the layer, or &#45;1 if no maximum number is required..." alt="" coords="271,341,449,367"/>
<area shape="rect" id="node9" href="classcaffe_1_1_layer.html#af452a938bc7596f9b5e9900c8dc4ab3d" title="Returns true if the layer requires an equal number of bottom and top blobs. " alt="" coords="259,392,461,433"/>
</map>
</div>

</div>
</div>
<a id="a55c8036130225fbc874a986bdf4b27e2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a55c8036130225fbc874a986bdf4b27e2">&#9670;&nbsp;</a></span>CheckBlobCounts() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Dtype&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual void <a class="el" href="classcaffe_1_1_layer.html">caffe::Layer</a>&lt; Dtype &gt;::CheckBlobCounts </td>
          <td>(</td>
          <td class="paramtype">const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;&#160;</td>
          <td class="paramname"><em>bottom</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;&#160;</td>
          <td class="paramname"><em>top</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">protected</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p class="">Called by the parent <a class="el" href="classcaffe_1_1_layer.html" title="An interface for the units of computation which can be composed into a Net. ">Layer</a>'s SetUp to check that the number of bottom and top Blobs provided as input match the expected numbers specified by the {ExactNum,Min,Max}{Bottom,Top}Blobs() functions. </p>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="classcaffe_1_1_layer_a55c8036130225fbc874a986bdf4b27e2_cgraph.png" border="0" usemap="#classcaffe_1_1_layer_a55c8036130225fbc874a986bdf4b27e2_cgraph" alt=""/></div>
<map name="classcaffe_1_1_layer_a55c8036130225fbc874a986bdf4b27e2_cgraph" id="classcaffe_1_1_layer_a55c8036130225fbc874a986bdf4b27e2_cgraph">
<area shape="rect" id="node2" href="classcaffe_1_1_layer.html#a8e5ee0494d85f5f55fc4396537cbc60f" title="Returns the exact number of bottom blobs required by the layer, or &#45;1 if no exact number is required..." alt="" coords="259,5,461,47"/>
<area shape="rect" id="node3" href="classcaffe_1_1_layer.html#a8952bff6bc4c2a96d8ea30d8ff65b198" title="Returns the layer type. " alt="" coords="298,71,422,98"/>
<area shape="rect" id="node4" href="classcaffe_1_1_layer.html#aca3cb2bafaefda5d4760aaebd0b72def" title="Returns the minimum number of bottom blobs required by the layer, or &#45;1 if no minimum number is requi..." alt="" coords="263,122,457,149"/>
<area shape="rect" id="node5" href="classcaffe_1_1_layer.html#af8bdc989053e0363ab032026b46de7c3" title="Returns the maximum number of bottom blobs required by the layer, or &#45;1 if no maximum number is requi..." alt="" coords="261,173,459,199"/>
<area shape="rect" id="node6" href="classcaffe_1_1_layer.html#a64e2ca72c719e4b2f1f9216ccfb0d37f" title="Returns the exact number of top blobs required by the layer, or &#45;1 if no exact number is required..." alt="" coords="269,224,451,265"/>
<area shape="rect" id="node7" href="classcaffe_1_1_layer.html#ab9e4c8d642e413948b131d851a8462a4" title="Returns the minimum number of top blobs required by the layer, or &#45;1 if no minimum number is required..." alt="" coords="273,290,447,317"/>
<area shape="rect" id="node8" href="classcaffe_1_1_layer.html#ac6c03df0b6e40e776c94001e19994a2e" title="Returns the maximum number of top blobs required by the layer, or &#45;1 if no maximum number is required..." alt="" coords="271,341,449,367"/>
<area shape="rect" id="node9" href="classcaffe_1_1_layer.html#af452a938bc7596f9b5e9900c8dc4ab3d" title="Returns true if the layer requires an equal number of bottom and top blobs. " alt="" coords="259,392,461,433"/>
</map>
</div>
<div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="classcaffe_1_1_layer_a55c8036130225fbc874a986bdf4b27e2_icgraph.png" border="0" usemap="#classcaffe_1_1_layer_a55c8036130225fbc874a986bdf4b27e2_icgraph" alt=""/></div>
<map name="classcaffe_1_1_layer_a55c8036130225fbc874a986bdf4b27e2_icgraph" id="classcaffe_1_1_layer_a55c8036130225fbc874a986bdf4b27e2_icgraph">
<area shape="rect" id="node2" href="classcaffe_1_1_layer.html#a18d6bfdb535ab8e96a971dec4ae39a84" title="Implements common layer setup functionality. " alt="" coords="259,5,395,32"/>
</map>
</div>

</div>
</div>
<a id="af452a938bc7596f9b5e9900c8dc4ab3d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af452a938bc7596f9b5e9900c8dc4ab3d">&#9670;&nbsp;</a></span>EqualNumBottomTopBlobs() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Dtype&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual bool <a class="el" href="classcaffe_1_1_layer.html">caffe::Layer</a>&lt; Dtype &gt;::EqualNumBottomTopBlobs </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Returns true if the layer requires an equal number of bottom and top blobs. </p>
<p class="">This method should be overridden to return true if your layer expects an equal number of bottom and top blobs. </p>

<p>Reimplemented in <a class="el" href="classcaffe_1_1_base_convolution_layer.html#ad8e839460bf52abe3df2008b99a1810d">caffe::BaseConvolutionLayer&lt; Dtype &gt;</a>, and <a class="el" href="classcaffe_1_1_base_convolution_layer.html#ad8e839460bf52abe3df2008b99a1810d">caffe::BaseConvolutionLayer&lt; Dtype &gt;</a>.</p>
<div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="classcaffe_1_1_layer_af452a938bc7596f9b5e9900c8dc4ab3d_icgraph.png" border="0" usemap="#classcaffe_1_1_layer_af452a938bc7596f9b5e9900c8dc4ab3d_icgraph" alt=""/></div>
<map name="classcaffe_1_1_layer_af452a938bc7596f9b5e9900c8dc4ab3d_icgraph" id="classcaffe_1_1_layer_af452a938bc7596f9b5e9900c8dc4ab3d_icgraph">
<area shape="rect" id="node2" href="classcaffe_1_1_layer.html#a55c8036130225fbc874a986bdf4b27e2" title="caffe::Layer::CheckBlobCounts" alt="" coords="256,13,461,39"/>
<area shape="rect" id="node3" href="classcaffe_1_1_layer.html#a18d6bfdb535ab8e96a971dec4ae39a84" title="Implements common layer setup functionality. " alt="" coords="509,13,645,39"/>
</map>
</div>

</div>
</div>
<a id="af452a938bc7596f9b5e9900c8dc4ab3d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af452a938bc7596f9b5e9900c8dc4ab3d">&#9670;&nbsp;</a></span>EqualNumBottomTopBlobs() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Dtype&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual bool <a class="el" href="classcaffe_1_1_layer.html">caffe::Layer</a>&lt; Dtype &gt;::EqualNumBottomTopBlobs </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Returns true if the layer requires an equal number of bottom and top blobs. </p>
<p class="">This method should be overridden to return true if your layer expects an equal number of bottom and top blobs. </p>

<p>Reimplemented in <a class="el" href="classcaffe_1_1_base_convolution_layer.html#ad8e839460bf52abe3df2008b99a1810d">caffe::BaseConvolutionLayer&lt; Dtype &gt;</a>, and <a class="el" href="classcaffe_1_1_base_convolution_layer.html#ad8e839460bf52abe3df2008b99a1810d">caffe::BaseConvolutionLayer&lt; Dtype &gt;</a>.</p>

</div>
</div>
<a id="a8e5ee0494d85f5f55fc4396537cbc60f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8e5ee0494d85f5f55fc4396537cbc60f">&#9670;&nbsp;</a></span>ExactNumBottomBlobs() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Dtype&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual int <a class="el" href="classcaffe_1_1_layer.html">caffe::Layer</a>&lt; Dtype &gt;::ExactNumBottomBlobs </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Returns the exact number of bottom blobs required by the layer, or -1 if no exact number is required. </p>
<p class="">This method should be overridden to return a non-negative value if your layer expects some exact number of bottom blobs. </p>

<p>Reimplemented in <a class="el" href="classcaffe_1_1_l_s_t_m_unit_layer.html#a087f5f5b0e6c50d98e7a7d04aa35f1b9">caffe::LSTMUnitLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_l_s_t_m_unit_layer.html#a087f5f5b0e6c50d98e7a7d04aa35f1b9">caffe::LSTMUnitLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_infogain_loss_layer.html#aa03732f381764180748479c83b289869">caffe::InfogainLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_infogain_loss_layer.html#aa03732f381764180748479c83b289869">caffe::InfogainLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_weighted_euclidean_loss_layer.html#a2ac1ab6f657c6531dee37f80a971bbd9">caffe::WeightedEuclideanLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_weighted_euclidean_loss_layer.html#a2ac1ab6f657c6531dee37f80a971bbd9">caffe::WeightedEuclideanLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_batch_norm_layer.html#a5b87980f25eea544ebff916586c870e6">caffe::BatchNormLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_batch_norm_layer.html#a5b87980f25eea544ebff916586c870e6">caffe::BatchNormLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_arg_max_layer.html#a786fb4163cd0a31a564100ce7e4b74b2">caffe::ArgMaxLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_contrastive_loss_layer.html#aa6f3ad6918e64ffa1828e821accf25e9">caffe::ContrastiveLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_arg_max_layer.html#a786fb4163cd0a31a564100ce7e4b74b2">caffe::ArgMaxLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_contrastive_loss_layer.html#aa6f3ad6918e64ffa1828e821accf25e9">caffe::ContrastiveLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_accuracy_layer.html#afb0d3db8e4a18bec0e05d54d11453ef1">caffe::AccuracyLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_h_d_f5_output_layer.html#a92fb5561414d7e8b8845b0279b1ee847">caffe::HDF5OutputLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_accuracy_layer.html#afb0d3db8e4a18bec0e05d54d11453ef1">caffe::AccuracyLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_h_d_f5_output_layer.html#a92fb5561414d7e8b8845b0279b1ee847">caffe::HDF5OutputLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_h_d_f5_data_layer.html#a4eb72974cea32c84acb6b8012a0d326b">caffe::HDF5DataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_h_d_f5_data_layer.html#a4eb72974cea32c84acb6b8012a0d326b">caffe::HDF5DataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_window_data_layer.html#ac982c8170a7f899366321412a7bb91d7">caffe::WindowDataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_window_data_layer.html#ac982c8170a7f899366321412a7bb91d7">caffe::WindowDataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_abs_val_layer.html#acac806dbc6d3fa3dd7daae00caabd731">caffe::AbsValLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_l_r_n_layer.html#a32be44f9f361d29f05261bd174d92321">caffe::LRNLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_abs_val_layer.html#acac806dbc6d3fa3dd7daae00caabd731">caffe::AbsValLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_l_r_n_layer.html#a32be44f9f361d29f05261bd174d92321">caffe::LRNLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_image_data_layer.html#a6776c86faf14e35ae7be9848c7012aa5">caffe::ImageDataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_loss_layer.html#af1620064baefb711e2c767bdc92b6fb1">caffe::LossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_image_data_layer.html#a6776c86faf14e35ae7be9848c7012aa5">caffe::ImageDataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_loss_layer.html#af1620064baefb711e2c767bdc92b6fb1">caffe::LossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_crop_layer.html#ac6386917437ef54003bb7f8c2618f5fe">caffe::CropLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_flatten_layer.html#a0b0f583d8952d7cd45cbf4bae2a38548">caffe::FlattenLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_crop_layer.html#ac6386917437ef54003bb7f8c2618f5fe">caffe::CropLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_flatten_layer.html#a0b0f583d8952d7cd45cbf4bae2a38548">caffe::FlattenLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_dummy_data_layer.html#a73101a8ace6de2b179e36c13be17cb17">caffe::DummyDataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_embed_layer.html#a0634500a12e1d2299b7c8556976e4529">caffe::EmbedLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_im2col_layer.html#a35772d667af49afe707c7b1db881c573">caffe::Im2colLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_input_layer.html#ac4c1f2f0444a103727d793a6ae410e67">caffe::InputLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_reduction_layer.html#a64694af2e56723590072cac88bf825c7">caffe::ReductionLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_dummy_data_layer.html#a73101a8ace6de2b179e36c13be17cb17">caffe::DummyDataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_embed_layer.html#a0634500a12e1d2299b7c8556976e4529">caffe::EmbedLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_im2col_layer.html#a35772d667af49afe707c7b1db881c573">caffe::Im2colLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_input_layer.html#ac4c1f2f0444a103727d793a6ae410e67">caffe::InputLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_reduction_layer.html#a64694af2e56723590072cac88bf825c7">caffe::ReductionLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_batch_reindex_layer.html#a4120d2fd610655c7ad3d846637564bc6">caffe::BatchReindexLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_inner_product_layer.html#a5afdeb6b448b2f7d0637afa554381500">caffe::InnerProductLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_parameter_layer.html#a0acd33d14dd208c5a439940c50c6d3d3">caffe::ParameterLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_reshape_layer.html#ad97ea6043b01351e85b39b512ae0e489">caffe::ReshapeLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_slice_layer.html#abfc6e86b0b22c156ddc350168cd7757b">caffe::SliceLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_s_p_p_layer.html#a0fcc7996823cba1a468e82b3f9058ff0">caffe::SPPLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_batch_reindex_layer.html#a4120d2fd610655c7ad3d846637564bc6">caffe::BatchReindexLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_inner_product_layer.html#a5afdeb6b448b2f7d0637afa554381500">caffe::InnerProductLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_parameter_layer.html#a0acd33d14dd208c5a439940c50c6d3d3">caffe::ParameterLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_reshape_layer.html#ad97ea6043b01351e85b39b512ae0e489">caffe::ReshapeLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_slice_layer.html#abfc6e86b0b22c156ddc350168cd7757b">caffe::SliceLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_s_p_p_layer.html#a0fcc7996823cba1a468e82b3f9058ff0">caffe::SPPLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_memory_data_layer.html#a05a867526de7e0c6ec4851a97f52a47b">caffe::MemoryDataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_pooling_layer.html#a07dc8b1c3bfa3a997dd86b4e53f54019">caffe::PoolingLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_memory_data_layer.html#a05a867526de7e0c6ec4851a97f52a47b">caffe::MemoryDataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_pooling_layer.html#a07dc8b1c3bfa3a997dd86b4e53f54019">caffe::PoolingLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_split_layer.html#a8ff310ac37e1e79ce6ef8fbc95be0cd9">caffe::SplitLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_split_layer.html#a8ff310ac37e1e79ce6ef8fbc95be0cd9">caffe::SplitLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_m_v_n_layer.html#afd9b078a1bb48de9b91f3766edbbf058">caffe::MVNLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_neuron_layer.html#abb6c0e6acd2863baf47d6e6acda6f55f">caffe::NeuronLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_softmax_layer.html#afe44488dde78e6bcf6d4bdad97ee4986">caffe::SoftmaxLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_m_v_n_layer.html#afd9b078a1bb48de9b91f3766edbbf058">caffe::MVNLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_neuron_layer.html#abb6c0e6acd2863baf47d6e6acda6f55f">caffe::NeuronLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_softmax_layer.html#afe44488dde78e6bcf6d4bdad97ee4986">caffe::SoftmaxLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_data_layer.html#a2b6fa99ededf0863d8bab4a7a46addae">caffe::DataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_tile_layer.html#ac7e0da0e543f134e04b00d8625132b71">caffe::TileLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_data_layer.html#a2b6fa99ededf0863d8bab4a7a46addae">caffe::DataLayer&lt; Dtype &gt;</a>, and <a class="el" href="classcaffe_1_1_tile_layer.html#ac7e0da0e543f134e04b00d8625132b71">caffe::TileLayer&lt; Dtype &gt;</a>.</p>

</div>
</div>
<a id="a8e5ee0494d85f5f55fc4396537cbc60f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8e5ee0494d85f5f55fc4396537cbc60f">&#9670;&nbsp;</a></span>ExactNumBottomBlobs() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Dtype&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual int <a class="el" href="classcaffe_1_1_layer.html">caffe::Layer</a>&lt; Dtype &gt;::ExactNumBottomBlobs </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Returns the exact number of bottom blobs required by the layer, or -1 if no exact number is required. </p>
<p class="">This method should be overridden to return a non-negative value if your layer expects some exact number of bottom blobs. </p>

<p>Reimplemented in <a class="el" href="classcaffe_1_1_l_s_t_m_unit_layer.html#a087f5f5b0e6c50d98e7a7d04aa35f1b9">caffe::LSTMUnitLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_l_s_t_m_unit_layer.html#a087f5f5b0e6c50d98e7a7d04aa35f1b9">caffe::LSTMUnitLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_infogain_loss_layer.html#aa03732f381764180748479c83b289869">caffe::InfogainLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_infogain_loss_layer.html#aa03732f381764180748479c83b289869">caffe::InfogainLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_weighted_euclidean_loss_layer.html#a2ac1ab6f657c6531dee37f80a971bbd9">caffe::WeightedEuclideanLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_weighted_euclidean_loss_layer.html#a2ac1ab6f657c6531dee37f80a971bbd9">caffe::WeightedEuclideanLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_batch_norm_layer.html#a5b87980f25eea544ebff916586c870e6">caffe::BatchNormLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_batch_norm_layer.html#a5b87980f25eea544ebff916586c870e6">caffe::BatchNormLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_arg_max_layer.html#a786fb4163cd0a31a564100ce7e4b74b2">caffe::ArgMaxLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_contrastive_loss_layer.html#aa6f3ad6918e64ffa1828e821accf25e9">caffe::ContrastiveLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_arg_max_layer.html#a786fb4163cd0a31a564100ce7e4b74b2">caffe::ArgMaxLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_contrastive_loss_layer.html#aa6f3ad6918e64ffa1828e821accf25e9">caffe::ContrastiveLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_accuracy_layer.html#afb0d3db8e4a18bec0e05d54d11453ef1">caffe::AccuracyLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_h_d_f5_output_layer.html#a92fb5561414d7e8b8845b0279b1ee847">caffe::HDF5OutputLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_accuracy_layer.html#afb0d3db8e4a18bec0e05d54d11453ef1">caffe::AccuracyLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_h_d_f5_output_layer.html#a92fb5561414d7e8b8845b0279b1ee847">caffe::HDF5OutputLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_h_d_f5_data_layer.html#a4eb72974cea32c84acb6b8012a0d326b">caffe::HDF5DataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_h_d_f5_data_layer.html#a4eb72974cea32c84acb6b8012a0d326b">caffe::HDF5DataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_window_data_layer.html#ac982c8170a7f899366321412a7bb91d7">caffe::WindowDataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_window_data_layer.html#ac982c8170a7f899366321412a7bb91d7">caffe::WindowDataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_abs_val_layer.html#acac806dbc6d3fa3dd7daae00caabd731">caffe::AbsValLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_l_r_n_layer.html#a32be44f9f361d29f05261bd174d92321">caffe::LRNLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_abs_val_layer.html#acac806dbc6d3fa3dd7daae00caabd731">caffe::AbsValLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_l_r_n_layer.html#a32be44f9f361d29f05261bd174d92321">caffe::LRNLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_image_data_layer.html#a6776c86faf14e35ae7be9848c7012aa5">caffe::ImageDataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_loss_layer.html#af1620064baefb711e2c767bdc92b6fb1">caffe::LossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_image_data_layer.html#a6776c86faf14e35ae7be9848c7012aa5">caffe::ImageDataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_loss_layer.html#af1620064baefb711e2c767bdc92b6fb1">caffe::LossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_crop_layer.html#ac6386917437ef54003bb7f8c2618f5fe">caffe::CropLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_flatten_layer.html#a0b0f583d8952d7cd45cbf4bae2a38548">caffe::FlattenLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_crop_layer.html#ac6386917437ef54003bb7f8c2618f5fe">caffe::CropLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_flatten_layer.html#a0b0f583d8952d7cd45cbf4bae2a38548">caffe::FlattenLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_dummy_data_layer.html#a73101a8ace6de2b179e36c13be17cb17">caffe::DummyDataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_embed_layer.html#a0634500a12e1d2299b7c8556976e4529">caffe::EmbedLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_im2col_layer.html#a35772d667af49afe707c7b1db881c573">caffe::Im2colLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_input_layer.html#ac4c1f2f0444a103727d793a6ae410e67">caffe::InputLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_reduction_layer.html#a64694af2e56723590072cac88bf825c7">caffe::ReductionLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_dummy_data_layer.html#a73101a8ace6de2b179e36c13be17cb17">caffe::DummyDataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_embed_layer.html#a0634500a12e1d2299b7c8556976e4529">caffe::EmbedLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_im2col_layer.html#a35772d667af49afe707c7b1db881c573">caffe::Im2colLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_input_layer.html#ac4c1f2f0444a103727d793a6ae410e67">caffe::InputLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_reduction_layer.html#a64694af2e56723590072cac88bf825c7">caffe::ReductionLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_batch_reindex_layer.html#a4120d2fd610655c7ad3d846637564bc6">caffe::BatchReindexLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_inner_product_layer.html#a5afdeb6b448b2f7d0637afa554381500">caffe::InnerProductLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_parameter_layer.html#a0acd33d14dd208c5a439940c50c6d3d3">caffe::ParameterLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_reshape_layer.html#ad97ea6043b01351e85b39b512ae0e489">caffe::ReshapeLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_slice_layer.html#abfc6e86b0b22c156ddc350168cd7757b">caffe::SliceLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_s_p_p_layer.html#a0fcc7996823cba1a468e82b3f9058ff0">caffe::SPPLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_batch_reindex_layer.html#a4120d2fd610655c7ad3d846637564bc6">caffe::BatchReindexLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_inner_product_layer.html#a5afdeb6b448b2f7d0637afa554381500">caffe::InnerProductLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_parameter_layer.html#a0acd33d14dd208c5a439940c50c6d3d3">caffe::ParameterLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_reshape_layer.html#ad97ea6043b01351e85b39b512ae0e489">caffe::ReshapeLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_slice_layer.html#abfc6e86b0b22c156ddc350168cd7757b">caffe::SliceLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_s_p_p_layer.html#a0fcc7996823cba1a468e82b3f9058ff0">caffe::SPPLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_memory_data_layer.html#a05a867526de7e0c6ec4851a97f52a47b">caffe::MemoryDataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_pooling_layer.html#a07dc8b1c3bfa3a997dd86b4e53f54019">caffe::PoolingLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_memory_data_layer.html#a05a867526de7e0c6ec4851a97f52a47b">caffe::MemoryDataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_pooling_layer.html#a07dc8b1c3bfa3a997dd86b4e53f54019">caffe::PoolingLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_split_layer.html#a8ff310ac37e1e79ce6ef8fbc95be0cd9">caffe::SplitLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_split_layer.html#a8ff310ac37e1e79ce6ef8fbc95be0cd9">caffe::SplitLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_m_v_n_layer.html#afd9b078a1bb48de9b91f3766edbbf058">caffe::MVNLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_neuron_layer.html#abb6c0e6acd2863baf47d6e6acda6f55f">caffe::NeuronLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_softmax_layer.html#afe44488dde78e6bcf6d4bdad97ee4986">caffe::SoftmaxLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_m_v_n_layer.html#afd9b078a1bb48de9b91f3766edbbf058">caffe::MVNLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_neuron_layer.html#abb6c0e6acd2863baf47d6e6acda6f55f">caffe::NeuronLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_softmax_layer.html#afe44488dde78e6bcf6d4bdad97ee4986">caffe::SoftmaxLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_data_layer.html#a2b6fa99ededf0863d8bab4a7a46addae">caffe::DataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_tile_layer.html#ac7e0da0e543f134e04b00d8625132b71">caffe::TileLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_data_layer.html#a2b6fa99ededf0863d8bab4a7a46addae">caffe::DataLayer&lt; Dtype &gt;</a>, and <a class="el" href="classcaffe_1_1_tile_layer.html#ac7e0da0e543f134e04b00d8625132b71">caffe::TileLayer&lt; Dtype &gt;</a>.</p>
<div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="classcaffe_1_1_layer_a8e5ee0494d85f5f55fc4396537cbc60f_icgraph.png" border="0" usemap="#classcaffe_1_1_layer_a8e5ee0494d85f5f55fc4396537cbc60f_icgraph" alt=""/></div>
<map name="classcaffe_1_1_layer_a8e5ee0494d85f5f55fc4396537cbc60f_icgraph" id="classcaffe_1_1_layer_a8e5ee0494d85f5f55fc4396537cbc60f_icgraph">
<area shape="rect" id="node2" href="classcaffe_1_1_layer.html#a55c8036130225fbc874a986bdf4b27e2" title="caffe::Layer::CheckBlobCounts" alt="" coords="256,13,461,39"/>
<area shape="rect" id="node3" href="classcaffe_1_1_layer.html#a18d6bfdb535ab8e96a971dec4ae39a84" title="Implements common layer setup functionality. " alt="" coords="509,13,645,39"/>
</map>
</div>

</div>
</div>
<a id="a64e2ca72c719e4b2f1f9216ccfb0d37f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a64e2ca72c719e4b2f1f9216ccfb0d37f">&#9670;&nbsp;</a></span>ExactNumTopBlobs() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Dtype&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual int <a class="el" href="classcaffe_1_1_layer.html">caffe::Layer</a>&lt; Dtype &gt;::ExactNumTopBlobs </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Returns the exact number of top blobs required by the layer, or -1 if no exact number is required. </p>
<p class="">This method should be overridden to return a non-negative value if your layer expects some exact number of top blobs. </p>

<p>Reimplemented in <a class="el" href="classcaffe_1_1_l_s_t_m_unit_layer.html#a5f56fd304b6581697cbf309ebb8bc9b7">caffe::LSTMUnitLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_l_s_t_m_unit_layer.html#a5f56fd304b6581697cbf309ebb8bc9b7">caffe::LSTMUnitLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_infogain_loss_layer.html#aaf55e75f2296586b1fee0175e2d72fbb">caffe::InfogainLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_infogain_loss_layer.html#aaf55e75f2296586b1fee0175e2d72fbb">caffe::InfogainLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_softmax_with_loss_layer.html#a9035d000b2ce51a973f255a5eb2df8e3">caffe::SoftmaxWithLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_softmax_with_loss_layer.html#a9035d000b2ce51a973f255a5eb2df8e3">caffe::SoftmaxWithLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_batch_norm_layer.html#ab8575decdd0c5c42e24b9c3424f708ad">caffe::BatchNormLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_batch_norm_layer.html#ab8575decdd0c5c42e24b9c3424f708ad">caffe::BatchNormLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_arg_max_layer.html#a45e9c6e7b572b915be8731fcb6403695">caffe::ArgMaxLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_recurrent_layer.html#a4cb9032f0942c0fef5f6c7094c7b2ab8">caffe::RecurrentLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_arg_max_layer.html#a45e9c6e7b572b915be8731fcb6403695">caffe::ArgMaxLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_recurrent_layer.html#a4cb9032f0942c0fef5f6c7094c7b2ab8">caffe::RecurrentLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_loss_layer.html#aa5d5ab714a14082f5343dc9c49025b23">caffe::LossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_loss_layer.html#aa5d5ab714a14082f5343dc9c49025b23">caffe::LossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_scale_layer.html#aeffb8fcfc522f7365c23b0e6ae5c232e">caffe::ScaleLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_scale_layer.html#aeffb8fcfc522f7365c23b0e6ae5c232e">caffe::ScaleLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_h_d_f5_output_layer.html#ad11b8da0a6217a0f9a63789b360b1c99">caffe::HDF5OutputLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_h_d_f5_output_layer.html#ad11b8da0a6217a0f9a63789b360b1c99">caffe::HDF5OutputLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_window_data_layer.html#a7bd9264758f462b3392d2eedec8b1c99">caffe::WindowDataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_window_data_layer.html#a7bd9264758f462b3392d2eedec8b1c99">caffe::WindowDataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_abs_val_layer.html#aaf18bf4b77994475e8b55e5cefaa654a">caffe::AbsValLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_bias_layer.html#a9552dc137a5bcbdd17bdb3321d678595">caffe::BiasLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_l_r_n_layer.html#ac0ee88b119c38749c50e914521cdc148">caffe::LRNLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_abs_val_layer.html#aaf18bf4b77994475e8b55e5cefaa654a">caffe::AbsValLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_bias_layer.html#a9552dc137a5bcbdd17bdb3321d678595">caffe::BiasLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_l_r_n_layer.html#ac0ee88b119c38749c50e914521cdc148">caffe::LRNLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_image_data_layer.html#aa9182d46877b8514fca86e3588249567">caffe::ImageDataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_image_data_layer.html#aa9182d46877b8514fca86e3588249567">caffe::ImageDataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_crop_layer.html#a7e4a9aa634577308bc189adcf0ac22ed">caffe::CropLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_flatten_layer.html#a09d5ccd980598cce0472b3bd66316c08">caffe::FlattenLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_crop_layer.html#a7e4a9aa634577308bc189adcf0ac22ed">caffe::CropLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_flatten_layer.html#a09d5ccd980598cce0472b3bd66316c08">caffe::FlattenLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_embed_layer.html#af02f4561fa25a979e523aae851bed39d">caffe::EmbedLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_im2col_layer.html#ab2cf1f7dd41b801ed32471ec492d423c">caffe::Im2colLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_reduction_layer.html#a14224774af732030c5f1c8a3d79e1fc3">caffe::ReductionLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_embed_layer.html#af02f4561fa25a979e523aae851bed39d">caffe::EmbedLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_im2col_layer.html#ab2cf1f7dd41b801ed32471ec492d423c">caffe::Im2colLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_reduction_layer.html#a14224774af732030c5f1c8a3d79e1fc3">caffe::ReductionLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_batch_reindex_layer.html#a7d5c537334359c2a83cce489fb534342">caffe::BatchReindexLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_eltwise_layer.html#a60ae4a38cade1cc7f6111e51cabb441b">caffe::EltwiseLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_inner_product_layer.html#a652d8a5b07b72938a81f50305c1a8ee1">caffe::InnerProductLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_parameter_layer.html#aeb70ea5cec478f098259356690b01c9b">caffe::ParameterLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_reshape_layer.html#a3318c2404c6072ba07178b48d39ef0f5">caffe::ReshapeLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_s_p_p_layer.html#a345f640e6c1d3e9ee929d706b68300e9">caffe::SPPLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_batch_reindex_layer.html#a7d5c537334359c2a83cce489fb534342">caffe::BatchReindexLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_eltwise_layer.html#a60ae4a38cade1cc7f6111e51cabb441b">caffe::EltwiseLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_inner_product_layer.html#a652d8a5b07b72938a81f50305c1a8ee1">caffe::InnerProductLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_parameter_layer.html#aeb70ea5cec478f098259356690b01c9b">caffe::ParameterLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_reshape_layer.html#a3318c2404c6072ba07178b48d39ef0f5">caffe::ReshapeLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_s_p_p_layer.html#a345f640e6c1d3e9ee929d706b68300e9">caffe::SPPLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_memory_data_layer.html#af714b4cbc022be1592ad26c300b63ae4">caffe::MemoryDataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_memory_data_layer.html#af714b4cbc022be1592ad26c300b63ae4">caffe::MemoryDataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_concat_layer.html#a0f19a4cac8676927f9c83010957a2921">caffe::ConcatLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_concat_layer.html#a0f19a4cac8676927f9c83010957a2921">caffe::ConcatLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_m_v_n_layer.html#ae10d9ef135adf3cd25e86ce06188c814">caffe::MVNLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_neuron_layer.html#a47ac5e7208e4b14ad1e4040a621dbfbc">caffe::NeuronLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_softmax_layer.html#a6bc4748c20e0940e5367ed4d50f4a11b">caffe::SoftmaxLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_m_v_n_layer.html#ae10d9ef135adf3cd25e86ce06188c814">caffe::MVNLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_neuron_layer.html#a47ac5e7208e4b14ad1e4040a621dbfbc">caffe::NeuronLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_softmax_layer.html#a6bc4748c20e0940e5367ed4d50f4a11b">caffe::SoftmaxLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_silence_layer.html#a1e072cbda98dbc57001ce92432b045b8">caffe::SilenceLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_silence_layer.html#a1e072cbda98dbc57001ce92432b045b8">caffe::SilenceLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_tile_layer.html#a1040cc3b4fb028d54f67a685513d745b">caffe::TileLayer&lt; Dtype &gt;</a>, and <a class="el" href="classcaffe_1_1_tile_layer.html#a1040cc3b4fb028d54f67a685513d745b">caffe::TileLayer&lt; Dtype &gt;</a>.</p>

</div>
</div>
<a id="a64e2ca72c719e4b2f1f9216ccfb0d37f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a64e2ca72c719e4b2f1f9216ccfb0d37f">&#9670;&nbsp;</a></span>ExactNumTopBlobs() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Dtype&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual int <a class="el" href="classcaffe_1_1_layer.html">caffe::Layer</a>&lt; Dtype &gt;::ExactNumTopBlobs </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Returns the exact number of top blobs required by the layer, or -1 if no exact number is required. </p>
<p class="">This method should be overridden to return a non-negative value if your layer expects some exact number of top blobs. </p>

<p>Reimplemented in <a class="el" href="classcaffe_1_1_l_s_t_m_unit_layer.html#a5f56fd304b6581697cbf309ebb8bc9b7">caffe::LSTMUnitLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_l_s_t_m_unit_layer.html#a5f56fd304b6581697cbf309ebb8bc9b7">caffe::LSTMUnitLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_infogain_loss_layer.html#aaf55e75f2296586b1fee0175e2d72fbb">caffe::InfogainLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_infogain_loss_layer.html#aaf55e75f2296586b1fee0175e2d72fbb">caffe::InfogainLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_softmax_with_loss_layer.html#a9035d000b2ce51a973f255a5eb2df8e3">caffe::SoftmaxWithLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_softmax_with_loss_layer.html#a9035d000b2ce51a973f255a5eb2df8e3">caffe::SoftmaxWithLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_batch_norm_layer.html#ab8575decdd0c5c42e24b9c3424f708ad">caffe::BatchNormLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_batch_norm_layer.html#ab8575decdd0c5c42e24b9c3424f708ad">caffe::BatchNormLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_arg_max_layer.html#a45e9c6e7b572b915be8731fcb6403695">caffe::ArgMaxLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_recurrent_layer.html#a4cb9032f0942c0fef5f6c7094c7b2ab8">caffe::RecurrentLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_arg_max_layer.html#a45e9c6e7b572b915be8731fcb6403695">caffe::ArgMaxLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_recurrent_layer.html#a4cb9032f0942c0fef5f6c7094c7b2ab8">caffe::RecurrentLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_loss_layer.html#aa5d5ab714a14082f5343dc9c49025b23">caffe::LossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_loss_layer.html#aa5d5ab714a14082f5343dc9c49025b23">caffe::LossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_scale_layer.html#aeffb8fcfc522f7365c23b0e6ae5c232e">caffe::ScaleLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_scale_layer.html#aeffb8fcfc522f7365c23b0e6ae5c232e">caffe::ScaleLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_h_d_f5_output_layer.html#ad11b8da0a6217a0f9a63789b360b1c99">caffe::HDF5OutputLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_h_d_f5_output_layer.html#ad11b8da0a6217a0f9a63789b360b1c99">caffe::HDF5OutputLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_window_data_layer.html#a7bd9264758f462b3392d2eedec8b1c99">caffe::WindowDataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_window_data_layer.html#a7bd9264758f462b3392d2eedec8b1c99">caffe::WindowDataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_abs_val_layer.html#aaf18bf4b77994475e8b55e5cefaa654a">caffe::AbsValLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_bias_layer.html#a9552dc137a5bcbdd17bdb3321d678595">caffe::BiasLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_l_r_n_layer.html#ac0ee88b119c38749c50e914521cdc148">caffe::LRNLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_abs_val_layer.html#aaf18bf4b77994475e8b55e5cefaa654a">caffe::AbsValLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_bias_layer.html#a9552dc137a5bcbdd17bdb3321d678595">caffe::BiasLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_l_r_n_layer.html#ac0ee88b119c38749c50e914521cdc148">caffe::LRNLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_image_data_layer.html#aa9182d46877b8514fca86e3588249567">caffe::ImageDataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_image_data_layer.html#aa9182d46877b8514fca86e3588249567">caffe::ImageDataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_crop_layer.html#a7e4a9aa634577308bc189adcf0ac22ed">caffe::CropLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_flatten_layer.html#a09d5ccd980598cce0472b3bd66316c08">caffe::FlattenLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_crop_layer.html#a7e4a9aa634577308bc189adcf0ac22ed">caffe::CropLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_flatten_layer.html#a09d5ccd980598cce0472b3bd66316c08">caffe::FlattenLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_embed_layer.html#af02f4561fa25a979e523aae851bed39d">caffe::EmbedLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_im2col_layer.html#ab2cf1f7dd41b801ed32471ec492d423c">caffe::Im2colLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_reduction_layer.html#a14224774af732030c5f1c8a3d79e1fc3">caffe::ReductionLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_embed_layer.html#af02f4561fa25a979e523aae851bed39d">caffe::EmbedLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_im2col_layer.html#ab2cf1f7dd41b801ed32471ec492d423c">caffe::Im2colLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_reduction_layer.html#a14224774af732030c5f1c8a3d79e1fc3">caffe::ReductionLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_batch_reindex_layer.html#a7d5c537334359c2a83cce489fb534342">caffe::BatchReindexLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_eltwise_layer.html#a60ae4a38cade1cc7f6111e51cabb441b">caffe::EltwiseLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_inner_product_layer.html#a652d8a5b07b72938a81f50305c1a8ee1">caffe::InnerProductLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_parameter_layer.html#aeb70ea5cec478f098259356690b01c9b">caffe::ParameterLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_reshape_layer.html#a3318c2404c6072ba07178b48d39ef0f5">caffe::ReshapeLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_s_p_p_layer.html#a345f640e6c1d3e9ee929d706b68300e9">caffe::SPPLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_batch_reindex_layer.html#a7d5c537334359c2a83cce489fb534342">caffe::BatchReindexLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_eltwise_layer.html#a60ae4a38cade1cc7f6111e51cabb441b">caffe::EltwiseLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_inner_product_layer.html#a652d8a5b07b72938a81f50305c1a8ee1">caffe::InnerProductLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_parameter_layer.html#aeb70ea5cec478f098259356690b01c9b">caffe::ParameterLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_reshape_layer.html#a3318c2404c6072ba07178b48d39ef0f5">caffe::ReshapeLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_s_p_p_layer.html#a345f640e6c1d3e9ee929d706b68300e9">caffe::SPPLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_memory_data_layer.html#af714b4cbc022be1592ad26c300b63ae4">caffe::MemoryDataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_memory_data_layer.html#af714b4cbc022be1592ad26c300b63ae4">caffe::MemoryDataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_concat_layer.html#a0f19a4cac8676927f9c83010957a2921">caffe::ConcatLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_concat_layer.html#a0f19a4cac8676927f9c83010957a2921">caffe::ConcatLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_m_v_n_layer.html#ae10d9ef135adf3cd25e86ce06188c814">caffe::MVNLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_neuron_layer.html#a47ac5e7208e4b14ad1e4040a621dbfbc">caffe::NeuronLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_softmax_layer.html#a6bc4748c20e0940e5367ed4d50f4a11b">caffe::SoftmaxLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_m_v_n_layer.html#ae10d9ef135adf3cd25e86ce06188c814">caffe::MVNLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_neuron_layer.html#a47ac5e7208e4b14ad1e4040a621dbfbc">caffe::NeuronLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_softmax_layer.html#a6bc4748c20e0940e5367ed4d50f4a11b">caffe::SoftmaxLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_silence_layer.html#a1e072cbda98dbc57001ce92432b045b8">caffe::SilenceLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_silence_layer.html#a1e072cbda98dbc57001ce92432b045b8">caffe::SilenceLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_tile_layer.html#a1040cc3b4fb028d54f67a685513d745b">caffe::TileLayer&lt; Dtype &gt;</a>, and <a class="el" href="classcaffe_1_1_tile_layer.html#a1040cc3b4fb028d54f67a685513d745b">caffe::TileLayer&lt; Dtype &gt;</a>.</p>
<div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="classcaffe_1_1_layer_a64e2ca72c719e4b2f1f9216ccfb0d37f_icgraph.png" border="0" usemap="#classcaffe_1_1_layer_a64e2ca72c719e4b2f1f9216ccfb0d37f_icgraph" alt=""/></div>
<map name="classcaffe_1_1_layer_a64e2ca72c719e4b2f1f9216ccfb0d37f_icgraph" id="classcaffe_1_1_layer_a64e2ca72c719e4b2f1f9216ccfb0d37f_icgraph">
<area shape="rect" id="node2" href="classcaffe_1_1_layer.html#a55c8036130225fbc874a986bdf4b27e2" title="caffe::Layer::CheckBlobCounts" alt="" coords="236,5,441,32"/>
<area shape="rect" id="node4" href="classcaffe_1_1_net.html#ae9fcfaabc89165d6c0cb4b14b4c6b584" title="Initialize a network with a NetParameter. " alt="" coords="285,56,392,83"/>
<area shape="rect" id="node3" href="classcaffe_1_1_layer.html#a18d6bfdb535ab8e96a971dec4ae39a84" title="Implements common layer setup functionality. " alt="" coords="489,5,625,32"/>
</map>
</div>

</div>
</div>
<a id="ab57d272dabe8c709d2a785eebe72ca57"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab57d272dabe8c709d2a785eebe72ca57">&#9670;&nbsp;</a></span>Forward() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Dtype&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">Dtype <a class="el" href="classcaffe_1_1_layer.html">caffe::Layer</a>&lt; Dtype &gt;::Forward </td>
          <td>(</td>
          <td class="paramtype">const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;&#160;</td>
          <td class="paramname"><em>bottom</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;&#160;</td>
          <td class="paramname"><em>top</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Given the bottom blobs, compute the top blobs and the loss. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">bottom</td><td>the input blobs, whose data fields store the input data for this layer </td></tr>
    <tr><td class="paramname">top</td><td>the preshaped output blobs, whose data fields will store this layers' outputs </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The total loss from the layer.</dd></dl>
<p>The Forward wrapper calls the relevant device wrapper function (Forward_cpu or Forward_gpu) to compute the top blob values given the bottom blobs. If the layer has any non-zero loss_weights, the wrapper then computes and returns the loss.</p>
<p class="">Your layer should implement Forward_cpu and (optionally) Forward_gpu. </p>

</div>
</div>
<a id="ab57d272dabe8c709d2a785eebe72ca57"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab57d272dabe8c709d2a785eebe72ca57">&#9670;&nbsp;</a></span>Forward() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Dtype &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">Dtype <a class="el" href="classcaffe_1_1_layer.html">caffe::Layer</a>&lt; Dtype &gt;::Forward </td>
          <td>(</td>
          <td class="paramtype">const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;&#160;</td>
          <td class="paramname"><em>bottom</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;&#160;</td>
          <td class="paramname"><em>top</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Given the bottom blobs, compute the top blobs and the loss. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">bottom</td><td>the input blobs, whose data fields store the input data for this layer </td></tr>
    <tr><td class="paramname">top</td><td>the preshaped output blobs, whose data fields will store this layers' outputs </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The total loss from the layer.</dd></dl>
<p>The Forward wrapper calls the relevant device wrapper function (Forward_cpu or Forward_gpu) to compute the top blob values given the bottom blobs. If the layer has any non-zero loss_weights, the wrapper then computes and returns the loss.</p>
<p class="">Your layer should implement Forward_cpu and (optionally) Forward_gpu. </p>

</div>
</div>
<a id="a481323a3e0972c682787f2137468c29f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a481323a3e0972c682787f2137468c29f">&#9670;&nbsp;</a></span>LayerSetUp() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Dtype&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual void <a class="el" href="classcaffe_1_1_layer.html">caffe::Layer</a>&lt; Dtype &gt;::LayerSetUp </td>
          <td>(</td>
          <td class="paramtype">const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;&#160;</td>
          <td class="paramname"><em>bottom</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;&#160;</td>
          <td class="paramname"><em>top</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Does layer-specific setup: your layer should implement this function as well as Reshape. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">bottom</td><td>the preshaped input blobs, whose data fields store the input data for this layer </td></tr>
    <tr><td class="paramname">top</td><td>the allocated but unshaped output blobs</td></tr>
  </table>
  </dd>
</dl>
<p>This method should do one-time layer specific setup. This includes reading and processing relevent parameters from the <code>layer_param_</code>. Setting up the shapes of top blobs and internal buffers should be done in <code>Reshape</code>, which will be called before the forward pass to adjust the top blob sizes. </p>

<p>Reimplemented in <a class="el" href="classcaffe_1_1_base_prefetching_data_layer.html#ad3b7914abaa6d46c148864c0e28204ad">caffe::BasePrefetchingDataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_base_prefetching_data_layer.html#ad3b7914abaa6d46c148864c0e28204ad">caffe::BasePrefetchingDataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_softmax_with_loss_layer.html#a96cd04896d4b805fcaf36c2c6522ae10">caffe::SoftmaxWithLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_softmax_with_loss_layer.html#a2a3985570178431a4cc3f9b9fd4378c2">caffe::SoftmaxWithLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_infogain_loss_layer.html#a772be3f4074c72b3cf9214bda3422402">caffe::InfogainLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_infogain_loss_layer.html#ae59c01de80f22c87c1dd2ef87c6e6a2f">caffe::InfogainLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_sigmoid_cross_entropy_loss_layer.html#aa1535140dd4eb94557c3afc89076d56d">caffe::SigmoidCrossEntropyLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_sigmoid_cross_entropy_loss_layer.html#ac67af0cc1033db08d47a3f56aff5d600">caffe::SigmoidCrossEntropyLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_batch_norm_layer.html#a259d8b26c05450339b33ad024f356b6a">caffe::BatchNormLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_batch_norm_layer.html#a01e75b47ce076569ed09e08618c5be7c">caffe::BatchNormLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_contrastive_loss_layer.html#a943e67e7bb9c2362ec20ce44c777beac">caffe::ContrastiveLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_contrastive_loss_layer.html#a957623c05cb2289cd2ae9e9e93b48969">caffe::ContrastiveLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_arg_max_layer.html#a53069bd5efc4639de93a8111da772572">caffe::ArgMaxLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_arg_max_layer.html#a1251d1d407e8d15a83ba6807d013b97d">caffe::ArgMaxLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_dropout_layer.html#addcfd0822c1c5e3591bc7001a034b167">caffe::DropoutLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_p_re_l_u_layer.html#a85e7207b664a4db8eb718f2075f44920">caffe::PReLULayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_swish_layer.html#a35bd01fae515cb064107c621a3c12820">caffe::SwishLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_dropout_layer.html#aaf3f194d0e4936f7a657b61d7468d744">caffe::DropoutLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_p_re_l_u_layer.html#ae4e9910b4258f17531cfe0c2229a7857">caffe::PReLULayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_swish_layer.html#a04035cc9ca9be4b99aba41197b16f2e4">caffe::SwishLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_exp_layer.html#a45ec267bdfd48e8aa34490e146405b9e">caffe::ExpLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_log_layer.html#a87e062000908b474ac4cda3b2f3c6f1e">caffe::LogLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_exp_layer.html#ad482cfebeedd32e7b7d146106ece981a">caffe::ExpLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_log_layer.html#aa73d4cdfc38059902ffa2258d58e1dd4">caffe::LogLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_accuracy_layer.html#a1f2447583c670d92ff6e2c8d53fb4dd9">caffe::AccuracyLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_power_layer.html#a954ad3da9a5fd54665de1181b6165796">caffe::PowerLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_accuracy_layer.html#a894a1fcb58e8f822f9d875e1acae560c">caffe::AccuracyLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_power_layer.html#a0adeb5a6bdf1e5e437eaae801236fecc">caffe::PowerLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_recurrent_layer.html#a4eec13bfbe23b1e3eb2bbc4652bd6952">caffe::RecurrentLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_scale_layer.html#a9781f923f1ff0aad8549e0e93eebb941">caffe::ScaleLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_recurrent_layer.html#a8e4537f7dd87a9cce60096e8ab04e843">caffe::RecurrentLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_scale_layer.html#ae3c263f882a7552fe9e88b2d2827cb29">caffe::ScaleLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_abs_val_layer.html#a4ef25e7d0cbe06404948d7e763bf0f84">caffe::AbsValLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_h_d_f5_output_layer.html#aed2dea5250c86c46dd866fbb241dd9f6">caffe::HDF5OutputLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_threshold_layer.html#a14e3782a6bea7bba511f3d6f23344037">caffe::ThresholdLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_abs_val_layer.html#a5bc321f94f7d13e938e31131fc55487b">caffe::AbsValLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_h_d_f5_output_layer.html#afb7ab27b33e5eaec6c50893f28748c14">caffe::HDF5OutputLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_threshold_layer.html#a4902e90735cf20735343705014b4176f">caffe::ThresholdLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_h_d_f5_data_layer.html#afcd473ff34b4035122ba9119fc67498c">caffe::HDF5DataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_h_d_f5_data_layer.html#a7e7281a510b9d6713c3c79c6e50a199b">caffe::HDF5DataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_base_data_layer.html#a7028919adf87326b808a2c7b21e8e927">caffe::BaseDataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_loss_layer.html#aa6fc7c2e90be66f1c1f0683637c949da">caffe::LossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_l_r_n_layer.html#ac7ae4b839d952b785b9911c258bd5b48">caffe::LRNLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_base_data_layer.html#a72276185eb4e5495de2d0e0d34bc8eda">caffe::BaseDataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_loss_layer.html#a479314172e8fbe1485f59537c1fba222">caffe::LossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_l_r_n_layer.html#a4fa3b333b55b43e28534905bec151e09">caffe::LRNLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_bias_layer.html#aa62a9554bf4fc3eb4db124da0d89fd85">caffe::BiasLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_bias_layer.html#a2c9d072e5e641b247988f22be20520ea">caffe::BiasLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_crop_layer.html#a59dcb04b78d55f666b69ff001c90caa7">caffe::CropLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_crop_layer.html#ad4858525eae95a2526b11e20f46d6c3f">caffe::CropLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_embed_layer.html#aaace16d2beba7db887c7b59213268bc2">caffe::EmbedLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_im2col_layer.html#ac4d6f34378681fa197546468b5aa6fd6">caffe::Im2colLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_reduction_layer.html#aafe0aa825e019ea35225a8e493e4e919">caffe::ReductionLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_embed_layer.html#a1fecd89c503b59a952f80ff61d4253b3">caffe::EmbedLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_im2col_layer.html#a45f559e3d3841e15b8bcb39ec061cfcb">caffe::Im2colLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_reduction_layer.html#a5503c3dac40e2a92d8bfca77d0712dfb">caffe::ReductionLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_dummy_data_layer.html#a43b495bfead8d18bf1d8eaf7bf91e3e4">caffe::DummyDataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_eltwise_layer.html#a02516b6e7b1b0d032e586785687bcabc">caffe::EltwiseLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_filter_layer.html#a26a302fd9629af812e7d0714db79bb53">caffe::FilterLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_inner_product_layer.html#a4adc29913343ddec1813f3a899e449cc">caffe::InnerProductLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_input_layer.html#a58be7dd9b52c1a98a872300e5108e065">caffe::InputLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_reshape_layer.html#a99db2601ec64ff20880641b6f6429947">caffe::ReshapeLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_slice_layer.html#a92c1cdabdce4c92b9a4ee58e2ceb601e">caffe::SliceLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_s_p_p_layer.html#a7241f9c4dfba841bc76a93298a3d28ee">caffe::SPPLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_dummy_data_layer.html#a8bf93d8426b7053bd32de10cc6eb7207">caffe::DummyDataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_eltwise_layer.html#a31bdf9cf9a45105610a85cd82a96e0bf">caffe::EltwiseLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_filter_layer.html#a59443022ba473d248c63b5ab7a182826">caffe::FilterLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_inner_product_layer.html#a35643c908323b6341101db342e4e78ee">caffe::InnerProductLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_input_layer.html#ae430286efdf685b7bd816b3faea10f27">caffe::InputLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_reshape_layer.html#a5d832d4057a304791ecadd242f2c5a6e">caffe::ReshapeLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_slice_layer.html#a17b30448f94f43b480c5c6393341109b">caffe::SliceLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_s_p_p_layer.html#aceca092b11940864ae7033a2c0cfa8cc">caffe::SPPLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_base_convolution_layer.html#a422e1ef9e6c8b4574f7677bb125e234a">caffe::BaseConvolutionLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_pooling_layer.html#aa310fbe7d766ac96a1957aca6a3c4469">caffe::PoolingLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_base_convolution_layer.html#a1527055aae7f9b74a7a82f680957162c">caffe::BaseConvolutionLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_pooling_layer.html#a0b00d820b4aeb2f95cfecf3173aaa795">caffe::PoolingLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_concat_layer.html#af4fc13f4977f84a30af260096ffd55d2">caffe::ConcatLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_concat_layer.html#aa39bdc6829d06c8cc501554ecd166513">caffe::ConcatLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_python_layer.html#ae5baf7b7552ff0113c174b0e77db5f4c">caffe::PythonLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_python_layer.html#ae5baf7b7552ff0113c174b0e77db5f4c">caffe::PythonLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_parameter_layer.html#a1485ccdbd01513b89b29a79df7cda6ee">caffe::ParameterLayer&lt; Dtype &gt;</a>, and <a class="el" href="classcaffe_1_1_parameter_layer.html#a1485ccdbd01513b89b29a79df7cda6ee">caffe::ParameterLayer&lt; Dtype &gt;</a>.</p>
<div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="classcaffe_1_1_layer_a481323a3e0972c682787f2137468c29f_icgraph.png" border="0" usemap="#classcaffe_1_1_layer_a481323a3e0972c682787f2137468c29f_icgraph" alt=""/></div>
<map name="classcaffe_1_1_layer_a481323a3e0972c682787f2137468c29f_icgraph" id="classcaffe_1_1_layer_a481323a3e0972c682787f2137468c29f_icgraph">
<area shape="rect" id="node2" href="classcaffe_1_1_layer.html#a18d6bfdb535ab8e96a971dec4ae39a84" title="Implements common layer setup functionality. " alt="" coords="249,5,385,32"/>
<area shape="rect" id="node3" href="classcaffe_1_1_abs_val_layer.html#a4ef25e7d0cbe06404948d7e763bf0f84" title="Does layer&#45;specific setup: your layer should implement this function as well as Reshape. " alt="" coords="250,57,383,98"/>
<area shape="rect" id="node4" href="classcaffe_1_1_dropout_layer.html#addcfd0822c1c5e3591bc7001a034b167" title="Does layer&#45;specific setup: your layer should implement this function as well as Reshape. " alt="" coords="248,122,385,163"/>
<area shape="rect" id="node5" href="classcaffe_1_1_exp_layer.html#a45ec267bdfd48e8aa34490e146405b9e" title="Does layer&#45;specific setup: your layer should implement this function as well as Reshape. " alt="" coords="221,188,412,215"/>
<area shape="rect" id="node6" href="classcaffe_1_1_log_layer.html#a87e062000908b474ac4cda3b2f3c6f1e" title="Does layer&#45;specific setup: your layer should implement this function as well as Reshape. " alt="" coords="222,239,411,265"/>
<area shape="rect" id="node7" href="classcaffe_1_1_power_layer.html#a954ad3da9a5fd54665de1181b6165796" title="Does layer&#45;specific setup: your layer should implement this function as well as Reshape. " alt="" coords="249,290,385,331"/>
<area shape="rect" id="node8" href="classcaffe_1_1_swish_layer.html#a35bd01fae515cb064107c621a3c12820" title="Does layer&#45;specific setup: your layer should implement this function as well as Reshape. " alt="" coords="249,355,384,397"/>
<area shape="rect" id="node9" href="classcaffe_1_1_threshold_layer.html#a14e3782a6bea7bba511f3d6f23344037" title="Does layer&#45;specific setup: your layer should implement this function as well as Reshape. " alt="" coords="243,421,391,462"/>
</map>
</div>

</div>
</div>
<a id="a481323a3e0972c682787f2137468c29f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a481323a3e0972c682787f2137468c29f">&#9670;&nbsp;</a></span>LayerSetUp() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Dtype&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual void <a class="el" href="classcaffe_1_1_layer.html">caffe::Layer</a>&lt; Dtype &gt;::LayerSetUp </td>
          <td>(</td>
          <td class="paramtype">const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;&#160;</td>
          <td class="paramname"><em>bottom</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;&#160;</td>
          <td class="paramname"><em>top</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Does layer-specific setup: your layer should implement this function as well as Reshape. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">bottom</td><td>the preshaped input blobs, whose data fields store the input data for this layer </td></tr>
    <tr><td class="paramname">top</td><td>the allocated but unshaped output blobs</td></tr>
  </table>
  </dd>
</dl>
<p>This method should do one-time layer specific setup. This includes reading and processing relevent parameters from the <code>layer_param_</code>. Setting up the shapes of top blobs and internal buffers should be done in <code>Reshape</code>, which will be called before the forward pass to adjust the top blob sizes. </p>

<p>Reimplemented in <a class="el" href="classcaffe_1_1_base_prefetching_data_layer.html#ad3b7914abaa6d46c148864c0e28204ad">caffe::BasePrefetchingDataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_base_prefetching_data_layer.html#ad3b7914abaa6d46c148864c0e28204ad">caffe::BasePrefetchingDataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_softmax_with_loss_layer.html#a96cd04896d4b805fcaf36c2c6522ae10">caffe::SoftmaxWithLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_softmax_with_loss_layer.html#a2a3985570178431a4cc3f9b9fd4378c2">caffe::SoftmaxWithLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_infogain_loss_layer.html#a772be3f4074c72b3cf9214bda3422402">caffe::InfogainLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_infogain_loss_layer.html#ae59c01de80f22c87c1dd2ef87c6e6a2f">caffe::InfogainLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_sigmoid_cross_entropy_loss_layer.html#aa1535140dd4eb94557c3afc89076d56d">caffe::SigmoidCrossEntropyLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_sigmoid_cross_entropy_loss_layer.html#ac67af0cc1033db08d47a3f56aff5d600">caffe::SigmoidCrossEntropyLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_batch_norm_layer.html#a259d8b26c05450339b33ad024f356b6a">caffe::BatchNormLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_batch_norm_layer.html#a01e75b47ce076569ed09e08618c5be7c">caffe::BatchNormLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_contrastive_loss_layer.html#a943e67e7bb9c2362ec20ce44c777beac">caffe::ContrastiveLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_contrastive_loss_layer.html#a957623c05cb2289cd2ae9e9e93b48969">caffe::ContrastiveLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_arg_max_layer.html#a53069bd5efc4639de93a8111da772572">caffe::ArgMaxLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_arg_max_layer.html#a1251d1d407e8d15a83ba6807d013b97d">caffe::ArgMaxLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_dropout_layer.html#addcfd0822c1c5e3591bc7001a034b167">caffe::DropoutLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_p_re_l_u_layer.html#a85e7207b664a4db8eb718f2075f44920">caffe::PReLULayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_swish_layer.html#a35bd01fae515cb064107c621a3c12820">caffe::SwishLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_dropout_layer.html#aaf3f194d0e4936f7a657b61d7468d744">caffe::DropoutLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_p_re_l_u_layer.html#ae4e9910b4258f17531cfe0c2229a7857">caffe::PReLULayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_swish_layer.html#a04035cc9ca9be4b99aba41197b16f2e4">caffe::SwishLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_exp_layer.html#a45ec267bdfd48e8aa34490e146405b9e">caffe::ExpLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_log_layer.html#a87e062000908b474ac4cda3b2f3c6f1e">caffe::LogLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_exp_layer.html#ad482cfebeedd32e7b7d146106ece981a">caffe::ExpLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_log_layer.html#aa73d4cdfc38059902ffa2258d58e1dd4">caffe::LogLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_accuracy_layer.html#a1f2447583c670d92ff6e2c8d53fb4dd9">caffe::AccuracyLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_power_layer.html#a954ad3da9a5fd54665de1181b6165796">caffe::PowerLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_accuracy_layer.html#a894a1fcb58e8f822f9d875e1acae560c">caffe::AccuracyLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_power_layer.html#a0adeb5a6bdf1e5e437eaae801236fecc">caffe::PowerLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_recurrent_layer.html#a4eec13bfbe23b1e3eb2bbc4652bd6952">caffe::RecurrentLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_scale_layer.html#a9781f923f1ff0aad8549e0e93eebb941">caffe::ScaleLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_recurrent_layer.html#a8e4537f7dd87a9cce60096e8ab04e843">caffe::RecurrentLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_scale_layer.html#ae3c263f882a7552fe9e88b2d2827cb29">caffe::ScaleLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_abs_val_layer.html#a4ef25e7d0cbe06404948d7e763bf0f84">caffe::AbsValLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_h_d_f5_output_layer.html#aed2dea5250c86c46dd866fbb241dd9f6">caffe::HDF5OutputLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_threshold_layer.html#a14e3782a6bea7bba511f3d6f23344037">caffe::ThresholdLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_abs_val_layer.html#a5bc321f94f7d13e938e31131fc55487b">caffe::AbsValLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_h_d_f5_output_layer.html#afb7ab27b33e5eaec6c50893f28748c14">caffe::HDF5OutputLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_threshold_layer.html#a4902e90735cf20735343705014b4176f">caffe::ThresholdLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_h_d_f5_data_layer.html#afcd473ff34b4035122ba9119fc67498c">caffe::HDF5DataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_h_d_f5_data_layer.html#a7e7281a510b9d6713c3c79c6e50a199b">caffe::HDF5DataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_base_data_layer.html#a7028919adf87326b808a2c7b21e8e927">caffe::BaseDataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_loss_layer.html#aa6fc7c2e90be66f1c1f0683637c949da">caffe::LossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_l_r_n_layer.html#ac7ae4b839d952b785b9911c258bd5b48">caffe::LRNLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_base_data_layer.html#a72276185eb4e5495de2d0e0d34bc8eda">caffe::BaseDataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_loss_layer.html#a479314172e8fbe1485f59537c1fba222">caffe::LossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_l_r_n_layer.html#a4fa3b333b55b43e28534905bec151e09">caffe::LRNLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_bias_layer.html#aa62a9554bf4fc3eb4db124da0d89fd85">caffe::BiasLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_bias_layer.html#a2c9d072e5e641b247988f22be20520ea">caffe::BiasLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_crop_layer.html#a59dcb04b78d55f666b69ff001c90caa7">caffe::CropLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_crop_layer.html#ad4858525eae95a2526b11e20f46d6c3f">caffe::CropLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_embed_layer.html#aaace16d2beba7db887c7b59213268bc2">caffe::EmbedLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_im2col_layer.html#ac4d6f34378681fa197546468b5aa6fd6">caffe::Im2colLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_reduction_layer.html#aafe0aa825e019ea35225a8e493e4e919">caffe::ReductionLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_embed_layer.html#a1fecd89c503b59a952f80ff61d4253b3">caffe::EmbedLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_im2col_layer.html#a45f559e3d3841e15b8bcb39ec061cfcb">caffe::Im2colLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_reduction_layer.html#a5503c3dac40e2a92d8bfca77d0712dfb">caffe::ReductionLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_dummy_data_layer.html#a43b495bfead8d18bf1d8eaf7bf91e3e4">caffe::DummyDataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_eltwise_layer.html#a02516b6e7b1b0d032e586785687bcabc">caffe::EltwiseLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_filter_layer.html#a26a302fd9629af812e7d0714db79bb53">caffe::FilterLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_inner_product_layer.html#a4adc29913343ddec1813f3a899e449cc">caffe::InnerProductLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_input_layer.html#a58be7dd9b52c1a98a872300e5108e065">caffe::InputLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_reshape_layer.html#a99db2601ec64ff20880641b6f6429947">caffe::ReshapeLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_slice_layer.html#a92c1cdabdce4c92b9a4ee58e2ceb601e">caffe::SliceLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_s_p_p_layer.html#a7241f9c4dfba841bc76a93298a3d28ee">caffe::SPPLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_dummy_data_layer.html#a8bf93d8426b7053bd32de10cc6eb7207">caffe::DummyDataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_eltwise_layer.html#a31bdf9cf9a45105610a85cd82a96e0bf">caffe::EltwiseLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_filter_layer.html#a59443022ba473d248c63b5ab7a182826">caffe::FilterLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_inner_product_layer.html#a35643c908323b6341101db342e4e78ee">caffe::InnerProductLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_input_layer.html#ae430286efdf685b7bd816b3faea10f27">caffe::InputLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_reshape_layer.html#a5d832d4057a304791ecadd242f2c5a6e">caffe::ReshapeLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_slice_layer.html#a17b30448f94f43b480c5c6393341109b">caffe::SliceLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_s_p_p_layer.html#aceca092b11940864ae7033a2c0cfa8cc">caffe::SPPLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_base_convolution_layer.html#a422e1ef9e6c8b4574f7677bb125e234a">caffe::BaseConvolutionLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_pooling_layer.html#aa310fbe7d766ac96a1957aca6a3c4469">caffe::PoolingLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_base_convolution_layer.html#a1527055aae7f9b74a7a82f680957162c">caffe::BaseConvolutionLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_pooling_layer.html#a0b00d820b4aeb2f95cfecf3173aaa795">caffe::PoolingLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_concat_layer.html#af4fc13f4977f84a30af260096ffd55d2">caffe::ConcatLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_concat_layer.html#aa39bdc6829d06c8cc501554ecd166513">caffe::ConcatLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_python_layer.html#ae5baf7b7552ff0113c174b0e77db5f4c">caffe::PythonLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_python_layer.html#ae5baf7b7552ff0113c174b0e77db5f4c">caffe::PythonLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_parameter_layer.html#a1485ccdbd01513b89b29a79df7cda6ee">caffe::ParameterLayer&lt; Dtype &gt;</a>, and <a class="el" href="classcaffe_1_1_parameter_layer.html#a1485ccdbd01513b89b29a79df7cda6ee">caffe::ParameterLayer&lt; Dtype &gt;</a>.</p>

</div>
</div>
<a id="af8bdc989053e0363ab032026b46de7c3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af8bdc989053e0363ab032026b46de7c3">&#9670;&nbsp;</a></span>MaxBottomBlobs() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Dtype&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual int <a class="el" href="classcaffe_1_1_layer.html">caffe::Layer</a>&lt; Dtype &gt;::MaxBottomBlobs </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Returns the maximum number of bottom blobs required by the layer, or -1 if no maximum number is required. </p>
<p class="">This method should be overridden to return a non-negative value if your layer expects some maximum number of bottom blobs. </p>

<p>Reimplemented in <a class="el" href="classcaffe_1_1_infogain_loss_layer.html#a9b2372959a16da1e80ae7a98b7689a4c">caffe::InfogainLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_infogain_loss_layer.html#a9b2372959a16da1e80ae7a98b7689a4c">caffe::InfogainLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_recurrent_layer.html#a983e1ead91884f9d2049a3000254961c">caffe::RecurrentLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_recurrent_layer.html#a983e1ead91884f9d2049a3000254961c">caffe::RecurrentLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_scale_layer.html#a7867d035776f78fe486ce633ec0520ad">caffe::ScaleLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_scale_layer.html#a7867d035776f78fe486ce633ec0520ad">caffe::ScaleLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_bias_layer.html#abdb89e3bc940f999d1d4da83de90a97c">caffe::BiasLayer&lt; Dtype &gt;</a>, and <a class="el" href="classcaffe_1_1_bias_layer.html#abdb89e3bc940f999d1d4da83de90a97c">caffe::BiasLayer&lt; Dtype &gt;</a>.</p>

</div>
</div>
<a id="af8bdc989053e0363ab032026b46de7c3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af8bdc989053e0363ab032026b46de7c3">&#9670;&nbsp;</a></span>MaxBottomBlobs() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Dtype&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual int <a class="el" href="classcaffe_1_1_layer.html">caffe::Layer</a>&lt; Dtype &gt;::MaxBottomBlobs </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Returns the maximum number of bottom blobs required by the layer, or -1 if no maximum number is required. </p>
<p class="">This method should be overridden to return a non-negative value if your layer expects some maximum number of bottom blobs. </p>

<p>Reimplemented in <a class="el" href="classcaffe_1_1_infogain_loss_layer.html#a9b2372959a16da1e80ae7a98b7689a4c">caffe::InfogainLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_infogain_loss_layer.html#a9b2372959a16da1e80ae7a98b7689a4c">caffe::InfogainLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_recurrent_layer.html#a983e1ead91884f9d2049a3000254961c">caffe::RecurrentLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_recurrent_layer.html#a983e1ead91884f9d2049a3000254961c">caffe::RecurrentLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_scale_layer.html#a7867d035776f78fe486ce633ec0520ad">caffe::ScaleLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_scale_layer.html#a7867d035776f78fe486ce633ec0520ad">caffe::ScaleLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_bias_layer.html#abdb89e3bc940f999d1d4da83de90a97c">caffe::BiasLayer&lt; Dtype &gt;</a>, and <a class="el" href="classcaffe_1_1_bias_layer.html#abdb89e3bc940f999d1d4da83de90a97c">caffe::BiasLayer&lt; Dtype &gt;</a>.</p>
<div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="classcaffe_1_1_layer_af8bdc989053e0363ab032026b46de7c3_icgraph.png" border="0" usemap="#classcaffe_1_1_layer_af8bdc989053e0363ab032026b46de7c3_icgraph" alt=""/></div>
<map name="classcaffe_1_1_layer_af8bdc989053e0363ab032026b46de7c3_icgraph" id="classcaffe_1_1_layer_af8bdc989053e0363ab032026b46de7c3_icgraph">
<area shape="rect" id="node2" href="classcaffe_1_1_layer.html#a55c8036130225fbc874a986bdf4b27e2" title="caffe::Layer::CheckBlobCounts" alt="" coords="252,5,457,32"/>
<area shape="rect" id="node3" href="classcaffe_1_1_layer.html#a18d6bfdb535ab8e96a971dec4ae39a84" title="Implements common layer setup functionality. " alt="" coords="505,5,641,32"/>
</map>
</div>

</div>
</div>
<a id="ac6c03df0b6e40e776c94001e19994a2e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac6c03df0b6e40e776c94001e19994a2e">&#9670;&nbsp;</a></span>MaxTopBlobs() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Dtype&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual int <a class="el" href="classcaffe_1_1_layer.html">caffe::Layer</a>&lt; Dtype &gt;::MaxTopBlobs </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Returns the maximum number of top blobs required by the layer, or -1 if no maximum number is required. </p>
<p class="">This method should be overridden to return a non-negative value if your layer expects some maximum number of top blobs. </p>

<p>Reimplemented in <a class="el" href="classcaffe_1_1_infogain_loss_layer.html#a93019601c6256354fd4758da91d9311f">caffe::InfogainLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_infogain_loss_layer.html#a93019601c6256354fd4758da91d9311f">caffe::InfogainLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_softmax_with_loss_layer.html#a5a0b4c02fe76ae9087cd8b1b9edd9910">caffe::SoftmaxWithLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_softmax_with_loss_layer.html#a5a0b4c02fe76ae9087cd8b1b9edd9910">caffe::SoftmaxWithLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_accuracy_layer.html#a7591ae6d50dd7d96b91241b5b0368997">caffe::AccuracyLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_accuracy_layer.html#a7591ae6d50dd7d96b91241b5b0368997">caffe::AccuracyLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_pooling_layer.html#a76539d04ef7252c12e932ea703f8246b">caffe::PoolingLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_pooling_layer.html#a76539d04ef7252c12e932ea703f8246b">caffe::PoolingLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_data_layer.html#ac47e9f3bff3db9d7364f6c392427745c">caffe::DataLayer&lt; Dtype &gt;</a>, and <a class="el" href="classcaffe_1_1_data_layer.html#ac47e9f3bff3db9d7364f6c392427745c">caffe::DataLayer&lt; Dtype &gt;</a>.</p>
<div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="classcaffe_1_1_layer_ac6c03df0b6e40e776c94001e19994a2e_icgraph.png" border="0" usemap="#classcaffe_1_1_layer_ac6c03df0b6e40e776c94001e19994a2e_icgraph" alt=""/></div>
<map name="classcaffe_1_1_layer_ac6c03df0b6e40e776c94001e19994a2e_icgraph" id="classcaffe_1_1_layer_ac6c03df0b6e40e776c94001e19994a2e_icgraph">
<area shape="rect" id="node2" href="classcaffe_1_1_layer.html#a55c8036130225fbc874a986bdf4b27e2" title="caffe::Layer::CheckBlobCounts" alt="" coords="232,5,437,32"/>
<area shape="rect" id="node3" href="classcaffe_1_1_layer.html#a18d6bfdb535ab8e96a971dec4ae39a84" title="Implements common layer setup functionality. " alt="" coords="485,5,621,32"/>
</map>
</div>

</div>
</div>
<a id="ac6c03df0b6e40e776c94001e19994a2e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac6c03df0b6e40e776c94001e19994a2e">&#9670;&nbsp;</a></span>MaxTopBlobs() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Dtype&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual int <a class="el" href="classcaffe_1_1_layer.html">caffe::Layer</a>&lt; Dtype &gt;::MaxTopBlobs </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Returns the maximum number of top blobs required by the layer, or -1 if no maximum number is required. </p>
<p class="">This method should be overridden to return a non-negative value if your layer expects some maximum number of top blobs. </p>

<p>Reimplemented in <a class="el" href="classcaffe_1_1_infogain_loss_layer.html#a93019601c6256354fd4758da91d9311f">caffe::InfogainLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_infogain_loss_layer.html#a93019601c6256354fd4758da91d9311f">caffe::InfogainLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_softmax_with_loss_layer.html#a5a0b4c02fe76ae9087cd8b1b9edd9910">caffe::SoftmaxWithLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_softmax_with_loss_layer.html#a5a0b4c02fe76ae9087cd8b1b9edd9910">caffe::SoftmaxWithLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_accuracy_layer.html#a7591ae6d50dd7d96b91241b5b0368997">caffe::AccuracyLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_accuracy_layer.html#a7591ae6d50dd7d96b91241b5b0368997">caffe::AccuracyLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_pooling_layer.html#a76539d04ef7252c12e932ea703f8246b">caffe::PoolingLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_pooling_layer.html#a76539d04ef7252c12e932ea703f8246b">caffe::PoolingLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_data_layer.html#ac47e9f3bff3db9d7364f6c392427745c">caffe::DataLayer&lt; Dtype &gt;</a>, and <a class="el" href="classcaffe_1_1_data_layer.html#ac47e9f3bff3db9d7364f6c392427745c">caffe::DataLayer&lt; Dtype &gt;</a>.</p>

</div>
</div>
<a id="aca3cb2bafaefda5d4760aaebd0b72def"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aca3cb2bafaefda5d4760aaebd0b72def">&#9670;&nbsp;</a></span>MinBottomBlobs() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Dtype&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual int <a class="el" href="classcaffe_1_1_layer.html">caffe::Layer</a>&lt; Dtype &gt;::MinBottomBlobs </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Returns the minimum number of bottom blobs required by the layer, or -1 if no minimum number is required. </p>
<p class="">This method should be overridden to return a non-negative value if your layer expects some minimum number of bottom blobs. </p>

<p>Reimplemented in <a class="el" href="classcaffe_1_1_infogain_loss_layer.html#ad8a1ef702a695e379e5d0450369b4a0c">caffe::InfogainLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_infogain_loss_layer.html#ad8a1ef702a695e379e5d0450369b4a0c">caffe::InfogainLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_recurrent_layer.html#ac31b705bc02d333ae768f7c2184fbfae">caffe::RecurrentLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_scale_layer.html#a12c10840f0fc3327854864a12054beb2">caffe::ScaleLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_recurrent_layer.html#ac31b705bc02d333ae768f7c2184fbfae">caffe::RecurrentLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_scale_layer.html#a12c10840f0fc3327854864a12054beb2">caffe::ScaleLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_bias_layer.html#ab75a2e05bbb1eb37bed5995288143f67">caffe::BiasLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_bias_layer.html#ab75a2e05bbb1eb37bed5995288143f67">caffe::BiasLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_eltwise_layer.html#a802079d89e0f007c15b39e0c1fb0d275">caffe::EltwiseLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_filter_layer.html#af4c97961e859653ef0fa21d796af0259">caffe::FilterLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_eltwise_layer.html#a802079d89e0f007c15b39e0c1fb0d275">caffe::EltwiseLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_filter_layer.html#af4c97961e859653ef0fa21d796af0259">caffe::FilterLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_base_convolution_layer.html#aa3d861ed15f6e41c6257d6a10defa7eb">caffe::BaseConvolutionLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_concat_layer.html#a314de9eb00a296ffd3cf84120bd1601e">caffe::ConcatLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_base_convolution_layer.html#aa3d861ed15f6e41c6257d6a10defa7eb">caffe::BaseConvolutionLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_concat_layer.html#a314de9eb00a296ffd3cf84120bd1601e">caffe::ConcatLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_silence_layer.html#af916fa4138f5d8761ec4490588eeccd1">caffe::SilenceLayer&lt; Dtype &gt;</a>, and <a class="el" href="classcaffe_1_1_silence_layer.html#af916fa4138f5d8761ec4490588eeccd1">caffe::SilenceLayer&lt; Dtype &gt;</a>.</p>
<div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="classcaffe_1_1_layer_aca3cb2bafaefda5d4760aaebd0b72def_icgraph.png" border="0" usemap="#classcaffe_1_1_layer_aca3cb2bafaefda5d4760aaebd0b72def_icgraph" alt=""/></div>
<map name="classcaffe_1_1_layer_aca3cb2bafaefda5d4760aaebd0b72def_icgraph" id="classcaffe_1_1_layer_aca3cb2bafaefda5d4760aaebd0b72def_icgraph">
<area shape="rect" id="node2" href="classcaffe_1_1_layer.html#a55c8036130225fbc874a986bdf4b27e2" title="caffe::Layer::CheckBlobCounts" alt="" coords="248,5,453,32"/>
<area shape="rect" id="node3" href="classcaffe_1_1_layer.html#a18d6bfdb535ab8e96a971dec4ae39a84" title="Implements common layer setup functionality. " alt="" coords="501,5,637,32"/>
</map>
</div>

</div>
</div>
<a id="aca3cb2bafaefda5d4760aaebd0b72def"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aca3cb2bafaefda5d4760aaebd0b72def">&#9670;&nbsp;</a></span>MinBottomBlobs() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Dtype&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual int <a class="el" href="classcaffe_1_1_layer.html">caffe::Layer</a>&lt; Dtype &gt;::MinBottomBlobs </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Returns the minimum number of bottom blobs required by the layer, or -1 if no minimum number is required. </p>
<p class="">This method should be overridden to return a non-negative value if your layer expects some minimum number of bottom blobs. </p>

<p>Reimplemented in <a class="el" href="classcaffe_1_1_infogain_loss_layer.html#ad8a1ef702a695e379e5d0450369b4a0c">caffe::InfogainLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_infogain_loss_layer.html#ad8a1ef702a695e379e5d0450369b4a0c">caffe::InfogainLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_recurrent_layer.html#ac31b705bc02d333ae768f7c2184fbfae">caffe::RecurrentLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_scale_layer.html#a12c10840f0fc3327854864a12054beb2">caffe::ScaleLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_recurrent_layer.html#ac31b705bc02d333ae768f7c2184fbfae">caffe::RecurrentLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_scale_layer.html#a12c10840f0fc3327854864a12054beb2">caffe::ScaleLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_bias_layer.html#ab75a2e05bbb1eb37bed5995288143f67">caffe::BiasLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_bias_layer.html#ab75a2e05bbb1eb37bed5995288143f67">caffe::BiasLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_eltwise_layer.html#a802079d89e0f007c15b39e0c1fb0d275">caffe::EltwiseLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_filter_layer.html#af4c97961e859653ef0fa21d796af0259">caffe::FilterLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_eltwise_layer.html#a802079d89e0f007c15b39e0c1fb0d275">caffe::EltwiseLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_filter_layer.html#af4c97961e859653ef0fa21d796af0259">caffe::FilterLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_base_convolution_layer.html#aa3d861ed15f6e41c6257d6a10defa7eb">caffe::BaseConvolutionLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_concat_layer.html#a314de9eb00a296ffd3cf84120bd1601e">caffe::ConcatLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_base_convolution_layer.html#aa3d861ed15f6e41c6257d6a10defa7eb">caffe::BaseConvolutionLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_concat_layer.html#a314de9eb00a296ffd3cf84120bd1601e">caffe::ConcatLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_silence_layer.html#af916fa4138f5d8761ec4490588eeccd1">caffe::SilenceLayer&lt; Dtype &gt;</a>, and <a class="el" href="classcaffe_1_1_silence_layer.html#af916fa4138f5d8761ec4490588eeccd1">caffe::SilenceLayer&lt; Dtype &gt;</a>.</p>

</div>
</div>
<a id="ab9e4c8d642e413948b131d851a8462a4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab9e4c8d642e413948b131d851a8462a4">&#9670;&nbsp;</a></span>MinTopBlobs() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Dtype&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual int <a class="el" href="classcaffe_1_1_layer.html">caffe::Layer</a>&lt; Dtype &gt;::MinTopBlobs </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Returns the minimum number of top blobs required by the layer, or -1 if no minimum number is required. </p>
<p class="">This method should be overridden to return a non-negative value if your layer expects some minimum number of top blobs. </p>

<p>Reimplemented in <a class="el" href="classcaffe_1_1_infogain_loss_layer.html#a15c4916e5de27151eb745491d8d14d41">caffe::InfogainLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_infogain_loss_layer.html#a15c4916e5de27151eb745491d8d14d41">caffe::InfogainLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_softmax_with_loss_layer.html#a9969336702fb1bbf31750629fb38fb45">caffe::SoftmaxWithLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_softmax_with_loss_layer.html#a9969336702fb1bbf31750629fb38fb45">caffe::SoftmaxWithLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_accuracy_layer.html#a568dd59acff7a172fa614c88ac56aff7">caffe::AccuracyLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_accuracy_layer.html#a568dd59acff7a172fa614c88ac56aff7">caffe::AccuracyLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_h_d_f5_data_layer.html#a6833e081c29049b1392eb98fb4451697">caffe::HDF5DataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_h_d_f5_data_layer.html#a6833e081c29049b1392eb98fb4451697">caffe::HDF5DataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_dummy_data_layer.html#a2a63e36dd6b39287981d0bee466975aa">caffe::DummyDataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_input_layer.html#a5d0512129e9c2955dde297a2f15595d2">caffe::InputLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_dummy_data_layer.html#a2a63e36dd6b39287981d0bee466975aa">caffe::DummyDataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_input_layer.html#a5d0512129e9c2955dde297a2f15595d2">caffe::InputLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_filter_layer.html#af8c6eb9b1986e03dd14a907b5caa1324">caffe::FilterLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_slice_layer.html#a2673c06234a234362c1e2592880567a1">caffe::SliceLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_filter_layer.html#af8c6eb9b1986e03dd14a907b5caa1324">caffe::FilterLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_slice_layer.html#a2673c06234a234362c1e2592880567a1">caffe::SliceLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_pooling_layer.html#abb61ab67b2bd809c5633a2722b83feeb">caffe::PoolingLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_pooling_layer.html#abb61ab67b2bd809c5633a2722b83feeb">caffe::PoolingLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_base_convolution_layer.html#ae4092cf1b48e18e5d82cd714ae6e8547">caffe::BaseConvolutionLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_split_layer.html#a48dafac272f2f098798e3caa09afbabe">caffe::SplitLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_base_convolution_layer.html#ae4092cf1b48e18e5d82cd714ae6e8547">caffe::BaseConvolutionLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_split_layer.html#a48dafac272f2f098798e3caa09afbabe">caffe::SplitLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_data_layer.html#ab0c5a7504085a6699272cdcfa8611887">caffe::DataLayer&lt; Dtype &gt;</a>, and <a class="el" href="classcaffe_1_1_data_layer.html#ab0c5a7504085a6699272cdcfa8611887">caffe::DataLayer&lt; Dtype &gt;</a>.</p>

</div>
</div>
<a id="ab9e4c8d642e413948b131d851a8462a4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab9e4c8d642e413948b131d851a8462a4">&#9670;&nbsp;</a></span>MinTopBlobs() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Dtype&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual int <a class="el" href="classcaffe_1_1_layer.html">caffe::Layer</a>&lt; Dtype &gt;::MinTopBlobs </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Returns the minimum number of top blobs required by the layer, or -1 if no minimum number is required. </p>
<p class="">This method should be overridden to return a non-negative value if your layer expects some minimum number of top blobs. </p>

<p>Reimplemented in <a class="el" href="classcaffe_1_1_infogain_loss_layer.html#a15c4916e5de27151eb745491d8d14d41">caffe::InfogainLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_infogain_loss_layer.html#a15c4916e5de27151eb745491d8d14d41">caffe::InfogainLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_softmax_with_loss_layer.html#a9969336702fb1bbf31750629fb38fb45">caffe::SoftmaxWithLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_softmax_with_loss_layer.html#a9969336702fb1bbf31750629fb38fb45">caffe::SoftmaxWithLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_accuracy_layer.html#a568dd59acff7a172fa614c88ac56aff7">caffe::AccuracyLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_accuracy_layer.html#a568dd59acff7a172fa614c88ac56aff7">caffe::AccuracyLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_h_d_f5_data_layer.html#a6833e081c29049b1392eb98fb4451697">caffe::HDF5DataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_h_d_f5_data_layer.html#a6833e081c29049b1392eb98fb4451697">caffe::HDF5DataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_dummy_data_layer.html#a2a63e36dd6b39287981d0bee466975aa">caffe::DummyDataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_input_layer.html#a5d0512129e9c2955dde297a2f15595d2">caffe::InputLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_dummy_data_layer.html#a2a63e36dd6b39287981d0bee466975aa">caffe::DummyDataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_input_layer.html#a5d0512129e9c2955dde297a2f15595d2">caffe::InputLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_filter_layer.html#af8c6eb9b1986e03dd14a907b5caa1324">caffe::FilterLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_slice_layer.html#a2673c06234a234362c1e2592880567a1">caffe::SliceLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_filter_layer.html#af8c6eb9b1986e03dd14a907b5caa1324">caffe::FilterLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_slice_layer.html#a2673c06234a234362c1e2592880567a1">caffe::SliceLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_pooling_layer.html#abb61ab67b2bd809c5633a2722b83feeb">caffe::PoolingLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_pooling_layer.html#abb61ab67b2bd809c5633a2722b83feeb">caffe::PoolingLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_base_convolution_layer.html#ae4092cf1b48e18e5d82cd714ae6e8547">caffe::BaseConvolutionLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_split_layer.html#a48dafac272f2f098798e3caa09afbabe">caffe::SplitLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_base_convolution_layer.html#ae4092cf1b48e18e5d82cd714ae6e8547">caffe::BaseConvolutionLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_split_layer.html#a48dafac272f2f098798e3caa09afbabe">caffe::SplitLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_data_layer.html#ab0c5a7504085a6699272cdcfa8611887">caffe::DataLayer&lt; Dtype &gt;</a>, and <a class="el" href="classcaffe_1_1_data_layer.html#ab0c5a7504085a6699272cdcfa8611887">caffe::DataLayer&lt; Dtype &gt;</a>.</p>
<div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="classcaffe_1_1_layer_ab9e4c8d642e413948b131d851a8462a4_icgraph.png" border="0" usemap="#classcaffe_1_1_layer_ab9e4c8d642e413948b131d851a8462a4_icgraph" alt=""/></div>
<map name="classcaffe_1_1_layer_ab9e4c8d642e413948b131d851a8462a4_icgraph" id="classcaffe_1_1_layer_ab9e4c8d642e413948b131d851a8462a4_icgraph">
<area shape="rect" id="node2" href="classcaffe_1_1_layer.html#a55c8036130225fbc874a986bdf4b27e2" title="caffe::Layer::CheckBlobCounts" alt="" coords="228,5,433,32"/>
<area shape="rect" id="node4" href="classcaffe_1_1_net.html#ae9fcfaabc89165d6c0cb4b14b4c6b584" title="Initialize a network with a NetParameter. " alt="" coords="277,56,384,83"/>
<area shape="rect" id="node3" href="classcaffe_1_1_layer.html#a18d6bfdb535ab8e96a971dec4ae39a84" title="Implements common layer setup functionality. " alt="" coords="481,5,617,32"/>
</map>
</div>

</div>
</div>
<a id="a1a3708013b0231e71d725252e10ce6e3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1a3708013b0231e71d725252e10ce6e3">&#9670;&nbsp;</a></span>param_propagate_down() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Dtype&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">bool <a class="el" href="classcaffe_1_1_layer.html">caffe::Layer</a>&lt; Dtype &gt;::param_propagate_down </td>
          <td>(</td>
          <td class="paramtype">const int&#160;</td>
          <td class="paramname"><em>param_id</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Specifies whether the layer should compute gradients w.r.t. a parameter at a particular index given by param_id. </p>
<p class="">You can safely ignore false values and always compute gradients for all parameters, but possibly with wasteful computation. </p>

</div>
</div>
<a id="a1a3708013b0231e71d725252e10ce6e3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1a3708013b0231e71d725252e10ce6e3">&#9670;&nbsp;</a></span>param_propagate_down() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Dtype&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">bool <a class="el" href="classcaffe_1_1_layer.html">caffe::Layer</a>&lt; Dtype &gt;::param_propagate_down </td>
          <td>(</td>
          <td class="paramtype">const int&#160;</td>
          <td class="paramname"><em>param_id</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Specifies whether the layer should compute gradients w.r.t. a parameter at a particular index given by param_id. </p>
<p class="">You can safely ignore false values and always compute gradients for all parameters, but possibly with wasteful computation. </p>

</div>
</div>
<a id="a7fe981e8af8d93d587acf2a952be563d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7fe981e8af8d93d587acf2a952be563d">&#9670;&nbsp;</a></span>Reshape() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Dtype&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual void <a class="el" href="classcaffe_1_1_layer.html">caffe::Layer</a>&lt; Dtype &gt;::Reshape </td>
          <td>(</td>
          <td class="paramtype">const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;&#160;</td>
          <td class="paramname"><em>bottom</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;&#160;</td>
          <td class="paramname"><em>top</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Adjust the shapes of top blobs and internal buffers to accommodate the shapes of the bottom blobs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">bottom</td><td>the input blobs, with the requested input shapes </td></tr>
    <tr><td class="paramname">top</td><td>the top blobs, which should be reshaped as needed</td></tr>
  </table>
  </dd>
</dl>
<p>This method should reshape top blobs as needed according to the shapes of the bottom (input) blobs, as well as reshaping any internal buffers and making any other necessary adjustments so that the layer can accommodate the bottom blobs. </p>

<p>Implemented in <a class="el" href="classcaffe_1_1_l_s_t_m_unit_layer.html#a795bd455f4635e876de32323e9cee96d">caffe::LSTMUnitLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_l_s_t_m_unit_layer.html#aa6b2edc73f84705744f9f17ad2d014bb">caffe::LSTMUnitLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_softmax_with_loss_layer.html#a2821b89b0f46a5e2ddaccb2708ab237b">caffe::SoftmaxWithLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_softmax_with_loss_layer.html#ad8f5d429254deaebe4ea5f14bfa0d4d0">caffe::SoftmaxWithLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_infogain_loss_layer.html#a83ed478450bc7f629499fed37f654c5c">caffe::InfogainLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_infogain_loss_layer.html#aa2903026b3886816270deb038a463759">caffe::InfogainLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_sigmoid_cross_entropy_loss_layer.html#a305423abeea4bd1652ff7e696aaba808">caffe::SigmoidCrossEntropyLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_sigmoid_cross_entropy_loss_layer.html#a4199eb0668451022f8da20ebca129eb3">caffe::SigmoidCrossEntropyLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_multinomial_logistic_loss_layer.html#a979be47987712c02dfb57a88b2a69f11">caffe::MultinomialLogisticLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_weighted_euclidean_loss_layer.html#a98e3de49ab49d66b8e3ebfe3aa4fbe20">caffe::WeightedEuclideanLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_multinomial_logistic_loss_layer.html#afd5162d1fc8be1a4abdf1afaa96519f8">caffe::MultinomialLogisticLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_weighted_euclidean_loss_layer.html#ac9b915b132fb539ffdd610992c507974">caffe::WeightedEuclideanLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_batch_norm_layer.html#a1acd542fe8fe89d88db9050d048fc7d2">caffe::BatchNormLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_batch_norm_layer.html#ab5cc20592aaa28fb2c41fabe842da3fc">caffe::BatchNormLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_euclidean_loss_layer.html#a9cbe90ea0130c31bd5b9419a1bbaa555">caffe::EuclideanLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_euclidean_loss_layer.html#ab7f1b879898ffba67cf5035f6a56d8eb">caffe::EuclideanLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_arg_max_layer.html#a291a2c548c28e7ab02ddac0cfd3cbdad">caffe::ArgMaxLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_arg_max_layer.html#a658393ef566ec585bf540a1b6f31a929">caffe::ArgMaxLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_p_re_l_u_layer.html#a50ad2070e060093556d1fc12f31e33b1">caffe::PReLULayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_p_re_l_u_layer.html#a923c7c14b470ff84a9b8ee4a93395b5d">caffe::PReLULayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_dropout_layer.html#a8ddbd583b7430f228506954910935505">caffe::DropoutLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_swish_layer.html#a995afbac7e3adc0bfe157b0458656a9e">caffe::SwishLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_dropout_layer.html#a93f66d83b510987fe37a42d14e6ff98a">caffe::DropoutLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_swish_layer.html#aecf840a1202549b60742eb11a2f188ee">caffe::SwishLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_accuracy_layer.html#aa2b680fc1e754440c2babd150e09f2f6">caffe::AccuracyLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_accuracy_layer.html#a1a42bc91c233a9f803482bff30163f36">caffe::AccuracyLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_base_data_layer.html#a2955d06a5e67609582fb293a0a37673f">caffe::BaseDataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_h_d_f5_output_layer.html#afaed17dc14251e627764334d54e55c4d">caffe::HDF5OutputLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_python_layer.html#aa6597e54cd5fea5b5c7b67299b74a72c">caffe::PythonLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_recurrent_layer.html#aba6011a9cbb18e38a8596aa5dbb44723">caffe::RecurrentLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_scale_layer.html#aeafe805a68903bae9a7f2b98bf453e22">caffe::ScaleLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_base_data_layer.html#a2955d06a5e67609582fb293a0a37673f">caffe::BaseDataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_h_d_f5_output_layer.html#afaed17dc14251e627764334d54e55c4d">caffe::HDF5OutputLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_python_layer.html#aa6597e54cd5fea5b5c7b67299b74a72c">caffe::PythonLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_recurrent_layer.html#aea7d9f8a75896b5bff438c6cdc966b6b">caffe::RecurrentLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_scale_layer.html#a40101bfc91fea909fdc9047c3618d07d">caffe::ScaleLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_h_d_f5_data_layer.html#a38b8924648ba4ab2933fe389fa608cad">caffe::HDF5DataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_h_d_f5_data_layer.html#a38b8924648ba4ab2933fe389fa608cad">caffe::HDF5DataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_loss_layer.html#abf00412194f5413ea9468ee44b0d986f">caffe::LossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_l_r_n_layer.html#aa002dacb2f69d2b500227f938a957a81">caffe::LRNLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_loss_layer.html#a1324e1bd42d84a6eb7e2c559d2da9ecc">caffe::LossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_l_r_n_layer.html#a5dd9938f40f479d6fd1de59becd09bdf">caffe::LRNLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_bias_layer.html#aff9bd5f76055189c5ec66f43faf17660">caffe::BiasLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_bias_layer.html#a00ab608f300c4fa94d75b15ab9e0c599">caffe::BiasLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_crop_layer.html#a195d2e437a70b0139411c1dd22b08120">caffe::CropLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_flatten_layer.html#a3b459231a94176753d0cb1ae94bc942f">caffe::FlattenLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_crop_layer.html#a71fca33b7fb554973d6e7cc39affd8da">caffe::CropLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_flatten_layer.html#a87b5836343017586d5aa928797c4b92a">caffe::FlattenLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_dummy_data_layer.html#ae72f2ea80339981bf925f0291f62d527">caffe::DummyDataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_embed_layer.html#ac7c19a708d491f9fe161c78348ec794b">caffe::EmbedLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_im2col_layer.html#a119c9e1965e219be1ccb719821d4542f">caffe::Im2colLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_input_layer.html#a4c2028f829734a202263725d8aa41152">caffe::InputLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_parameter_layer.html#acc7cf7e2dea7e254717b13980fdf6c1a">caffe::ParameterLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_reduction_layer.html#a0f6594ec41a0556e9fcfb9af0ae86c8a">caffe::ReductionLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_dummy_data_layer.html#ae72f2ea80339981bf925f0291f62d527">caffe::DummyDataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_embed_layer.html#ab388111d4ccdbcf081030ccd2e258f69">caffe::EmbedLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_im2col_layer.html#a18fcf2571b0c73b6dd828a7fc7caf5e6">caffe::Im2colLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_input_layer.html#a4c2028f829734a202263725d8aa41152">caffe::InputLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_parameter_layer.html#acc7cf7e2dea7e254717b13980fdf6c1a">caffe::ParameterLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_reduction_layer.html#ad830b3c52fb34555e45cd172a8b27ed9">caffe::ReductionLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_batch_reindex_layer.html#a7f69b6b19387959bf0926dde7a7922a4">caffe::BatchReindexLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_eltwise_layer.html#a17b4cb0842a154224bab9733e77e07b9">caffe::EltwiseLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_filter_layer.html#ade673aa44e466adbe3aa79531a7c7484">caffe::FilterLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_inner_product_layer.html#a1c823624ec9286477db7caa5188152b8">caffe::InnerProductLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_reshape_layer.html#a5b85ce44e23b4f958a60ff2b2c43e61f">caffe::ReshapeLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_slice_layer.html#af9fa49d54abf1cb090cfc772eb4acc4d">caffe::SliceLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_s_p_p_layer.html#a3ba65e459c1bde4f772d545efb43a2f2">caffe::SPPLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_batch_reindex_layer.html#a7fac1505092f43372ed39a99a1405d4b">caffe::BatchReindexLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_eltwise_layer.html#a3f9e26946868f6249af1d4f57fc8259f">caffe::EltwiseLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_filter_layer.html#aea626ef6cdd51ca2ede31319daab2d1b">caffe::FilterLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_inner_product_layer.html#a12915397170ea81ccc0bce177897d4ba">caffe::InnerProductLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_reshape_layer.html#ab071d750b8cef391e9fe0c67efaa4994">caffe::ReshapeLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_slice_layer.html#ac6fce397efbab95848f56be7b4f6a786">caffe::SliceLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_s_p_p_layer.html#ab23015d8d27fccab684de17b7c6d4e28">caffe::SPPLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_base_convolution_layer.html#aa215338f200c832081f2719a54bc5256">caffe::BaseConvolutionLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_pooling_layer.html#ac652e08deffb0eeb6c3113abb55eb641">caffe::PoolingLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_base_convolution_layer.html#af384650d31552ea10b1a030788cb52d8">caffe::BaseConvolutionLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_pooling_layer.html#ad8ab4e6541bc0954146d62781aeb1af8">caffe::PoolingLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_concat_layer.html#a3c7cbd500d3a15cfbdbf33479c4fb228">caffe::ConcatLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_neuron_layer.html#a6d0facf4a5e6f459cf1cb8b28d945790">caffe::NeuronLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_split_layer.html#a4e978965461dedcc2fbb905e4910c0b1">caffe::SplitLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_concat_layer.html#af210770b1c8bbce8fc34340ba94f9f75">caffe::ConcatLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_neuron_layer.html#a2c87bff832b685db76a41cbc8539e7ce">caffe::NeuronLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_split_layer.html#a1064977331e5bfcf5d75590d14986e1f">caffe::SplitLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_m_v_n_layer.html#a48aafabe729bb3b22171cfdbda6e6073">caffe::MVNLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_softmax_layer.html#a756fd5ad3af07d019b5f2247f38b4496">caffe::SoftmaxLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_m_v_n_layer.html#afcb6c5f28b45496eed1b0ea19705b763">caffe::MVNLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_softmax_layer.html#a503694b3161839de7c19d7d0af2cecc2">caffe::SoftmaxLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_silence_layer.html#a96a47a49a103e60a681f97eff7bf42f2">caffe::SilenceLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_silence_layer.html#a96a47a49a103e60a681f97eff7bf42f2">caffe::SilenceLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_tile_layer.html#a593f5b8342f1b092633d2a1f7e4a6843">caffe::TileLayer&lt; Dtype &gt;</a>, and <a class="el" href="classcaffe_1_1_tile_layer.html#a1fe845a1597dbc119e922ee92032632b">caffe::TileLayer&lt; Dtype &gt;</a>.</p>
<div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="classcaffe_1_1_layer_a7fe981e8af8d93d587acf2a952be563d_icgraph.png" border="0" usemap="#classcaffe_1_1_layer_a7fe981e8af8d93d587acf2a952be563d_icgraph" alt=""/></div>
<map name="classcaffe_1_1_layer_a7fe981e8af8d93d587acf2a952be563d_icgraph" id="classcaffe_1_1_layer_a7fe981e8af8d93d587acf2a952be563d_icgraph">
<area shape="rect" id="node2" href="classcaffe_1_1_layer.html#a18d6bfdb535ab8e96a971dec4ae39a84" title="Implements common layer setup functionality. " alt="" coords="204,5,340,32"/>
</map>
</div>

</div>
</div>
<a id="a7fe981e8af8d93d587acf2a952be563d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7fe981e8af8d93d587acf2a952be563d">&#9670;&nbsp;</a></span>Reshape() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Dtype&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">virtual void <a class="el" href="classcaffe_1_1_layer.html">caffe::Layer</a>&lt; Dtype &gt;::Reshape </td>
          <td>(</td>
          <td class="paramtype">const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;&#160;</td>
          <td class="paramname"><em>bottom</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;&#160;</td>
          <td class="paramname"><em>top</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">pure virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Adjust the shapes of top blobs and internal buffers to accommodate the shapes of the bottom blobs. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">bottom</td><td>the input blobs, with the requested input shapes </td></tr>
    <tr><td class="paramname">top</td><td>the top blobs, which should be reshaped as needed</td></tr>
  </table>
  </dd>
</dl>
<p>This method should reshape top blobs as needed according to the shapes of the bottom (input) blobs, as well as reshaping any internal buffers and making any other necessary adjustments so that the layer can accommodate the bottom blobs. </p>

<p>Implemented in <a class="el" href="classcaffe_1_1_l_s_t_m_unit_layer.html#a795bd455f4635e876de32323e9cee96d">caffe::LSTMUnitLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_l_s_t_m_unit_layer.html#aa6b2edc73f84705744f9f17ad2d014bb">caffe::LSTMUnitLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_softmax_with_loss_layer.html#a2821b89b0f46a5e2ddaccb2708ab237b">caffe::SoftmaxWithLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_softmax_with_loss_layer.html#ad8f5d429254deaebe4ea5f14bfa0d4d0">caffe::SoftmaxWithLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_infogain_loss_layer.html#a83ed478450bc7f629499fed37f654c5c">caffe::InfogainLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_infogain_loss_layer.html#aa2903026b3886816270deb038a463759">caffe::InfogainLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_sigmoid_cross_entropy_loss_layer.html#a305423abeea4bd1652ff7e696aaba808">caffe::SigmoidCrossEntropyLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_sigmoid_cross_entropy_loss_layer.html#a4199eb0668451022f8da20ebca129eb3">caffe::SigmoidCrossEntropyLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_multinomial_logistic_loss_layer.html#a979be47987712c02dfb57a88b2a69f11">caffe::MultinomialLogisticLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_weighted_euclidean_loss_layer.html#a98e3de49ab49d66b8e3ebfe3aa4fbe20">caffe::WeightedEuclideanLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_multinomial_logistic_loss_layer.html#afd5162d1fc8be1a4abdf1afaa96519f8">caffe::MultinomialLogisticLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_weighted_euclidean_loss_layer.html#ac9b915b132fb539ffdd610992c507974">caffe::WeightedEuclideanLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_batch_norm_layer.html#a1acd542fe8fe89d88db9050d048fc7d2">caffe::BatchNormLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_batch_norm_layer.html#ab5cc20592aaa28fb2c41fabe842da3fc">caffe::BatchNormLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_euclidean_loss_layer.html#a9cbe90ea0130c31bd5b9419a1bbaa555">caffe::EuclideanLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_euclidean_loss_layer.html#ab7f1b879898ffba67cf5035f6a56d8eb">caffe::EuclideanLossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_arg_max_layer.html#a291a2c548c28e7ab02ddac0cfd3cbdad">caffe::ArgMaxLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_arg_max_layer.html#a658393ef566ec585bf540a1b6f31a929">caffe::ArgMaxLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_p_re_l_u_layer.html#a50ad2070e060093556d1fc12f31e33b1">caffe::PReLULayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_p_re_l_u_layer.html#a923c7c14b470ff84a9b8ee4a93395b5d">caffe::PReLULayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_dropout_layer.html#a8ddbd583b7430f228506954910935505">caffe::DropoutLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_swish_layer.html#a995afbac7e3adc0bfe157b0458656a9e">caffe::SwishLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_dropout_layer.html#a93f66d83b510987fe37a42d14e6ff98a">caffe::DropoutLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_swish_layer.html#aecf840a1202549b60742eb11a2f188ee">caffe::SwishLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_accuracy_layer.html#aa2b680fc1e754440c2babd150e09f2f6">caffe::AccuracyLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_accuracy_layer.html#a1a42bc91c233a9f803482bff30163f36">caffe::AccuracyLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_base_data_layer.html#a2955d06a5e67609582fb293a0a37673f">caffe::BaseDataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_h_d_f5_output_layer.html#afaed17dc14251e627764334d54e55c4d">caffe::HDF5OutputLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_python_layer.html#aa6597e54cd5fea5b5c7b67299b74a72c">caffe::PythonLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_recurrent_layer.html#aba6011a9cbb18e38a8596aa5dbb44723">caffe::RecurrentLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_scale_layer.html#aeafe805a68903bae9a7f2b98bf453e22">caffe::ScaleLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_base_data_layer.html#a2955d06a5e67609582fb293a0a37673f">caffe::BaseDataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_h_d_f5_output_layer.html#afaed17dc14251e627764334d54e55c4d">caffe::HDF5OutputLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_python_layer.html#aa6597e54cd5fea5b5c7b67299b74a72c">caffe::PythonLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_recurrent_layer.html#aea7d9f8a75896b5bff438c6cdc966b6b">caffe::RecurrentLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_scale_layer.html#a40101bfc91fea909fdc9047c3618d07d">caffe::ScaleLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_h_d_f5_data_layer.html#a38b8924648ba4ab2933fe389fa608cad">caffe::HDF5DataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_h_d_f5_data_layer.html#a38b8924648ba4ab2933fe389fa608cad">caffe::HDF5DataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_loss_layer.html#abf00412194f5413ea9468ee44b0d986f">caffe::LossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_l_r_n_layer.html#aa002dacb2f69d2b500227f938a957a81">caffe::LRNLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_loss_layer.html#a1324e1bd42d84a6eb7e2c559d2da9ecc">caffe::LossLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_l_r_n_layer.html#a5dd9938f40f479d6fd1de59becd09bdf">caffe::LRNLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_bias_layer.html#aff9bd5f76055189c5ec66f43faf17660">caffe::BiasLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_bias_layer.html#a00ab608f300c4fa94d75b15ab9e0c599">caffe::BiasLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_crop_layer.html#a195d2e437a70b0139411c1dd22b08120">caffe::CropLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_flatten_layer.html#a3b459231a94176753d0cb1ae94bc942f">caffe::FlattenLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_crop_layer.html#a71fca33b7fb554973d6e7cc39affd8da">caffe::CropLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_flatten_layer.html#a87b5836343017586d5aa928797c4b92a">caffe::FlattenLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_dummy_data_layer.html#ae72f2ea80339981bf925f0291f62d527">caffe::DummyDataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_embed_layer.html#ac7c19a708d491f9fe161c78348ec794b">caffe::EmbedLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_im2col_layer.html#a119c9e1965e219be1ccb719821d4542f">caffe::Im2colLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_input_layer.html#a4c2028f829734a202263725d8aa41152">caffe::InputLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_parameter_layer.html#acc7cf7e2dea7e254717b13980fdf6c1a">caffe::ParameterLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_reduction_layer.html#a0f6594ec41a0556e9fcfb9af0ae86c8a">caffe::ReductionLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_dummy_data_layer.html#ae72f2ea80339981bf925f0291f62d527">caffe::DummyDataLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_embed_layer.html#ab388111d4ccdbcf081030ccd2e258f69">caffe::EmbedLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_im2col_layer.html#a18fcf2571b0c73b6dd828a7fc7caf5e6">caffe::Im2colLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_input_layer.html#a4c2028f829734a202263725d8aa41152">caffe::InputLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_parameter_layer.html#acc7cf7e2dea7e254717b13980fdf6c1a">caffe::ParameterLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_reduction_layer.html#ad830b3c52fb34555e45cd172a8b27ed9">caffe::ReductionLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_batch_reindex_layer.html#a7f69b6b19387959bf0926dde7a7922a4">caffe::BatchReindexLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_eltwise_layer.html#a17b4cb0842a154224bab9733e77e07b9">caffe::EltwiseLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_filter_layer.html#ade673aa44e466adbe3aa79531a7c7484">caffe::FilterLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_inner_product_layer.html#a1c823624ec9286477db7caa5188152b8">caffe::InnerProductLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_reshape_layer.html#a5b85ce44e23b4f958a60ff2b2c43e61f">caffe::ReshapeLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_slice_layer.html#af9fa49d54abf1cb090cfc772eb4acc4d">caffe::SliceLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_s_p_p_layer.html#a3ba65e459c1bde4f772d545efb43a2f2">caffe::SPPLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_batch_reindex_layer.html#a7fac1505092f43372ed39a99a1405d4b">caffe::BatchReindexLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_eltwise_layer.html#a3f9e26946868f6249af1d4f57fc8259f">caffe::EltwiseLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_filter_layer.html#aea626ef6cdd51ca2ede31319daab2d1b">caffe::FilterLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_inner_product_layer.html#a12915397170ea81ccc0bce177897d4ba">caffe::InnerProductLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_reshape_layer.html#ab071d750b8cef391e9fe0c67efaa4994">caffe::ReshapeLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_slice_layer.html#ac6fce397efbab95848f56be7b4f6a786">caffe::SliceLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_s_p_p_layer.html#ab23015d8d27fccab684de17b7c6d4e28">caffe::SPPLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_base_convolution_layer.html#aa215338f200c832081f2719a54bc5256">caffe::BaseConvolutionLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_pooling_layer.html#ac652e08deffb0eeb6c3113abb55eb641">caffe::PoolingLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_base_convolution_layer.html#af384650d31552ea10b1a030788cb52d8">caffe::BaseConvolutionLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_pooling_layer.html#ad8ab4e6541bc0954146d62781aeb1af8">caffe::PoolingLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_concat_layer.html#a3c7cbd500d3a15cfbdbf33479c4fb228">caffe::ConcatLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_neuron_layer.html#a6d0facf4a5e6f459cf1cb8b28d945790">caffe::NeuronLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_split_layer.html#a4e978965461dedcc2fbb905e4910c0b1">caffe::SplitLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_concat_layer.html#af210770b1c8bbce8fc34340ba94f9f75">caffe::ConcatLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_neuron_layer.html#a2c87bff832b685db76a41cbc8539e7ce">caffe::NeuronLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_split_layer.html#a1064977331e5bfcf5d75590d14986e1f">caffe::SplitLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_m_v_n_layer.html#a48aafabe729bb3b22171cfdbda6e6073">caffe::MVNLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_softmax_layer.html#a756fd5ad3af07d019b5f2247f38b4496">caffe::SoftmaxLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_m_v_n_layer.html#afcb6c5f28b45496eed1b0ea19705b763">caffe::MVNLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_softmax_layer.html#a503694b3161839de7c19d7d0af2cecc2">caffe::SoftmaxLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_silence_layer.html#a96a47a49a103e60a681f97eff7bf42f2">caffe::SilenceLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_silence_layer.html#a96a47a49a103e60a681f97eff7bf42f2">caffe::SilenceLayer&lt; Dtype &gt;</a>, <a class="el" href="classcaffe_1_1_tile_layer.html#a593f5b8342f1b092633d2a1f7e4a6843">caffe::TileLayer&lt; Dtype &gt;</a>, and <a class="el" href="classcaffe_1_1_tile_layer.html#a1fe845a1597dbc119e922ee92032632b">caffe::TileLayer&lt; Dtype &gt;</a>.</p>

</div>
</div>
<a id="a04eb2a3d1d59c64cd64c233217d5d6fc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a04eb2a3d1d59c64cd64c233217d5d6fc">&#9670;&nbsp;</a></span>SetLossWeights() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Dtype&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcaffe_1_1_layer.html">caffe::Layer</a>&lt; Dtype &gt;::SetLossWeights </td>
          <td>(</td>
          <td class="paramtype">const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;&#160;</td>
          <td class="paramname"><em>top</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p class="">Called by SetUp to initialize the weights associated with any top blobs in the loss function. Store non-zero loss weights in the diff blob. </p>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="classcaffe_1_1_layer_a04eb2a3d1d59c64cd64c233217d5d6fc_cgraph.png" border="0" usemap="#classcaffe_1_1_layer_a04eb2a3d1d59c64cd64c233217d5d6fc_cgraph" alt=""/></div>
<map name="classcaffe_1_1_layer_a04eb2a3d1d59c64cd64c233217d5d6fc_cgraph" id="classcaffe_1_1_layer_a04eb2a3d1d59c64cd64c233217d5d6fc_cgraph">
<area shape="rect" id="node2" href="classcaffe_1_1_layer.html#a899b09f4b91ada8545b3a43ee91e0d69" title="Sets the loss associated with a top blob at a given index. " alt="" coords="248,5,396,32"/>
</map>
</div>
<div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="classcaffe_1_1_layer_a04eb2a3d1d59c64cd64c233217d5d6fc_icgraph.png" border="0" usemap="#classcaffe_1_1_layer_a04eb2a3d1d59c64cd64c233217d5d6fc_icgraph" alt=""/></div>
<map name="classcaffe_1_1_layer_a04eb2a3d1d59c64cd64c233217d5d6fc_icgraph" id="classcaffe_1_1_layer_a04eb2a3d1d59c64cd64c233217d5d6fc_icgraph">
<area shape="rect" id="node2" href="classcaffe_1_1_layer.html#a18d6bfdb535ab8e96a971dec4ae39a84" title="Implements common layer setup functionality. " alt="" coords="248,5,384,32"/>
</map>
</div>

</div>
</div>
<a id="a04eb2a3d1d59c64cd64c233217d5d6fc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a04eb2a3d1d59c64cd64c233217d5d6fc">&#9670;&nbsp;</a></span>SetLossWeights() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Dtype&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcaffe_1_1_layer.html">caffe::Layer</a>&lt; Dtype &gt;::SetLossWeights </td>
          <td>(</td>
          <td class="paramtype">const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;&#160;</td>
          <td class="paramname"><em>top</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p class="">Called by SetUp to initialize the weights associated with any top blobs in the loss function. Store non-zero loss weights in the diff blob. </p>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="classcaffe_1_1_layer_a04eb2a3d1d59c64cd64c233217d5d6fc_cgraph.png" border="0" usemap="#classcaffe_1_1_layer_a04eb2a3d1d59c64cd64c233217d5d6fc_cgraph" alt=""/></div>
<map name="classcaffe_1_1_layer_a04eb2a3d1d59c64cd64c233217d5d6fc_cgraph" id="classcaffe_1_1_layer_a04eb2a3d1d59c64cd64c233217d5d6fc_cgraph">
<area shape="rect" id="node2" href="classcaffe_1_1_layer.html#a899b09f4b91ada8545b3a43ee91e0d69" title="Sets the loss associated with a top blob at a given index. " alt="" coords="248,5,396,32"/>
</map>
</div>

</div>
</div>
<a id="a18d6bfdb535ab8e96a971dec4ae39a84"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a18d6bfdb535ab8e96a971dec4ae39a84">&#9670;&nbsp;</a></span>SetUp() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Dtype&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcaffe_1_1_layer.html">caffe::Layer</a>&lt; Dtype &gt;::SetUp </td>
          <td>(</td>
          <td class="paramtype">const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;&#160;</td>
          <td class="paramname"><em>bottom</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;&#160;</td>
          <td class="paramname"><em>top</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Implements common layer setup functionality. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">bottom</td><td>the preshaped input blobs </td></tr>
    <tr><td class="paramname">top</td><td>the allocated but unshaped output blobs, to be shaped by Reshape</td></tr>
  </table>
  </dd>
</dl>
<p>Checks that the number of bottom and top blobs is correct. Calls LayerSetUp to do special layer setup for individual layer types, followed by Reshape to set up sizes of top blobs and internal buffers. Sets up the loss weight multiplier blobs for any non-zero loss weights. This method may not be overridden. </p>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="classcaffe_1_1_layer_a18d6bfdb535ab8e96a971dec4ae39a84_cgraph.png" border="0" usemap="#classcaffe_1_1_layer_a18d6bfdb535ab8e96a971dec4ae39a84_cgraph" alt=""/></div>
<map name="classcaffe_1_1_layer_a18d6bfdb535ab8e96a971dec4ae39a84_cgraph" id="classcaffe_1_1_layer_a18d6bfdb535ab8e96a971dec4ae39a84_cgraph">
<area shape="rect" id="node2" href="classcaffe_1_1_layer.html#a55c8036130225fbc874a986bdf4b27e2" title="caffe::Layer::CheckBlobCounts" alt="" coords="189,231,395,258"/>
<area shape="rect" id="node11" href="classcaffe_1_1_layer.html#a481323a3e0972c682787f2137468c29f" title="Does layer&#45;specific setup: your layer should implement this function as well as Reshape. " alt="" coords="208,301,376,327"/>
<area shape="rect" id="node12" href="classcaffe_1_1_layer.html#a7fe981e8af8d93d587acf2a952be563d" title="Adjust the shapes of top blobs and internal buffers to accommodate the shapes of the bottom blobs..." alt="" coords="217,351,367,378"/>
<area shape="rect" id="node13" href="classcaffe_1_1_layer.html#a04eb2a3d1d59c64cd64c233217d5d6fc" title="caffe::Layer::SetLossWeights" alt="" coords="195,439,389,466"/>
<area shape="rect" id="node3" href="classcaffe_1_1_layer.html#a8e5ee0494d85f5f55fc4396537cbc60f" title="Returns the exact number of bottom blobs required by the layer, or &#45;1 if no exact number is required..." alt="" coords="443,5,645,47"/>
<area shape="rect" id="node4" href="classcaffe_1_1_layer.html#a8952bff6bc4c2a96d8ea30d8ff65b198" title="Returns the layer type. " alt="" coords="482,71,606,98"/>
<area shape="rect" id="node5" href="classcaffe_1_1_layer.html#aca3cb2bafaefda5d4760aaebd0b72def" title="Returns the minimum number of bottom blobs required by the layer, or &#45;1 if no minimum number is requi..." alt="" coords="447,122,641,149"/>
<area shape="rect" id="node6" href="classcaffe_1_1_layer.html#af8bdc989053e0363ab032026b46de7c3" title="Returns the maximum number of bottom blobs required by the layer, or &#45;1 if no maximum number is requi..." alt="" coords="445,173,643,199"/>
<area shape="rect" id="node7" href="classcaffe_1_1_layer.html#a64e2ca72c719e4b2f1f9216ccfb0d37f" title="Returns the exact number of top blobs required by the layer, or &#45;1 if no exact number is required..." alt="" coords="453,224,635,265"/>
<area shape="rect" id="node8" href="classcaffe_1_1_layer.html#ab9e4c8d642e413948b131d851a8462a4" title="Returns the minimum number of top blobs required by the layer, or &#45;1 if no minimum number is required..." alt="" coords="457,290,631,317"/>
<area shape="rect" id="node9" href="classcaffe_1_1_layer.html#ac6c03df0b6e40e776c94001e19994a2e" title="Returns the maximum number of top blobs required by the layer, or &#45;1 if no maximum number is required..." alt="" coords="455,341,633,367"/>
<area shape="rect" id="node10" href="classcaffe_1_1_layer.html#af452a938bc7596f9b5e9900c8dc4ab3d" title="Returns true if the layer requires an equal number of bottom and top blobs. " alt="" coords="443,392,645,433"/>
<area shape="rect" id="node14" href="classcaffe_1_1_layer.html#a899b09f4b91ada8545b3a43ee91e0d69" title="Sets the loss associated with a top blob at a given index. " alt="" coords="470,458,618,485"/>
</map>
</div>

</div>
</div>
<a id="a18d6bfdb535ab8e96a971dec4ae39a84"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a18d6bfdb535ab8e96a971dec4ae39a84">&#9670;&nbsp;</a></span>SetUp() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Dtype&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void <a class="el" href="classcaffe_1_1_layer.html">caffe::Layer</a>&lt; Dtype &gt;::SetUp </td>
          <td>(</td>
          <td class="paramtype">const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;&#160;</td>
          <td class="paramname"><em>bottom</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const vector&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; *&gt; &amp;&#160;</td>
          <td class="paramname"><em>top</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Implements common layer setup functionality. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">bottom</td><td>the preshaped input blobs </td></tr>
    <tr><td class="paramname">top</td><td>the allocated but unshaped output blobs, to be shaped by Reshape</td></tr>
  </table>
  </dd>
</dl>
<p>Checks that the number of bottom and top blobs is correct. Calls LayerSetUp to do special layer setup for individual layer types, followed by Reshape to set up sizes of top blobs and internal buffers. Sets up the loss weight multiplier blobs for any non-zero loss weights. This method may not be overridden. </p>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="classcaffe_1_1_layer_a18d6bfdb535ab8e96a971dec4ae39a84_cgraph.png" border="0" usemap="#classcaffe_1_1_layer_a18d6bfdb535ab8e96a971dec4ae39a84_cgraph" alt=""/></div>
<map name="classcaffe_1_1_layer_a18d6bfdb535ab8e96a971dec4ae39a84_cgraph" id="classcaffe_1_1_layer_a18d6bfdb535ab8e96a971dec4ae39a84_cgraph">
<area shape="rect" id="node2" href="classcaffe_1_1_layer.html#a55c8036130225fbc874a986bdf4b27e2" title="caffe::Layer::CheckBlobCounts" alt="" coords="189,231,395,258"/>
<area shape="rect" id="node11" href="classcaffe_1_1_layer.html#a481323a3e0972c682787f2137468c29f" title="Does layer&#45;specific setup: your layer should implement this function as well as Reshape. " alt="" coords="208,301,376,327"/>
<area shape="rect" id="node12" href="classcaffe_1_1_layer.html#a7fe981e8af8d93d587acf2a952be563d" title="Adjust the shapes of top blobs and internal buffers to accommodate the shapes of the bottom blobs..." alt="" coords="217,351,367,378"/>
<area shape="rect" id="node13" href="classcaffe_1_1_layer.html#a04eb2a3d1d59c64cd64c233217d5d6fc" title="caffe::Layer::SetLossWeights" alt="" coords="195,439,389,466"/>
<area shape="rect" id="node3" href="classcaffe_1_1_layer.html#a8e5ee0494d85f5f55fc4396537cbc60f" title="Returns the exact number of bottom blobs required by the layer, or &#45;1 if no exact number is required..." alt="" coords="443,5,645,47"/>
<area shape="rect" id="node4" href="classcaffe_1_1_layer.html#a8952bff6bc4c2a96d8ea30d8ff65b198" title="Returns the layer type. " alt="" coords="482,71,606,98"/>
<area shape="rect" id="node5" href="classcaffe_1_1_layer.html#aca3cb2bafaefda5d4760aaebd0b72def" title="Returns the minimum number of bottom blobs required by the layer, or &#45;1 if no minimum number is requi..." alt="" coords="447,122,641,149"/>
<area shape="rect" id="node6" href="classcaffe_1_1_layer.html#af8bdc989053e0363ab032026b46de7c3" title="Returns the maximum number of bottom blobs required by the layer, or &#45;1 if no maximum number is requi..." alt="" coords="445,173,643,199"/>
<area shape="rect" id="node7" href="classcaffe_1_1_layer.html#a64e2ca72c719e4b2f1f9216ccfb0d37f" title="Returns the exact number of top blobs required by the layer, or &#45;1 if no exact number is required..." alt="" coords="453,224,635,265"/>
<area shape="rect" id="node8" href="classcaffe_1_1_layer.html#ab9e4c8d642e413948b131d851a8462a4" title="Returns the minimum number of top blobs required by the layer, or &#45;1 if no minimum number is required..." alt="" coords="457,290,631,317"/>
<area shape="rect" id="node9" href="classcaffe_1_1_layer.html#ac6c03df0b6e40e776c94001e19994a2e" title="Returns the maximum number of top blobs required by the layer, or &#45;1 if no maximum number is required..." alt="" coords="455,341,633,367"/>
<area shape="rect" id="node10" href="classcaffe_1_1_layer.html#af452a938bc7596f9b5e9900c8dc4ab3d" title="Returns true if the layer requires an equal number of bottom and top blobs. " alt="" coords="443,392,645,433"/>
<area shape="rect" id="node14" href="classcaffe_1_1_layer.html#a899b09f4b91ada8545b3a43ee91e0d69" title="Sets the loss associated with a top blob at a given index. " alt="" coords="470,458,618,485"/>
</map>
</div>

</div>
</div>
<h2 class="groupheader">Member Data Documentation</h2>
<a id="a8d6998a5f8ca95990976021de743dd21"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8d6998a5f8ca95990976021de743dd21">&#9670;&nbsp;</a></span>blobs_</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Dtype&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">vector&lt; shared_ptr&lt; <a class="el" href="classcaffe_1_1_blob.html">Blob</a>&lt; Dtype &gt; &gt; &gt; <a class="el" href="classcaffe_1_1_layer.html">caffe::Layer</a>&lt; Dtype &gt;::blobs_</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p class="">The vector that stores the learnable parameters as a set of blobs. </p>

</div>
</div>
<a id="a7ed12bb2df25c887e41d7ea9557fc701"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7ed12bb2df25c887e41d7ea9557fc701">&#9670;&nbsp;</a></span>layer_param_</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Dtype&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classcaffe_1_1_layer_parameter.html">LayerParameter</a> <a class="el" href="classcaffe_1_1_layer.html">caffe::Layer</a>&lt; Dtype &gt;::layer_param_</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p class="">The protobuf that stores the layer parameters </p>

</div>
</div>
<a id="a5fbf5ce7385b2da3d8edc7eec3822ac7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5fbf5ce7385b2da3d8edc7eec3822ac7">&#9670;&nbsp;</a></span>loss_</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Dtype&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">vector&lt; Dtype &gt; <a class="el" href="classcaffe_1_1_layer.html">caffe::Layer</a>&lt; Dtype &gt;::loss_</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p class="">The vector that indicates whether each top blob has a non-zero weight in the objective function. </p>

</div>
</div>
<a id="ab1db6c32fa71343dac868b07288eb45e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab1db6c32fa71343dac868b07288eb45e">&#9670;&nbsp;</a></span>param_propagate_down_</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Dtype&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">vector&lt; bool &gt; <a class="el" href="classcaffe_1_1_layer.html">caffe::Layer</a>&lt; Dtype &gt;::param_propagate_down_</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p class="">Vector indicating whether to compute the diff of each param blob. </p>

</div>
</div>
<a id="a1d04ad7f595a82a1c811f102d68b8a19"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1d04ad7f595a82a1c811f102d68b8a19">&#9670;&nbsp;</a></span>phase_</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename Dtype&gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">Phase <a class="el" href="classcaffe_1_1_layer.html">caffe::Layer</a>&lt; Dtype &gt;::phase_</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p class="">The phase: TRAIN or TEST </p>

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>build/install/include/caffe/<a class="el" href="build_2install_2include_2caffe_2layer_8hpp_source.html">layer.hpp</a></li>
</ul>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a class="el" href="namespacecaffe.html">caffe</a></li><li class="navelem"><a class="el" href="classcaffe_1_1_layer.html">Layer</a></li>
    <li class="footer">Generated by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.15 </li>
  </ul>
</div>
</body>
</html>
