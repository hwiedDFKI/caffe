\hypertarget{classcaffe_1_1_log_layer}{}\section{caffe\+:\+:Log\+Layer$<$ Dtype $>$ Class Template Reference}
\label{classcaffe_1_1_log_layer}\index{caffe\+::\+Log\+Layer$<$ Dtype $>$@{caffe\+::\+Log\+Layer$<$ Dtype $>$}}


Computes $ y = log_{\gamma}(\alpha x + \beta) $, as specified by the scale $ \alpha $, shift $ \beta $, and base $ \gamma $.  




{\ttfamily \#include $<$log\+\_\+layer.\+hpp$>$}



Inheritance diagram for caffe\+:\+:Log\+Layer$<$ Dtype $>$\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=208pt]{classcaffe_1_1_log_layer__inherit__graph}
\end{center}
\end{figure}
\subsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{classcaffe_1_1_log_layer_aa6f92a0b12140d70a44a2bcb71bab552}{Log\+Layer}} (const \mbox{\hyperlink{classcaffe_1_1_layer_parameter}{Layer\+Parameter}} \&param)
\item 
virtual void \mbox{\hyperlink{classcaffe_1_1_log_layer_a87e062000908b474ac4cda3b2f3c6f1e}{Layer\+Set\+Up}} (const vector$<$ \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}}$<$ Dtype $>$ $\ast$$>$ \&bottom, const vector$<$ \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}}$<$ Dtype $>$ $\ast$$>$ \&top)
\begin{DoxyCompactList}\small\item\em Does layer-\/specific setup\+: your layer should implement this function as well as Reshape. \end{DoxyCompactList}\item 
\mbox{\Hypertarget{classcaffe_1_1_log_layer_aec4c7354215da16156bdc3c966ba311f}\label{classcaffe_1_1_log_layer_aec4c7354215da16156bdc3c966ba311f}} 
virtual const char $\ast$ \mbox{\hyperlink{classcaffe_1_1_log_layer_aec4c7354215da16156bdc3c966ba311f}{type}} () const
\begin{DoxyCompactList}\small\item\em Returns the layer type. \end{DoxyCompactList}\item 
\mbox{\hyperlink{classcaffe_1_1_log_layer_aa6f92a0b12140d70a44a2bcb71bab552}{Log\+Layer}} (const \mbox{\hyperlink{classcaffe_1_1_layer_parameter}{Layer\+Parameter}} \&param)
\item 
virtual void \mbox{\hyperlink{classcaffe_1_1_log_layer_aa73d4cdfc38059902ffa2258d58e1dd4}{Layer\+Set\+Up}} (const vector$<$ \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}}$<$ Dtype $>$ $\ast$$>$ \&bottom, const vector$<$ \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}}$<$ Dtype $>$ $\ast$$>$ \&top)
\begin{DoxyCompactList}\small\item\em Does layer-\/specific setup\+: your layer should implement this function as well as Reshape. \end{DoxyCompactList}\item 
\mbox{\Hypertarget{classcaffe_1_1_log_layer_aec4c7354215da16156bdc3c966ba311f}\label{classcaffe_1_1_log_layer_aec4c7354215da16156bdc3c966ba311f}} 
virtual const char $\ast$ \mbox{\hyperlink{classcaffe_1_1_log_layer_aec4c7354215da16156bdc3c966ba311f}{type}} () const
\begin{DoxyCompactList}\small\item\em Returns the layer type. \end{DoxyCompactList}\end{DoxyCompactItemize}
\subsection*{Protected Member Functions}
\begin{DoxyCompactItemize}
\item 
virtual void \mbox{\hyperlink{classcaffe_1_1_log_layer_a407de9bdb364ed170a73c6eebc74dce9}{Forward\+\_\+cpu}} (const vector$<$ \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}}$<$ Dtype $>$ $\ast$$>$ \&bottom, const vector$<$ \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}}$<$ Dtype $>$ $\ast$$>$ \&top)
\item 
\mbox{\Hypertarget{classcaffe_1_1_log_layer_a37ec5bf1dc1a00c1830ec92fcf22fe09}\label{classcaffe_1_1_log_layer_a37ec5bf1dc1a00c1830ec92fcf22fe09}} 
virtual void \mbox{\hyperlink{classcaffe_1_1_log_layer_a37ec5bf1dc1a00c1830ec92fcf22fe09}{Forward\+\_\+gpu}} (const vector$<$ \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}}$<$ Dtype $>$ $\ast$$>$ \&bottom, const vector$<$ \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}}$<$ Dtype $>$ $\ast$$>$ \&top)
\begin{DoxyCompactList}\small\item\em Using the G\+PU device, compute the layer output. Fall back to \mbox{\hyperlink{classcaffe_1_1_log_layer_a407de9bdb364ed170a73c6eebc74dce9}{Forward\+\_\+cpu()}} if unavailable. \end{DoxyCompactList}\item 
virtual void \mbox{\hyperlink{classcaffe_1_1_log_layer_a79f6398d807b7d751820528d5a68faa7}{Backward\+\_\+cpu}} (const vector$<$ \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}}$<$ Dtype $>$ $\ast$$>$ \&top, const vector$<$ bool $>$ \&propagate\+\_\+down, const vector$<$ \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}}$<$ Dtype $>$ $\ast$$>$ \&bottom)
\begin{DoxyCompactList}\small\item\em Computes the error gradient w.\+r.\+t. the exp inputs. \end{DoxyCompactList}\item 
\mbox{\Hypertarget{classcaffe_1_1_log_layer_ac31070a5303ee3e4c04b01326cb0c40a}\label{classcaffe_1_1_log_layer_ac31070a5303ee3e4c04b01326cb0c40a}} 
virtual void \mbox{\hyperlink{classcaffe_1_1_log_layer_ac31070a5303ee3e4c04b01326cb0c40a}{Backward\+\_\+gpu}} (const vector$<$ \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}}$<$ Dtype $>$ $\ast$$>$ \&top, const vector$<$ bool $>$ \&propagate\+\_\+down, const vector$<$ \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}}$<$ Dtype $>$ $\ast$$>$ \&bottom)
\begin{DoxyCompactList}\small\item\em Using the G\+PU device, compute the gradients for any parameters and for the bottom blobs if propagate\+\_\+down is true. Fall back to \mbox{\hyperlink{classcaffe_1_1_log_layer_a79f6398d807b7d751820528d5a68faa7}{Backward\+\_\+cpu()}} if unavailable. \end{DoxyCompactList}\item 
virtual void \mbox{\hyperlink{classcaffe_1_1_log_layer_aeb9fead649bae76818f950a43382d0dc}{Forward\+\_\+cpu}} (const vector$<$ \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}}$<$ Dtype $>$ $\ast$$>$ \&bottom, const vector$<$ \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}}$<$ Dtype $>$ $\ast$$>$ \&top)
\item 
\mbox{\Hypertarget{classcaffe_1_1_log_layer_a37ec5bf1dc1a00c1830ec92fcf22fe09}\label{classcaffe_1_1_log_layer_a37ec5bf1dc1a00c1830ec92fcf22fe09}} 
virtual void \mbox{\hyperlink{classcaffe_1_1_log_layer_a37ec5bf1dc1a00c1830ec92fcf22fe09}{Forward\+\_\+gpu}} (const vector$<$ \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}}$<$ Dtype $>$ $\ast$$>$ \&bottom, const vector$<$ \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}}$<$ Dtype $>$ $\ast$$>$ \&top)
\begin{DoxyCompactList}\small\item\em Using the G\+PU device, compute the layer output. Fall back to \mbox{\hyperlink{classcaffe_1_1_log_layer_a407de9bdb364ed170a73c6eebc74dce9}{Forward\+\_\+cpu()}} if unavailable. \end{DoxyCompactList}\item 
virtual void \mbox{\hyperlink{classcaffe_1_1_log_layer_a89e1a1a60fca7d144afeee42aa996951}{Backward\+\_\+cpu}} (const vector$<$ \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}}$<$ Dtype $>$ $\ast$$>$ \&top, const vector$<$ bool $>$ \&propagate\+\_\+down, const vector$<$ \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}}$<$ Dtype $>$ $\ast$$>$ \&bottom)
\begin{DoxyCompactList}\small\item\em Computes the error gradient w.\+r.\+t. the exp inputs. \end{DoxyCompactList}\item 
\mbox{\Hypertarget{classcaffe_1_1_log_layer_ac31070a5303ee3e4c04b01326cb0c40a}\label{classcaffe_1_1_log_layer_ac31070a5303ee3e4c04b01326cb0c40a}} 
virtual void \mbox{\hyperlink{classcaffe_1_1_log_layer_ac31070a5303ee3e4c04b01326cb0c40a}{Backward\+\_\+gpu}} (const vector$<$ \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}}$<$ Dtype $>$ $\ast$$>$ \&top, const vector$<$ bool $>$ \&propagate\+\_\+down, const vector$<$ \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}}$<$ Dtype $>$ $\ast$$>$ \&bottom)
\begin{DoxyCompactList}\small\item\em Using the G\+PU device, compute the gradients for any parameters and for the bottom blobs if propagate\+\_\+down is true. Fall back to \mbox{\hyperlink{classcaffe_1_1_log_layer_a79f6398d807b7d751820528d5a68faa7}{Backward\+\_\+cpu()}} if unavailable. \end{DoxyCompactList}\end{DoxyCompactItemize}
\subsection*{Protected Attributes}
\begin{DoxyCompactItemize}
\item 
\mbox{\Hypertarget{classcaffe_1_1_log_layer_a491b3c774d06e7444e098f5e92116473}\label{classcaffe_1_1_log_layer_a491b3c774d06e7444e098f5e92116473}} 
Dtype {\bfseries base\+\_\+scale\+\_\+}
\item 
\mbox{\Hypertarget{classcaffe_1_1_log_layer_a8c45b84ac085d9422655e68c107aa38f}\label{classcaffe_1_1_log_layer_a8c45b84ac085d9422655e68c107aa38f}} 
Dtype {\bfseries input\+\_\+scale\+\_\+}
\item 
\mbox{\Hypertarget{classcaffe_1_1_log_layer_aea8ff4c75c4d1332801b91af479916af}\label{classcaffe_1_1_log_layer_aea8ff4c75c4d1332801b91af479916af}} 
Dtype {\bfseries input\+\_\+shift\+\_\+}
\item 
\mbox{\Hypertarget{classcaffe_1_1_log_layer_ab87303089b3708884efaabef8a5e0df2}\label{classcaffe_1_1_log_layer_ab87303089b3708884efaabef8a5e0df2}} 
Dtype {\bfseries backward\+\_\+num\+\_\+scale\+\_\+}
\end{DoxyCompactItemize}


\subsection{Detailed Description}
\subsubsection*{template$<$typename Dtype$>$\newline
class caffe\+::\+Log\+Layer$<$ Dtype $>$}

Computes $ y = log_{\gamma}(\alpha x + \beta) $, as specified by the scale $ \alpha $, shift $ \beta $, and base $ \gamma $. 

\subsection{Constructor \& Destructor Documentation}
\mbox{\Hypertarget{classcaffe_1_1_log_layer_aa6f92a0b12140d70a44a2bcb71bab552}\label{classcaffe_1_1_log_layer_aa6f92a0b12140d70a44a2bcb71bab552}} 
\index{caffe\+::\+Log\+Layer@{caffe\+::\+Log\+Layer}!Log\+Layer@{Log\+Layer}}
\index{Log\+Layer@{Log\+Layer}!caffe\+::\+Log\+Layer@{caffe\+::\+Log\+Layer}}
\subsubsection{\texorpdfstring{Log\+Layer()}{LogLayer()}\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily template$<$typename Dtype$>$ \\
\mbox{\hyperlink{classcaffe_1_1_log_layer}{caffe\+::\+Log\+Layer}}$<$ Dtype $>$\+::\mbox{\hyperlink{classcaffe_1_1_log_layer}{Log\+Layer}} (\begin{DoxyParamCaption}\item[{const \mbox{\hyperlink{classcaffe_1_1_layer_parameter}{Layer\+Parameter}} \&}]{param }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [inline]}, {\ttfamily [explicit]}}


\begin{DoxyParams}{Parameters}
{\em param} & provides \mbox{\hyperlink{classcaffe_1_1_log_parameter}{Log\+Parameter}} log\+\_\+param, with \mbox{\hyperlink{classcaffe_1_1_log_layer}{Log\+Layer}} options\+:
\begin{DoxyItemize}
\item scale ({\bfseries optional}, default 1) the scale $ \alpha $
\item shift ({\bfseries optional}, default 0) the shift $ \beta $
\item base ({\bfseries optional}, default -\/1 for a value of $ e \approx 2.718 $) the base $ \gamma $ 
\end{DoxyItemize}\\
\hline
\end{DoxyParams}
\mbox{\Hypertarget{classcaffe_1_1_log_layer_aa6f92a0b12140d70a44a2bcb71bab552}\label{classcaffe_1_1_log_layer_aa6f92a0b12140d70a44a2bcb71bab552}} 
\index{caffe\+::\+Log\+Layer@{caffe\+::\+Log\+Layer}!Log\+Layer@{Log\+Layer}}
\index{Log\+Layer@{Log\+Layer}!caffe\+::\+Log\+Layer@{caffe\+::\+Log\+Layer}}
\subsubsection{\texorpdfstring{Log\+Layer()}{LogLayer()}\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily template$<$typename Dtype$>$ \\
\mbox{\hyperlink{classcaffe_1_1_log_layer}{caffe\+::\+Log\+Layer}}$<$ Dtype $>$\+::\mbox{\hyperlink{classcaffe_1_1_log_layer}{Log\+Layer}} (\begin{DoxyParamCaption}\item[{const \mbox{\hyperlink{classcaffe_1_1_layer_parameter}{Layer\+Parameter}} \&}]{param }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [inline]}, {\ttfamily [explicit]}}


\begin{DoxyParams}{Parameters}
{\em param} & provides \mbox{\hyperlink{classcaffe_1_1_log_parameter}{Log\+Parameter}} log\+\_\+param, with \mbox{\hyperlink{classcaffe_1_1_log_layer}{Log\+Layer}} options\+:
\begin{DoxyItemize}
\item scale ({\bfseries optional}, default 1) the scale $ \alpha $
\item shift ({\bfseries optional}, default 0) the shift $ \beta $
\item base ({\bfseries optional}, default -\/1 for a value of $ e \approx 2.718 $) the base $ \gamma $ 
\end{DoxyItemize}\\
\hline
\end{DoxyParams}


\subsection{Member Function Documentation}
\mbox{\Hypertarget{classcaffe_1_1_log_layer_a79f6398d807b7d751820528d5a68faa7}\label{classcaffe_1_1_log_layer_a79f6398d807b7d751820528d5a68faa7}} 
\index{caffe\+::\+Log\+Layer@{caffe\+::\+Log\+Layer}!Backward\+\_\+cpu@{Backward\+\_\+cpu}}
\index{Backward\+\_\+cpu@{Backward\+\_\+cpu}!caffe\+::\+Log\+Layer@{caffe\+::\+Log\+Layer}}
\subsubsection{\texorpdfstring{Backward\+\_\+cpu()}{Backward\_cpu()}\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily template$<$typename Dtype $>$ \\
void \mbox{\hyperlink{classcaffe_1_1_log_layer}{caffe\+::\+Log\+Layer}}$<$ Dtype $>$\+::Backward\+\_\+cpu (\begin{DoxyParamCaption}\item[{const vector$<$ \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}}$<$ Dtype $>$ $\ast$$>$ \&}]{top,  }\item[{const vector$<$ bool $>$ \&}]{propagate\+\_\+down,  }\item[{const vector$<$ \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}}$<$ Dtype $>$ $\ast$$>$ \&}]{bottom }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [protected]}, {\ttfamily [virtual]}}



Computes the error gradient w.\+r.\+t. the exp inputs. 


\begin{DoxyParams}{Parameters}
{\em top} & output \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}} vector (length 1), providing the error gradient with respect to the outputs
\begin{DoxyEnumerate}
\item $ (N \times C \times H \times W) $ containing error gradients $ \frac{\partial E}{\partial y} $ with respect to computed outputs $ y $ 
\end{DoxyEnumerate}\\
\hline
{\em propagate\+\_\+down} & see \mbox{\hyperlink{classcaffe_1_1_layer_a183d343f5183a4762307f2c5e6ed1e12}{Layer\+::\+Backward}}. \\
\hline
{\em bottom} & input \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}} vector (length 1)
\begin{DoxyEnumerate}
\item $ (N \times C \times H \times W) $ the inputs $ x $; Backward fills their diff with gradients $ \frac{\partial E}{\partial x} = \frac{\partial E}{\partial y} y \alpha \log_e(gamma) $ if propagate\+\_\+down\mbox{[}0\mbox{]} 
\end{DoxyEnumerate}\\
\hline
\end{DoxyParams}


Implements \mbox{\hyperlink{classcaffe_1_1_layer_a75c9b2a321dc713e0eaef530d02dc37f}{caffe\+::\+Layer$<$ Dtype $>$}}.

\mbox{\Hypertarget{classcaffe_1_1_log_layer_a89e1a1a60fca7d144afeee42aa996951}\label{classcaffe_1_1_log_layer_a89e1a1a60fca7d144afeee42aa996951}} 
\index{caffe\+::\+Log\+Layer@{caffe\+::\+Log\+Layer}!Backward\+\_\+cpu@{Backward\+\_\+cpu}}
\index{Backward\+\_\+cpu@{Backward\+\_\+cpu}!caffe\+::\+Log\+Layer@{caffe\+::\+Log\+Layer}}
\subsubsection{\texorpdfstring{Backward\+\_\+cpu()}{Backward\_cpu()}\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily template$<$typename Dtype$>$ \\
virtual void \mbox{\hyperlink{classcaffe_1_1_log_layer}{caffe\+::\+Log\+Layer}}$<$ Dtype $>$\+::Backward\+\_\+cpu (\begin{DoxyParamCaption}\item[{const vector$<$ \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}}$<$ Dtype $>$ $\ast$$>$ \&}]{top,  }\item[{const vector$<$ bool $>$ \&}]{propagate\+\_\+down,  }\item[{const vector$<$ \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}}$<$ Dtype $>$ $\ast$$>$ \&}]{bottom }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [protected]}, {\ttfamily [virtual]}}



Computes the error gradient w.\+r.\+t. the exp inputs. 


\begin{DoxyParams}{Parameters}
{\em top} & output \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}} vector (length 1), providing the error gradient with respect to the outputs
\begin{DoxyEnumerate}
\item $ (N \times C \times H \times W) $ containing error gradients $ \frac{\partial E}{\partial y} $ with respect to computed outputs $ y $ 
\end{DoxyEnumerate}\\
\hline
{\em propagate\+\_\+down} & see \mbox{\hyperlink{classcaffe_1_1_layer_a183d343f5183a4762307f2c5e6ed1e12}{Layer\+::\+Backward}}. \\
\hline
{\em bottom} & input \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}} vector (length 1)
\begin{DoxyEnumerate}
\item $ (N \times C \times H \times W) $ the inputs $ x $; Backward fills their diff with gradients $ \frac{\partial E}{\partial x} = \frac{\partial E}{\partial y} y \alpha \log_e(gamma) $ if propagate\+\_\+down\mbox{[}0\mbox{]} 
\end{DoxyEnumerate}\\
\hline
\end{DoxyParams}


Implements \mbox{\hyperlink{classcaffe_1_1_layer_a75c9b2a321dc713e0eaef530d02dc37f}{caffe\+::\+Layer$<$ Dtype $>$}}.

\mbox{\Hypertarget{classcaffe_1_1_log_layer_aeb9fead649bae76818f950a43382d0dc}\label{classcaffe_1_1_log_layer_aeb9fead649bae76818f950a43382d0dc}} 
\index{caffe\+::\+Log\+Layer@{caffe\+::\+Log\+Layer}!Forward\+\_\+cpu@{Forward\+\_\+cpu}}
\index{Forward\+\_\+cpu@{Forward\+\_\+cpu}!caffe\+::\+Log\+Layer@{caffe\+::\+Log\+Layer}}
\subsubsection{\texorpdfstring{Forward\+\_\+cpu()}{Forward\_cpu()}\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily template$<$typename Dtype$>$ \\
virtual void \mbox{\hyperlink{classcaffe_1_1_log_layer}{caffe\+::\+Log\+Layer}}$<$ Dtype $>$\+::Forward\+\_\+cpu (\begin{DoxyParamCaption}\item[{const vector$<$ \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}}$<$ Dtype $>$ $\ast$$>$ \&}]{bottom,  }\item[{const vector$<$ \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}}$<$ Dtype $>$ $\ast$$>$ \&}]{top }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [protected]}, {\ttfamily [virtual]}}


\begin{DoxyParams}{Parameters}
{\em bottom} & input \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}} vector (length 1)
\begin{DoxyEnumerate}
\item $ (N \times C \times H \times W) $ the inputs $ x $ 
\end{DoxyEnumerate}\\
\hline
{\em top} & output \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}} vector (length 1)
\begin{DoxyEnumerate}
\item $ (N \times C \times H \times W) $ the computed outputs $ y = log_{\gamma}(\alpha x + \beta) $ 
\end{DoxyEnumerate}\\
\hline
\end{DoxyParams}


Implements \mbox{\hyperlink{classcaffe_1_1_layer_a576ac6a60b1e99fe383831f52a6cea77}{caffe\+::\+Layer$<$ Dtype $>$}}.

\mbox{\Hypertarget{classcaffe_1_1_log_layer_a407de9bdb364ed170a73c6eebc74dce9}\label{classcaffe_1_1_log_layer_a407de9bdb364ed170a73c6eebc74dce9}} 
\index{caffe\+::\+Log\+Layer@{caffe\+::\+Log\+Layer}!Forward\+\_\+cpu@{Forward\+\_\+cpu}}
\index{Forward\+\_\+cpu@{Forward\+\_\+cpu}!caffe\+::\+Log\+Layer@{caffe\+::\+Log\+Layer}}
\subsubsection{\texorpdfstring{Forward\+\_\+cpu()}{Forward\_cpu()}\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily template$<$typename Dtype $>$ \\
void \mbox{\hyperlink{classcaffe_1_1_log_layer}{caffe\+::\+Log\+Layer}}$<$ Dtype $>$\+::Forward\+\_\+cpu (\begin{DoxyParamCaption}\item[{const vector$<$ \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}}$<$ Dtype $>$ $\ast$$>$ \&}]{bottom,  }\item[{const vector$<$ \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}}$<$ Dtype $>$ $\ast$$>$ \&}]{top }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [protected]}, {\ttfamily [virtual]}}


\begin{DoxyParams}{Parameters}
{\em bottom} & input \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}} vector (length 1)
\begin{DoxyEnumerate}
\item $ (N \times C \times H \times W) $ the inputs $ x $ 
\end{DoxyEnumerate}\\
\hline
{\em top} & output \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}} vector (length 1)
\begin{DoxyEnumerate}
\item $ (N \times C \times H \times W) $ the computed outputs $ y = log_{\gamma}(\alpha x + \beta) $ 
\end{DoxyEnumerate}\\
\hline
\end{DoxyParams}


Implements \mbox{\hyperlink{classcaffe_1_1_layer_a576ac6a60b1e99fe383831f52a6cea77}{caffe\+::\+Layer$<$ Dtype $>$}}.

\mbox{\Hypertarget{classcaffe_1_1_log_layer_a87e062000908b474ac4cda3b2f3c6f1e}\label{classcaffe_1_1_log_layer_a87e062000908b474ac4cda3b2f3c6f1e}} 
\index{caffe\+::\+Log\+Layer@{caffe\+::\+Log\+Layer}!Layer\+Set\+Up@{Layer\+Set\+Up}}
\index{Layer\+Set\+Up@{Layer\+Set\+Up}!caffe\+::\+Log\+Layer@{caffe\+::\+Log\+Layer}}
\subsubsection{\texorpdfstring{Layer\+Set\+Up()}{LayerSetUp()}\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily template$<$typename Dtype $>$ \\
void \mbox{\hyperlink{classcaffe_1_1_log_layer}{caffe\+::\+Log\+Layer}}$<$ Dtype $>$\+::Layer\+Set\+Up (\begin{DoxyParamCaption}\item[{const vector$<$ \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}}$<$ Dtype $>$ $\ast$$>$ \&}]{bottom,  }\item[{const vector$<$ \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}}$<$ Dtype $>$ $\ast$$>$ \&}]{top }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [virtual]}}



Does layer-\/specific setup\+: your layer should implement this function as well as Reshape. 


\begin{DoxyParams}{Parameters}
{\em bottom} & the preshaped input blobs, whose data fields store the input data for this layer \\
\hline
{\em top} & the allocated but unshaped output blobs\\
\hline
\end{DoxyParams}
This method should do one-\/time layer specific setup. This includes reading and processing relevent parameters from the {\ttfamily layer\+\_\+param\+\_\+}. Setting up the shapes of top blobs and internal buffers should be done in {\ttfamily Reshape}, which will be called before the forward pass to adjust the top blob sizes. 

Reimplemented from \mbox{\hyperlink{classcaffe_1_1_layer_a481323a3e0972c682787f2137468c29f}{caffe\+::\+Layer$<$ Dtype $>$}}.

Here is the call graph for this function\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=350pt]{classcaffe_1_1_log_layer_a87e062000908b474ac4cda3b2f3c6f1e_cgraph}
\end{center}
\end{figure}
\mbox{\Hypertarget{classcaffe_1_1_log_layer_aa73d4cdfc38059902ffa2258d58e1dd4}\label{classcaffe_1_1_log_layer_aa73d4cdfc38059902ffa2258d58e1dd4}} 
\index{caffe\+::\+Log\+Layer@{caffe\+::\+Log\+Layer}!Layer\+Set\+Up@{Layer\+Set\+Up}}
\index{Layer\+Set\+Up@{Layer\+Set\+Up}!caffe\+::\+Log\+Layer@{caffe\+::\+Log\+Layer}}
\subsubsection{\texorpdfstring{Layer\+Set\+Up()}{LayerSetUp()}\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily template$<$typename Dtype$>$ \\
virtual void \mbox{\hyperlink{classcaffe_1_1_log_layer}{caffe\+::\+Log\+Layer}}$<$ Dtype $>$\+::Layer\+Set\+Up (\begin{DoxyParamCaption}\item[{const vector$<$ \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}}$<$ Dtype $>$ $\ast$$>$ \&}]{bottom,  }\item[{const vector$<$ \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}}$<$ Dtype $>$ $\ast$$>$ \&}]{top }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [virtual]}}



Does layer-\/specific setup\+: your layer should implement this function as well as Reshape. 


\begin{DoxyParams}{Parameters}
{\em bottom} & the preshaped input blobs, whose data fields store the input data for this layer \\
\hline
{\em top} & the allocated but unshaped output blobs\\
\hline
\end{DoxyParams}
This method should do one-\/time layer specific setup. This includes reading and processing relevent parameters from the {\ttfamily layer\+\_\+param\+\_\+}. Setting up the shapes of top blobs and internal buffers should be done in {\ttfamily Reshape}, which will be called before the forward pass to adjust the top blob sizes. 

Reimplemented from \mbox{\hyperlink{classcaffe_1_1_layer_a481323a3e0972c682787f2137468c29f}{caffe\+::\+Layer$<$ Dtype $>$}}.



The documentation for this class was generated from the following files\+:\begin{DoxyCompactItemize}
\item 
build/install/include/caffe/layers/log\+\_\+layer.\+hpp\item 
src/caffe/layers/log\+\_\+layer.\+cpp\end{DoxyCompactItemize}
