

 \subsection*{title\+: Interfaces }

\section*{Interfaces}

Caffe has command line, Python, and M\+A\+T\+L\+AB interfaces for day-\/to-\/day usage, interfacing with research code, and rapid prototyping. While Caffe is a C++ library at heart and it exposes a modular interface for development, not every occasion calls for custom compilation. The cmdcaffe, pycaffe, and matcaffe interfaces are here for you.

\subsection*{Command Line}

The command line interface -- cmdcaffe -- is the {\ttfamily caffe} tool for model training, scoring, and diagnostics. Run {\ttfamily caffe} without any arguments for help. This tool and others are found in caffe/build/tools. (The following example calls require completing the Le\+Net / M\+N\+I\+ST example first.)

{\bfseries Training}\+: {\ttfamily caffe train} learns models from scratch, resumes learning from saved snapshots, and fine-\/tunes models to new data and tasks\+:


\begin{DoxyItemize}
\item All training requires a solver configuration through the {\ttfamily -\/solver solver.\+prototxt} argument.
\item Resuming requires the {\ttfamily -\/snapshot model\+\_\+iter\+\_\+1000.\+solverstate} argument to load the solver snapshot.
\item Fine-\/tuning requires the {\ttfamily -\/weights model.\+caffemodel} argument for the model initialization.
\end{DoxyItemize}

For example, you can run\+: \begin{DoxyVerb}# train LeNet
caffe train -solver examples/mnist/lenet_solver.prototxt
# train on GPU 2
caffe train -solver examples/mnist/lenet_solver.prototxt -gpu 2
# resume training from the half-way point snapshot
caffe train -solver examples/mnist/lenet_solver.prototxt -snapshot examples/mnist/lenet_iter_5000.solverstate
\end{DoxyVerb}


For a full example of fine-\/tuning, see examples/finetuning\+\_\+on\+\_\+flickr\+\_\+style, but the training call alone is \begin{DoxyVerb}# fine-tune CaffeNet model weights for style recognition
caffe train -solver examples/finetuning_on_flickr_style/solver.prototxt -weights models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel
\end{DoxyVerb}


{\bfseries Testing}\+: {\ttfamily caffe test} scores models by running them in the test phase and reports the net output as its score. The net architecture must be properly defined to output an accuracy measure or loss as its output. The per-\/batch score is reported and then the grand average is reported last. \begin{DoxyVerb}# score the learned LeNet model on the validation set as defined in the
# model architeture lenet_train_test.prototxt
caffe test -model examples/mnist/lenet_train_test.prototxt -weights examples/mnist/lenet_iter_10000.caffemodel -gpu 0 -iterations 100
\end{DoxyVerb}


{\bfseries Benchmarking}\+: {\ttfamily caffe time} benchmarks model execution layer-\/by-\/layer through timing and synchronization. This is useful to check system performance and measure relative execution times for models. \begin{DoxyVerb}# (These example calls require you complete the LeNet / MNIST example first.)
# time LeNet training on CPU for 10 iterations
caffe time -model examples/mnist/lenet_train_test.prototxt -iterations 10
# time LeNet training on GPU for the default 50 iterations
caffe time -model examples/mnist/lenet_train_test.prototxt -gpu 0
# time a model architecture with the given weights on the first GPU for 10 iterations
caffe time -model examples/mnist/lenet_train_test.prototxt -weights examples/mnist/lenet_iter_10000.caffemodel -gpu 0 -iterations 10
\end{DoxyVerb}


{\bfseries Diagnostics}\+: {\ttfamily caffe device\+\_\+query} reports G\+PU details for reference and checking device ordinals for running on a given device in multi-\/\+G\+PU machines. \begin{DoxyVerb}# query the first device
caffe device_query -gpu 0
\end{DoxyVerb}


{\bfseries Parallelism}\+: the {\ttfamily -\/gpu} flag to the {\ttfamily caffe} tool can take a comma separated list of I\+Ds to run on multiple G\+P\+Us. A solver and net will be instantiated for each G\+PU so the batch size is effectively multiplied by the number of G\+P\+Us. To reproduce single G\+PU training, reduce the batch size in the network definition accordingly. \begin{DoxyVerb}# train on GPUs 0 & 1 (doubling the batch size)
caffe train -solver examples/mnist/lenet_solver.prototxt -gpu 0,1
# train on all GPUs (multiplying batch size by number of devices)
caffe train -solver examples/mnist/lenet_solver.prototxt -gpu all
\end{DoxyVerb}


\subsection*{Python}

The Python interface -- pycaffe -- is the {\ttfamily caffe} module and its scripts in caffe/python. {\ttfamily import caffe} to load models, do forward and backward, handle IO, visualize networks, and even instrument model solving. All model data, derivatives, and parameters are exposed for reading and writing.


\begin{DoxyItemize}
\item {\ttfamily \mbox{\hyperlink{classcaffe_1_1_net}{caffe.\+Net}}} is the central interface for loading, configuring, and running models. {\ttfamily caffe.\+Classifier} and {\ttfamily caffe.\+Detector} provide convenience interfaces for common tasks.
\item {\ttfamily \mbox{\hyperlink{classcaffe_1_1_s_g_d_solver}{caffe.\+S\+G\+D\+Solver}}} exposes the solving interface.
\item {\ttfamily caffe.\+io} handles input / output with preprocessing and protocol buffers.
\item {\ttfamily \mbox{\hyperlink{namespacecaffe_1_1draw}{caffe.\+draw}}} visualizes network architectures.
\item Caffe blobs are exposed as numpy ndarrays for ease-\/of-\/use and efficiency.
\end{DoxyItemize}

Tutorial I\+Python notebooks are found in caffe/examples\+: do {\ttfamily ipython notebook caffe/examples} to try them. For developer reference docstrings can be found throughout the code.

Compile pycaffe by {\ttfamily make pycaffe}. Add the module directory to your {\ttfamily \$\+P\+Y\+T\+H\+O\+N\+P\+A\+TH} by {\ttfamily export P\+Y\+T\+H\+O\+N\+P\+A\+TH=/path/to/caffe/python\+:\$\+P\+Y\+T\+H\+O\+N\+P\+A\+TH} or the like for {\ttfamily import caffe}.

\subsection*{M\+A\+T\+L\+AB}

The M\+A\+T\+L\+AB interface -- matcaffe -- is the {\ttfamily caffe} package in caffe/matlab in which you can integrate Caffe in your Matlab code.

In Mat\+Caffe, you can


\begin{DoxyItemize}
\item Creating multiple Nets in Matlab
\item Do forward and backward computation
\item Access any layer within a network, and any parameter blob in a layer
\item Get and set data or diff to any blob within a network, not restricting to input blobs or output blobs
\item Save a network\textquotesingle{}s parameters to file, and load parameters from file
\item Reshape a blob and reshape a network
\item Edit network parameter and do network surgery
\item Create multiple Solvers in Matlab for training
\item Resume training from solver snapshots
\item Access train net and test nets in a solver
\item Run for a certain number of iterations and give back control to Matlab
\item Intermingle arbitrary Matlab code with gradient steps
\end{DoxyItemize}

An I\+L\+S\+V\+RC image classification demo is in caffe/matlab/demo/classification\+\_\+demo.\+m (you need to download B\+A\+IR Caffe\+Net from \href{http://caffe.berkeleyvision.org/model_zoo.html}{\tt Model Zoo} to run it).

\subsubsection*{Build Mat\+Caffe}

Build Mat\+Caffe with {\ttfamily make all matcaffe}. After that, you may test it using {\ttfamily make mattest}.

Common issue\+: if you run into error messages like `libstdc++.so.\+6\+:version \textquotesingle{}G\+L\+I\+B\+C\+X\+X\+\_\+3.\+4.\+15' not found{\ttfamily during}make mattest\`{}, then it usually means that your Matlab\textquotesingle{}s runtime libraries do not match your compile-\/time libraries. You may need to do the following before you start Matlab\+: \begin{DoxyVerb}export LD_LIBRARY_PATH=/opt/intel/mkl/lib/intel64:/usr/local/cuda/lib64
export LD_PRELOAD=/usr/lib/x86_64-linux-gnu/libstdc++.so.6
\end{DoxyVerb}


Or the equivalent based on where things are installed on your system, and do {\ttfamily make mattest} again to see if the issue is fixed. Note\+: this issue is sometimes more complicated since during its startup Matlab may overwrite your {\ttfamily L\+D\+\_\+\+L\+I\+B\+R\+A\+R\+Y\+\_\+\+P\+A\+TH} environment variable. You can run {\ttfamily !ldd ./matlab/+caffe/private/caffe\+\_\+.mexa64} (the mex extension may differ on your system) in Matlab to see its runtime libraries, and preload your compile-\/time libraries by exporting them to your {\ttfamily L\+D\+\_\+\+P\+R\+E\+L\+O\+AD} environment variable.

After successful building and testing, add this package to Matlab search P\+A\+TH by starting {\ttfamily matlab} from caffe root folder and running the following commands in Matlab command window. \begin{DoxyVerb}addpath ./matlab
\end{DoxyVerb}


You can save your Matlab search P\+A\+TH by running {\ttfamily savepath} so that you don\textquotesingle{}t have to run the command above again every time you use Mat\+Caffe.

\subsubsection*{Use Mat\+Caffe}

Mat\+Caffe is very similar to Py\+Caffe in usage.

Examples below shows detailed usages and assumes you have downloaded B\+A\+IR Caffe\+Net from \href{http://caffe.berkeleyvision.org/model_zoo.html}{\tt Model Zoo} and started {\ttfamily matlab} from caffe root folder. \begin{DoxyVerb}model = './models/bvlc_reference_caffenet/deploy.prototxt';
weights = './models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel';
\end{DoxyVerb}


\paragraph*{Set mode and device}

{\bfseries Mode and device should always be set B\+E\+F\+O\+RE you create a net or a solver.}

Use C\+PU\+: \begin{DoxyVerb}caffe.set_mode_cpu();
\end{DoxyVerb}


Use G\+PU and specify its gpu\+\_\+id\+: \begin{DoxyVerb}caffe.set_mode_gpu();
caffe.set_device(gpu_id);
\end{DoxyVerb}


\paragraph*{Create a network and access its layers and blobs}

Create a network\+: \begin{DoxyVerb}net = caffe.Net(model, weights, 'test'); % create net and load weights
\end{DoxyVerb}


Or \begin{DoxyVerb}net = caffe.Net(model, 'test'); % create net but not load weights
net.copy_from(weights); % load weights
\end{DoxyVerb}


which creates {\ttfamily net} object as \begin{DoxyVerb}  Net with properties:

           layer_vec: [1x23 caffe.Layer]
            blob_vec: [1x15 caffe.Blob]
              inputs: {'data'}
             outputs: {'prob'}
    name2layer_index: [23x1 containers.Map]
     name2blob_index: [15x1 containers.Map]
         layer_names: {23x1 cell}
          blob_names: {15x1 cell}
\end{DoxyVerb}


The two {\ttfamily containers.\+Map} objects are useful to find the index of a layer or a blob by its name.

You have access to every blob in this network. To fill blob \textquotesingle{}data\textquotesingle{} with all ones\+: \begin{DoxyVerb}net.blobs('data').set_data(ones(net.blobs('data').shape));
\end{DoxyVerb}


To multiply all values in blob \textquotesingle{}data\textquotesingle{} by 10\+: \begin{DoxyVerb}net.blobs('data').set_data(net.blobs('data').get_data() * 10);
\end{DoxyVerb}


{\bfseries Be aware that since Matlab is 1-\/indexed and column-\/major, the usual 4 blob dimensions in Matlab are {\ttfamily \mbox{[}width, height, channels, num\mbox{]}}, and {\ttfamily width} is the fastest dimension. Also be aware that images are in B\+GR channels.} Also, Caffe uses single-\/precision float data. If your data is not single, {\ttfamily set\+\_\+data} will automatically convert it to single.

You also have access to every layer, so you can do network surgery. For example, to multiply conv1 parameters by 10\+: \begin{DoxyVerb}net.params('conv1', 1).set_data(net.params('conv1', 1).get_data() * 10); % set weights
net.params('conv1', 2).set_data(net.params('conv1', 2).get_data() * 10); % set bias
\end{DoxyVerb}


Alternatively, you can use \begin{DoxyVerb}net.layers('conv1').params(1).set_data(net.layers('conv1').params(1).get_data() * 10);
net.layers('conv1').params(2).set_data(net.layers('conv1').params(2).get_data() * 10);
\end{DoxyVerb}


To save the network you just modified\+: \begin{DoxyVerb}net.save('my_net.caffemodel');
\end{DoxyVerb}


To get a layer\textquotesingle{}s type (string)\+: \begin{DoxyVerb}layer_type = net.layers('conv1').type;
\end{DoxyVerb}


\paragraph*{Forward and backward}

Forward pass can be done using {\ttfamily net.\+forward} or {\ttfamily net.\+forward\+\_\+prefilled}. Function {\ttfamily net.\+forward} takes in a cell array of N-\/D arrays containing data of input blob(s) and outputs a cell array containing data from output blob(s). Function {\ttfamily net.\+forward\+\_\+prefilled} uses existing data in input blob(s) during forward pass, takes no input and produces no output. After creating some data for input blobs like `data = rand(net.\+blobs(\textquotesingle{}data').shape);\`{} you can run \begin{DoxyVerb}res = net.forward({data});
prob = res{1};
\end{DoxyVerb}


Or \begin{DoxyVerb}net.blobs('data').set_data(data);
net.forward_prefilled();
prob = net.blobs('prob').get_data();
\end{DoxyVerb}


Backward is similar using {\ttfamily net.\+backward} or {\ttfamily net.\+backward\+\_\+prefilled} and replacing {\ttfamily get\+\_\+data} and {\ttfamily set\+\_\+data} with {\ttfamily get\+\_\+diff} and {\ttfamily set\+\_\+diff}. After creating some gradients for output blobs like `prob\+\_\+diff = rand(net.\+blobs(\textquotesingle{}prob').shape);\`{} you can run \begin{DoxyVerb}res = net.backward({prob_diff});
data_diff = res{1};
\end{DoxyVerb}


Or \begin{DoxyVerb}net.blobs('prob').set_diff(prob_diff);
net.backward_prefilled();
data_diff = net.blobs('data').get_diff();
\end{DoxyVerb}


$\ast$$\ast$\+However, the backward computation above doesn\textquotesingle{}t get correct results, because Caffe decides that the network does not need backward computation. To get correct backward results, you need to set `\textquotesingle{}force\+\_\+backward\+: true'\`{} in your network prototxt.$\ast$$\ast$

After performing forward or backward pass, you can also get the data or diff in internal blobs. For example, to extract pool5 features after forward pass\+: \begin{DoxyVerb}pool5_feat = net.blobs('pool5').get_data();
\end{DoxyVerb}


\paragraph*{Reshape}

Assume you want to run 1 image at a time instead of 10\+: \begin{DoxyVerb}net.blobs('data').reshape([227 227 3 1]); % reshape blob 'data'
net.reshape();
\end{DoxyVerb}


Then the whole network is reshaped, and now `net.\+blobs(\textquotesingle{}prob').shape{\ttfamily should be}\mbox{[}1000 1\mbox{]}\`{};

\paragraph*{Training}

Assume you have created training and validation lmdbs following our \href{http://caffe.berkeleyvision.org/gathered/examples/imagenet.html}{\tt Image\+N\+ET Tutorial}, to create a solver and train on I\+L\+S\+V\+RC 2012 classification dataset\+: \begin{DoxyVerb}solver = caffe.Solver('./models/bvlc_reference_caffenet/solver.prototxt');
\end{DoxyVerb}


which creates {\ttfamily solver} object as \begin{DoxyVerb}  Solver with properties:

          net: [1x1 caffe.Net]
    test_nets: [1x1 caffe.Net]
\end{DoxyVerb}


To train\+: \begin{DoxyVerb}solver.solve();
\end{DoxyVerb}


Or train for only 1000 iterations (so that you can do something to its net before training more iterations) \begin{DoxyVerb}solver.step(1000);
\end{DoxyVerb}


To get iteration number\+: \begin{DoxyVerb}iter = solver.iter();
\end{DoxyVerb}


To get its network\+: \begin{DoxyVerb}train_net = solver.net;
test_net = solver.test_nets(1);
\end{DoxyVerb}


To resume from a snapshot \char`\"{}your\+\_\+snapshot.\+solverstate\char`\"{}\+: \begin{DoxyVerb}solver.restore('your_snapshot.solverstate');
\end{DoxyVerb}


\paragraph*{Input and output}

{\ttfamily caffe.\+io} class provides basic input functions {\ttfamily load\+\_\+image} and {\ttfamily read\+\_\+mean}. For example, to read I\+L\+S\+V\+RC 2012 mean file (assume you have downloaded imagenet example auxiliary files by running {\ttfamily ./data/ilsvrc12/get\+\_\+ilsvrc\+\_\+aux.sh})\+: \begin{DoxyVerb}mean_data = caffe.io.read_mean('./data/ilsvrc12/imagenet_mean.binaryproto');
\end{DoxyVerb}


To read Caffe\textquotesingle{}s example image and resize to {\ttfamily \mbox{[}width, height\mbox{]}} and suppose we want {\ttfamily width = 256; height = 256;} \begin{DoxyVerb}im_data = caffe.io.load_image('./examples/images/cat.jpg');
im_data = imresize(im_data, [width, height]); % resize using Matlab's imresize
\end{DoxyVerb}


{\bfseries Keep in mind that {\ttfamily width} is the fastest dimension and channels are B\+GR, which is different from the usual way that Matlab stores an image.} If you don\textquotesingle{}t want to use {\ttfamily caffe.\+io.\+load\+\_\+image} and prefer to load an image by yourself, you can do \begin{DoxyVerb}im_data = imread('./examples/images/cat.jpg'); % read image
im_data = im_data(:, :, [3, 2, 1]); % convert from RGB to BGR
im_data = permute(im_data, [2, 1, 3]); % permute width and height
im_data = single(im_data); % convert to single precision
\end{DoxyVerb}


Also, you may take a look at caffe/matlab/demo/classification\+\_\+demo.\+m to see how to prepare input by taking crops from an image.

We show in caffe/matlab/hdf5creation how to read and write H\+D\+F5 data with Matlab. We do not provide extra functions for data output as Matlab itself is already quite powerful in output.

\paragraph*{Clear nets and solvers}

Call {\ttfamily caffe.\+reset\+\_\+all()} to clear all solvers and stand-\/alone nets you have created. 