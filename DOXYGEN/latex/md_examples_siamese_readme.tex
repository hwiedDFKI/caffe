

 title\+: Siamese Network Tutorial description\+: Train and test a siamese network on M\+N\+I\+ST data. category\+: example include\+\_\+in\+\_\+docs\+: true layout\+: default \subsection*{priority\+: 100 }

\section*{Siamese Network Training with Caffe}

This example shows how you can use weight sharing and a contrastive loss function to learn a model using a siamese network in Caffe.

We will assume that you have caffe successfully compiled. If not, please refer to the \href{../../installation.html}{\tt Installation page}. This example builds on the \href{mnist.html}{\tt M\+N\+I\+ST tutorial} so it would be a good idea to read that before continuing.

{\itshape The guide specifies all paths and assumes all commands are executed from the root caffe directory}

\subsection*{Prepare Datasets}

You will first need to download and convert the data from the M\+N\+I\+ST website. To do this, simply run the following commands\+: \begin{DoxyVerb}./data/mnist/get_mnist.sh
./examples/siamese/create_mnist_siamese.sh
\end{DoxyVerb}


After running the script there should be two datasets, {\ttfamily ./examples/siamese/mnist\+\_\+siamese\+\_\+train\+\_\+leveldb}, and {\ttfamily ./examples/siamese/mnist\+\_\+siamese\+\_\+test\+\_\+leveldb}.

\subsection*{The Model}

First, we will define the model that we want to train using the siamese network. We will use the convolutional net defined in {\ttfamily ./examples/siamese/mnist\+\_\+siamese.prototxt}. This model is almost exactly the same as the \href{mnist.html}{\tt Le\+Net model}, the only difference is that we have replaced the top layers that produced probabilities over the 10 digit classes with a linear \char`\"{}feature\char`\"{} layer that produces a 2 dimensional vector. \begin{DoxyVerb}layer {
  name: "feat"
  type: "InnerProduct"
  bottom: "ip2"
  top: "feat"
  param {
    name: "feat_w"
    lr_mult: 1
  }
  param {
    name: "feat_b"
    lr_mult: 2
  }
  inner_product_param {
    num_output: 2
  }
}
\end{DoxyVerb}


\subsection*{Define the Siamese Network}

In this section we will define the siamese network used for training. The resulting network is defined in {\ttfamily ./examples/siamese/mnist\+\_\+siamese\+\_\+train\+\_\+test.prototxt}.

\subsubsection*{Reading in the Pair Data}

We start with a data layer that reads from the Level\+DB database we created earlier. Each entry in this database contains the image data for a pair of images ({\ttfamily pair\+\_\+data}) and a binary label saying if they belong to the same class or different classes ({\ttfamily sim}). \begin{DoxyVerb}layer {
  name: "pair_data"
  type: "Data"
  top: "pair_data"
  top: "sim"
  include { phase: TRAIN }
  transform_param {
    scale: 0.00390625
  }
  data_param {
    source: "examples/siamese/mnist_siamese_train_leveldb"
    batch_size: 64
  }
}
\end{DoxyVerb}


In order to pack a pair of images into the same blob in the database we pack one image per channel. We want to be able to work with these two images separately, so we add a slice layer after the data layer. This takes the {\ttfamily pair\+\_\+data} and slices it along the channel dimension so that we have a single image in {\ttfamily data} and its paired image in {\ttfamily data\+\_\+p.} \begin{DoxyVerb}layer {
  name: "slice_pair"
  type: "Slice"
  bottom: "pair_data"
  top: "data"
  top: "data_p"
  slice_param {
    slice_dim: 1
    slice_point: 1
  }
}
\end{DoxyVerb}


\subsubsection*{Building the First Side of the Siamese Net}

Now we can specify the first side of the siamese net. This side operates on {\ttfamily data} and produces {\ttfamily feat}. Starting from the net in {\ttfamily ./examples/siamese/mnist\+\_\+siamese.prototxt} we add default weight fillers. Then we name the parameters of the convolutional and inner product layers. Naming the parameters allows Caffe to share the parameters between layers on both sides of the siamese net. In the definition this looks like\+: \begin{DoxyVerb}...
param { name: "conv1_w" ...  }
param { name: "conv1_b" ...  }
...
param { name: "conv2_w" ...  }
param { name: "conv2_b" ...  }
...
param { name: "ip1_w" ...  }
param { name: "ip1_b" ...  }
...
param { name: "ip2_w" ...  }
param { name: "ip2_b" ...  }
...
\end{DoxyVerb}


\subsubsection*{Building the Second Side of the Siamese Net}

Now we need to create the second path that operates on {\ttfamily data\+\_\+p} and produces {\ttfamily feat\+\_\+p}. This path is exactly the same as the first. So we can just copy and paste it. Then we change the name of each layer, input, and output by appending {\ttfamily \+\_\+p} to differentiate the \char`\"{}paired\char`\"{} layers from the originals.

\subsubsection*{Adding the Contrastive Loss Function}

To train the network we will optimize a contrastive loss function proposed in\+: Raia Hadsell, Sumit Chopra, and Yann Le\+Cun \char`\"{}\+Dimensionality Reduction by Learning
an Invariant Mapping\char`\"{}. This loss function encourages matching pairs to be close together in feature space while pushing non-\/matching pairs apart. This cost function is implemented with the {\ttfamily C\+O\+N\+T\+R\+A\+S\+T\+I\+V\+E\+\_\+\+L\+O\+SS} layer\+: \begin{DoxyVerb}layer {
    name: "loss"
    type: "ContrastiveLoss"
    contrastive_loss_param {
        margin: 1.0
    }
    bottom: "feat"
    bottom: "feat_p"
    bottom: "sim"
    top: "loss"
}
\end{DoxyVerb}


\subsection*{Define the Solver}

Nothing special needs to be done to the solver besides pointing it at the correct model file. The solver is defined in {\ttfamily ./examples/siamese/mnist\+\_\+siamese\+\_\+solver.prototxt}.

\subsection*{Training and Testing the Model}

Training the model is simple after you have written the network definition protobuf and solver protobuf files. Simply run {\ttfamily ./examples/siamese/train\+\_\+mnist\+\_\+siamese.sh}\+: \begin{DoxyVerb}./examples/siamese/train_mnist_siamese.sh
\end{DoxyVerb}


\section*{Plotting the results}

First, we can draw the model and siamese networks by running the following commands that draw the D\+A\+Gs defined in the .prototxt files\+: \begin{DoxyVerb}./python/draw_net.py \
    ./examples/siamese/mnist_siamese.prototxt \
    ./examples/siamese/mnist_siamese.png

./python/draw_net.py \
    ./examples/siamese/mnist_siamese_train_test.prototxt \
    ./examples/siamese/mnist_siamese_train_test.png
\end{DoxyVerb}


Second, we can load the learned model and plot the features using the i\+Python notebook\+: \begin{DoxyVerb}ipython notebook ./examples/siamese/mnist_siamese.ipynb\end{DoxyVerb}
 