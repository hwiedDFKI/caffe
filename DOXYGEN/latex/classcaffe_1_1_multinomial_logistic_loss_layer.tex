\hypertarget{classcaffe_1_1_multinomial_logistic_loss_layer}{}\section{caffe\+:\+:Multinomial\+Logistic\+Loss\+Layer$<$ Dtype $>$ Class Template Reference}
\label{classcaffe_1_1_multinomial_logistic_loss_layer}\index{caffe\+::\+Multinomial\+Logistic\+Loss\+Layer$<$ Dtype $>$@{caffe\+::\+Multinomial\+Logistic\+Loss\+Layer$<$ Dtype $>$}}


Computes the multinomial logistic loss for a one-\/of-\/many classification task, directly taking a predicted probability distribution as input.  




{\ttfamily \#include $<$multinomial\+\_\+logistic\+\_\+loss\+\_\+layer.\+hpp$>$}



Inheritance diagram for caffe\+:\+:Multinomial\+Logistic\+Loss\+Layer$<$ Dtype $>$\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=214pt]{classcaffe_1_1_multinomial_logistic_loss_layer__inherit__graph}
\end{center}
\end{figure}
\subsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
\mbox{\Hypertarget{classcaffe_1_1_multinomial_logistic_loss_layer_a1c9567f9901885ec4737cf9315d52081}\label{classcaffe_1_1_multinomial_logistic_loss_layer_a1c9567f9901885ec4737cf9315d52081}} 
{\bfseries Multinomial\+Logistic\+Loss\+Layer} (const \mbox{\hyperlink{classcaffe_1_1_layer_parameter}{Layer\+Parameter}} \&param)
\item 
virtual void \mbox{\hyperlink{classcaffe_1_1_multinomial_logistic_loss_layer_a979be47987712c02dfb57a88b2a69f11}{Reshape}} (const vector$<$ \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}}$<$ Dtype $>$ $\ast$$>$ \&bottom, const vector$<$ \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}}$<$ Dtype $>$ $\ast$$>$ \&top)
\begin{DoxyCompactList}\small\item\em Adjust the shapes of top blobs and internal buffers to accommodate the shapes of the bottom blobs. \end{DoxyCompactList}\item 
\mbox{\Hypertarget{classcaffe_1_1_multinomial_logistic_loss_layer_a024d90a0acee12dbec6c640fe709d5ea}\label{classcaffe_1_1_multinomial_logistic_loss_layer_a024d90a0acee12dbec6c640fe709d5ea}} 
virtual const char $\ast$ \mbox{\hyperlink{classcaffe_1_1_multinomial_logistic_loss_layer_a024d90a0acee12dbec6c640fe709d5ea}{type}} () const
\begin{DoxyCompactList}\small\item\em Returns the layer type. \end{DoxyCompactList}\item 
\mbox{\Hypertarget{classcaffe_1_1_multinomial_logistic_loss_layer_a1c9567f9901885ec4737cf9315d52081}\label{classcaffe_1_1_multinomial_logistic_loss_layer_a1c9567f9901885ec4737cf9315d52081}} 
{\bfseries Multinomial\+Logistic\+Loss\+Layer} (const \mbox{\hyperlink{classcaffe_1_1_layer_parameter}{Layer\+Parameter}} \&param)
\item 
virtual void \mbox{\hyperlink{classcaffe_1_1_multinomial_logistic_loss_layer_afd5162d1fc8be1a4abdf1afaa96519f8}{Reshape}} (const vector$<$ \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}}$<$ Dtype $>$ $\ast$$>$ \&bottom, const vector$<$ \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}}$<$ Dtype $>$ $\ast$$>$ \&top)
\begin{DoxyCompactList}\small\item\em Adjust the shapes of top blobs and internal buffers to accommodate the shapes of the bottom blobs. \end{DoxyCompactList}\item 
\mbox{\Hypertarget{classcaffe_1_1_multinomial_logistic_loss_layer_a024d90a0acee12dbec6c640fe709d5ea}\label{classcaffe_1_1_multinomial_logistic_loss_layer_a024d90a0acee12dbec6c640fe709d5ea}} 
virtual const char $\ast$ \mbox{\hyperlink{classcaffe_1_1_multinomial_logistic_loss_layer_a024d90a0acee12dbec6c640fe709d5ea}{type}} () const
\begin{DoxyCompactList}\small\item\em Returns the layer type. \end{DoxyCompactList}\end{DoxyCompactItemize}
\subsection*{Protected Member Functions}
\begin{DoxyCompactItemize}
\item 
virtual void \mbox{\hyperlink{classcaffe_1_1_multinomial_logistic_loss_layer_a7192a16a5b051f93d784be269d7bfcb3}{Forward\+\_\+cpu}} (const vector$<$ \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}}$<$ Dtype $>$ $\ast$$>$ \&bottom, const vector$<$ \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}}$<$ Dtype $>$ $\ast$$>$ \&top)
\begin{DoxyCompactList}\small\item\em Computes the multinomial logistic loss for a one-\/of-\/many classification task, directly taking a predicted probability distribution as input. \end{DoxyCompactList}\item 
virtual void \mbox{\hyperlink{classcaffe_1_1_multinomial_logistic_loss_layer_a817e9cb16c4af367edf6941f6009a74d}{Backward\+\_\+cpu}} (const vector$<$ \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}}$<$ Dtype $>$ $\ast$$>$ \&top, const vector$<$ bool $>$ \&propagate\+\_\+down, const vector$<$ \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}}$<$ Dtype $>$ $\ast$$>$ \&bottom)
\begin{DoxyCompactList}\small\item\em Computes the multinomial logistic loss error gradient w.\+r.\+t. the predictions. \end{DoxyCompactList}\item 
virtual void \mbox{\hyperlink{classcaffe_1_1_multinomial_logistic_loss_layer_a92a355f79ca6d47741712f85fd79ab97}{Forward\+\_\+cpu}} (const vector$<$ \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}}$<$ Dtype $>$ $\ast$$>$ \&bottom, const vector$<$ \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}}$<$ Dtype $>$ $\ast$$>$ \&top)
\begin{DoxyCompactList}\small\item\em Computes the multinomial logistic loss for a one-\/of-\/many classification task, directly taking a predicted probability distribution as input. \end{DoxyCompactList}\item 
virtual void \mbox{\hyperlink{classcaffe_1_1_multinomial_logistic_loss_layer_a030ad8b4fa8b33e41b5cea44c946b4b0}{Backward\+\_\+cpu}} (const vector$<$ \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}}$<$ Dtype $>$ $\ast$$>$ \&top, const vector$<$ bool $>$ \&propagate\+\_\+down, const vector$<$ \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}}$<$ Dtype $>$ $\ast$$>$ \&bottom)
\begin{DoxyCompactList}\small\item\em Computes the multinomial logistic loss error gradient w.\+r.\+t. the predictions. \end{DoxyCompactList}\end{DoxyCompactItemize}
\subsection*{Additional Inherited Members}


\subsection{Detailed Description}
\subsubsection*{template$<$typename Dtype$>$\newline
class caffe\+::\+Multinomial\+Logistic\+Loss\+Layer$<$ Dtype $>$}

Computes the multinomial logistic loss for a one-\/of-\/many classification task, directly taking a predicted probability distribution as input. 

When predictions are not already a probability distribution, you should instead use the \mbox{\hyperlink{classcaffe_1_1_softmax_with_loss_layer}{Softmax\+With\+Loss\+Layer}}, which maps predictions to a distribution using the \mbox{\hyperlink{classcaffe_1_1_softmax_layer}{Softmax\+Layer}}, before computing the multinomial logistic loss. The \mbox{\hyperlink{classcaffe_1_1_softmax_with_loss_layer}{Softmax\+With\+Loss\+Layer}} should be preferred over separate \mbox{\hyperlink{classcaffe_1_1_softmax_layer}{Softmax\+Layer}} + \mbox{\hyperlink{classcaffe_1_1_multinomial_logistic_loss_layer}{Multinomial\+Logistic\+Loss\+Layer}} as its gradient computation is more numerically stable.


\begin{DoxyParams}{Parameters}
{\em bottom} & input \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}} vector (length 2)
\begin{DoxyEnumerate}
\item $ (N \times C \times H \times W) $ the predictions $ \hat{p} $, a \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}} with values in $ [0, 1] $ indicating the predicted probability of each of the $ K = CHW $ classes. Each prediction vector $ \hat{p}_n $ should sum to 1 as in a probability distribution\+: $ \forall n \sum\limits_{k=1}^K \hat{p}_{nk} = 1 $.
\item $ (N \times 1 \times 1 \times 1) $ the labels $ l $, an integer-\/valued \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}} with values $ l_n \in [0, 1, 2, ..., K - 1] $ indicating the correct class label among the $ K $ classes 
\end{DoxyEnumerate}\\
\hline
{\em top} & output \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}} vector (length 1)
\begin{DoxyEnumerate}
\item $ (1 \times 1 \times 1 \times 1) $ the computed multinomial logistic loss\+: $ E = \frac{-1}{N} \sum\limits_{n=1}^N \log(\hat{p}_{n,l_n}) $ 
\end{DoxyEnumerate}\\
\hline
\end{DoxyParams}


\subsection{Member Function Documentation}
\mbox{\Hypertarget{classcaffe_1_1_multinomial_logistic_loss_layer_a817e9cb16c4af367edf6941f6009a74d}\label{classcaffe_1_1_multinomial_logistic_loss_layer_a817e9cb16c4af367edf6941f6009a74d}} 
\index{caffe\+::\+Multinomial\+Logistic\+Loss\+Layer@{caffe\+::\+Multinomial\+Logistic\+Loss\+Layer}!Backward\+\_\+cpu@{Backward\+\_\+cpu}}
\index{Backward\+\_\+cpu@{Backward\+\_\+cpu}!caffe\+::\+Multinomial\+Logistic\+Loss\+Layer@{caffe\+::\+Multinomial\+Logistic\+Loss\+Layer}}
\subsubsection{\texorpdfstring{Backward\+\_\+cpu()}{Backward\_cpu()}\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily template$<$typename Dtype $>$ \\
void \mbox{\hyperlink{classcaffe_1_1_multinomial_logistic_loss_layer}{caffe\+::\+Multinomial\+Logistic\+Loss\+Layer}}$<$ Dtype $>$\+::Backward\+\_\+cpu (\begin{DoxyParamCaption}\item[{const vector$<$ \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}}$<$ Dtype $>$ $\ast$$>$ \&}]{top,  }\item[{const vector$<$ bool $>$ \&}]{propagate\+\_\+down,  }\item[{const vector$<$ \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}}$<$ Dtype $>$ $\ast$$>$ \&}]{bottom }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [protected]}, {\ttfamily [virtual]}}



Computes the multinomial logistic loss error gradient w.\+r.\+t. the predictions. 

Gradients cannot be computed with respect to the label inputs (bottom\mbox{[}1\mbox{]}), so this method ignores bottom\mbox{[}1\mbox{]} and requires !propagate\+\_\+down\mbox{[}1\mbox{]}, crashing if propagate\+\_\+down\mbox{[}1\mbox{]} is set.


\begin{DoxyParams}{Parameters}
{\em top} & output \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}} vector (length 1), providing the error gradient with respect to the outputs
\begin{DoxyEnumerate}
\item $ (1 \times 1 \times 1 \times 1) $ This \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}}\textquotesingle{}s diff will simply contain the loss\+\_\+weight$\ast$ $ \lambda $, as $ \lambda $ is the coefficient of this layer\textquotesingle{}s output $\ell_i$ in the overall \mbox{\hyperlink{classcaffe_1_1_net}{Net}} loss $ E = \lambda_i \ell_i + \mbox{other loss terms}$; hence $ \frac{\partial E}{\partial \ell_i} = \lambda_i $. ($\ast$\+Assuming that this top \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}} is not used as a bottom (input) by any other layer of the \mbox{\hyperlink{classcaffe_1_1_net}{Net}}.) 
\end{DoxyEnumerate}\\
\hline
{\em propagate\+\_\+down} & see \mbox{\hyperlink{classcaffe_1_1_layer_a183d343f5183a4762307f2c5e6ed1e12}{Layer\+::\+Backward}}. propagate\+\_\+down\mbox{[}1\mbox{]} must be false as we can\textquotesingle{}t compute gradients with respect to the labels. \\
\hline
{\em bottom} & input \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}} vector (length 2)
\begin{DoxyEnumerate}
\item $ (N \times C \times H \times W) $ the predictions $ \hat{p} $; Backward computes diff $ \frac{\partial E}{\partial \hat{p}} $
\item $ (N \times 1 \times 1 \times 1) $ the labels -- ignored as we can\textquotesingle{}t compute their error gradients 
\end{DoxyEnumerate}\\
\hline
\end{DoxyParams}


Implements \mbox{\hyperlink{classcaffe_1_1_layer_a75c9b2a321dc713e0eaef530d02dc37f}{caffe\+::\+Layer$<$ Dtype $>$}}.

\mbox{\Hypertarget{classcaffe_1_1_multinomial_logistic_loss_layer_a030ad8b4fa8b33e41b5cea44c946b4b0}\label{classcaffe_1_1_multinomial_logistic_loss_layer_a030ad8b4fa8b33e41b5cea44c946b4b0}} 
\index{caffe\+::\+Multinomial\+Logistic\+Loss\+Layer@{caffe\+::\+Multinomial\+Logistic\+Loss\+Layer}!Backward\+\_\+cpu@{Backward\+\_\+cpu}}
\index{Backward\+\_\+cpu@{Backward\+\_\+cpu}!caffe\+::\+Multinomial\+Logistic\+Loss\+Layer@{caffe\+::\+Multinomial\+Logistic\+Loss\+Layer}}
\subsubsection{\texorpdfstring{Backward\+\_\+cpu()}{Backward\_cpu()}\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily template$<$typename Dtype$>$ \\
virtual void \mbox{\hyperlink{classcaffe_1_1_multinomial_logistic_loss_layer}{caffe\+::\+Multinomial\+Logistic\+Loss\+Layer}}$<$ Dtype $>$\+::Backward\+\_\+cpu (\begin{DoxyParamCaption}\item[{const vector$<$ \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}}$<$ Dtype $>$ $\ast$$>$ \&}]{top,  }\item[{const vector$<$ bool $>$ \&}]{propagate\+\_\+down,  }\item[{const vector$<$ \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}}$<$ Dtype $>$ $\ast$$>$ \&}]{bottom }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [protected]}, {\ttfamily [virtual]}}



Computes the multinomial logistic loss error gradient w.\+r.\+t. the predictions. 

Gradients cannot be computed with respect to the label inputs (bottom\mbox{[}1\mbox{]}), so this method ignores bottom\mbox{[}1\mbox{]} and requires !propagate\+\_\+down\mbox{[}1\mbox{]}, crashing if propagate\+\_\+down\mbox{[}1\mbox{]} is set.


\begin{DoxyParams}{Parameters}
{\em top} & output \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}} vector (length 1), providing the error gradient with respect to the outputs
\begin{DoxyEnumerate}
\item $ (1 \times 1 \times 1 \times 1) $ This \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}}\textquotesingle{}s diff will simply contain the loss\+\_\+weight$\ast$ $ \lambda $, as $ \lambda $ is the coefficient of this layer\textquotesingle{}s output $\ell_i$ in the overall \mbox{\hyperlink{classcaffe_1_1_net}{Net}} loss $ E = \lambda_i \ell_i + \mbox{other loss terms}$; hence $ \frac{\partial E}{\partial \ell_i} = \lambda_i $. ($\ast$\+Assuming that this top \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}} is not used as a bottom (input) by any other layer of the \mbox{\hyperlink{classcaffe_1_1_net}{Net}}.) 
\end{DoxyEnumerate}\\
\hline
{\em propagate\+\_\+down} & see \mbox{\hyperlink{classcaffe_1_1_layer_a183d343f5183a4762307f2c5e6ed1e12}{Layer\+::\+Backward}}. propagate\+\_\+down\mbox{[}1\mbox{]} must be false as we can\textquotesingle{}t compute gradients with respect to the labels. \\
\hline
{\em bottom} & input \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}} vector (length 2)
\begin{DoxyEnumerate}
\item $ (N \times C \times H \times W) $ the predictions $ \hat{p} $; Backward computes diff $ \frac{\partial E}{\partial \hat{p}} $
\item $ (N \times 1 \times 1 \times 1) $ the labels -- ignored as we can\textquotesingle{}t compute their error gradients 
\end{DoxyEnumerate}\\
\hline
\end{DoxyParams}


Implements \mbox{\hyperlink{classcaffe_1_1_layer_a75c9b2a321dc713e0eaef530d02dc37f}{caffe\+::\+Layer$<$ Dtype $>$}}.

\mbox{\Hypertarget{classcaffe_1_1_multinomial_logistic_loss_layer_a7192a16a5b051f93d784be269d7bfcb3}\label{classcaffe_1_1_multinomial_logistic_loss_layer_a7192a16a5b051f93d784be269d7bfcb3}} 
\index{caffe\+::\+Multinomial\+Logistic\+Loss\+Layer@{caffe\+::\+Multinomial\+Logistic\+Loss\+Layer}!Forward\+\_\+cpu@{Forward\+\_\+cpu}}
\index{Forward\+\_\+cpu@{Forward\+\_\+cpu}!caffe\+::\+Multinomial\+Logistic\+Loss\+Layer@{caffe\+::\+Multinomial\+Logistic\+Loss\+Layer}}
\subsubsection{\texorpdfstring{Forward\+\_\+cpu()}{Forward\_cpu()}\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily template$<$typename Dtype $>$ \\
void \mbox{\hyperlink{classcaffe_1_1_multinomial_logistic_loss_layer}{caffe\+::\+Multinomial\+Logistic\+Loss\+Layer}}$<$ Dtype $>$\+::Forward\+\_\+cpu (\begin{DoxyParamCaption}\item[{const vector$<$ \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}}$<$ Dtype $>$ $\ast$$>$ \&}]{bottom,  }\item[{const vector$<$ \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}}$<$ Dtype $>$ $\ast$$>$ \&}]{top }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [protected]}, {\ttfamily [virtual]}}



Computes the multinomial logistic loss for a one-\/of-\/many classification task, directly taking a predicted probability distribution as input. 

When predictions are not already a probability distribution, you should instead use the \mbox{\hyperlink{classcaffe_1_1_softmax_with_loss_layer}{Softmax\+With\+Loss\+Layer}}, which maps predictions to a distribution using the \mbox{\hyperlink{classcaffe_1_1_softmax_layer}{Softmax\+Layer}}, before computing the multinomial logistic loss. The \mbox{\hyperlink{classcaffe_1_1_softmax_with_loss_layer}{Softmax\+With\+Loss\+Layer}} should be preferred over separate \mbox{\hyperlink{classcaffe_1_1_softmax_layer}{Softmax\+Layer}} + \mbox{\hyperlink{classcaffe_1_1_multinomial_logistic_loss_layer}{Multinomial\+Logistic\+Loss\+Layer}} as its gradient computation is more numerically stable.


\begin{DoxyParams}{Parameters}
{\em bottom} & input \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}} vector (length 2)
\begin{DoxyEnumerate}
\item $ (N \times C \times H \times W) $ the predictions $ \hat{p} $, a \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}} with values in $ [0, 1] $ indicating the predicted probability of each of the $ K = CHW $ classes. Each prediction vector $ \hat{p}_n $ should sum to 1 as in a probability distribution\+: $ \forall n \sum\limits_{k=1}^K \hat{p}_{nk} = 1 $.
\item $ (N \times 1 \times 1 \times 1) $ the labels $ l $, an integer-\/valued \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}} with values $ l_n \in [0, 1, 2, ..., K - 1] $ indicating the correct class label among the $ K $ classes 
\end{DoxyEnumerate}\\
\hline
{\em top} & output \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}} vector (length 1)
\begin{DoxyEnumerate}
\item $ (1 \times 1 \times 1 \times 1) $ the computed multinomial logistic loss\+: $ E = \frac{-1}{N} \sum\limits_{n=1}^N \log(\hat{p}_{n,l_n}) $ 
\end{DoxyEnumerate}\\
\hline
\end{DoxyParams}


Implements \mbox{\hyperlink{classcaffe_1_1_layer_a576ac6a60b1e99fe383831f52a6cea77}{caffe\+::\+Layer$<$ Dtype $>$}}.

\mbox{\Hypertarget{classcaffe_1_1_multinomial_logistic_loss_layer_a92a355f79ca6d47741712f85fd79ab97}\label{classcaffe_1_1_multinomial_logistic_loss_layer_a92a355f79ca6d47741712f85fd79ab97}} 
\index{caffe\+::\+Multinomial\+Logistic\+Loss\+Layer@{caffe\+::\+Multinomial\+Logistic\+Loss\+Layer}!Forward\+\_\+cpu@{Forward\+\_\+cpu}}
\index{Forward\+\_\+cpu@{Forward\+\_\+cpu}!caffe\+::\+Multinomial\+Logistic\+Loss\+Layer@{caffe\+::\+Multinomial\+Logistic\+Loss\+Layer}}
\subsubsection{\texorpdfstring{Forward\+\_\+cpu()}{Forward\_cpu()}\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily template$<$typename Dtype$>$ \\
virtual void \mbox{\hyperlink{classcaffe_1_1_multinomial_logistic_loss_layer}{caffe\+::\+Multinomial\+Logistic\+Loss\+Layer}}$<$ Dtype $>$\+::Forward\+\_\+cpu (\begin{DoxyParamCaption}\item[{const vector$<$ \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}}$<$ Dtype $>$ $\ast$$>$ \&}]{bottom,  }\item[{const vector$<$ \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}}$<$ Dtype $>$ $\ast$$>$ \&}]{top }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [protected]}, {\ttfamily [virtual]}}



Computes the multinomial logistic loss for a one-\/of-\/many classification task, directly taking a predicted probability distribution as input. 

When predictions are not already a probability distribution, you should instead use the \mbox{\hyperlink{classcaffe_1_1_softmax_with_loss_layer}{Softmax\+With\+Loss\+Layer}}, which maps predictions to a distribution using the \mbox{\hyperlink{classcaffe_1_1_softmax_layer}{Softmax\+Layer}}, before computing the multinomial logistic loss. The \mbox{\hyperlink{classcaffe_1_1_softmax_with_loss_layer}{Softmax\+With\+Loss\+Layer}} should be preferred over separate \mbox{\hyperlink{classcaffe_1_1_softmax_layer}{Softmax\+Layer}} + \mbox{\hyperlink{classcaffe_1_1_multinomial_logistic_loss_layer}{Multinomial\+Logistic\+Loss\+Layer}} as its gradient computation is more numerically stable.


\begin{DoxyParams}{Parameters}
{\em bottom} & input \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}} vector (length 2)
\begin{DoxyEnumerate}
\item $ (N \times C \times H \times W) $ the predictions $ \hat{p} $, a \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}} with values in $ [0, 1] $ indicating the predicted probability of each of the $ K = CHW $ classes. Each prediction vector $ \hat{p}_n $ should sum to 1 as in a probability distribution\+: $ \forall n \sum\limits_{k=1}^K \hat{p}_{nk} = 1 $.
\item $ (N \times 1 \times 1 \times 1) $ the labels $ l $, an integer-\/valued \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}} with values $ l_n \in [0, 1, 2, ..., K - 1] $ indicating the correct class label among the $ K $ classes 
\end{DoxyEnumerate}\\
\hline
{\em top} & output \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}} vector (length 1)
\begin{DoxyEnumerate}
\item $ (1 \times 1 \times 1 \times 1) $ the computed multinomial logistic loss\+: $ E = \frac{-1}{N} \sum\limits_{n=1}^N \log(\hat{p}_{n,l_n}) $ 
\end{DoxyEnumerate}\\
\hline
\end{DoxyParams}


Implements \mbox{\hyperlink{classcaffe_1_1_layer_a576ac6a60b1e99fe383831f52a6cea77}{caffe\+::\+Layer$<$ Dtype $>$}}.

\mbox{\Hypertarget{classcaffe_1_1_multinomial_logistic_loss_layer_afd5162d1fc8be1a4abdf1afaa96519f8}\label{classcaffe_1_1_multinomial_logistic_loss_layer_afd5162d1fc8be1a4abdf1afaa96519f8}} 
\index{caffe\+::\+Multinomial\+Logistic\+Loss\+Layer@{caffe\+::\+Multinomial\+Logistic\+Loss\+Layer}!Reshape@{Reshape}}
\index{Reshape@{Reshape}!caffe\+::\+Multinomial\+Logistic\+Loss\+Layer@{caffe\+::\+Multinomial\+Logistic\+Loss\+Layer}}
\subsubsection{\texorpdfstring{Reshape()}{Reshape()}\hspace{0.1cm}{\footnotesize\ttfamily [1/2]}}
{\footnotesize\ttfamily template$<$typename Dtype$>$ \\
virtual void \mbox{\hyperlink{classcaffe_1_1_multinomial_logistic_loss_layer}{caffe\+::\+Multinomial\+Logistic\+Loss\+Layer}}$<$ Dtype $>$\+::Reshape (\begin{DoxyParamCaption}\item[{const vector$<$ \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}}$<$ Dtype $>$ $\ast$$>$ \&}]{bottom,  }\item[{const vector$<$ \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}}$<$ Dtype $>$ $\ast$$>$ \&}]{top }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [virtual]}}



Adjust the shapes of top blobs and internal buffers to accommodate the shapes of the bottom blobs. 


\begin{DoxyParams}{Parameters}
{\em bottom} & the input blobs, with the requested input shapes \\
\hline
{\em top} & the top blobs, which should be reshaped as needed\\
\hline
\end{DoxyParams}
This method should reshape top blobs as needed according to the shapes of the bottom (input) blobs, as well as reshaping any internal buffers and making any other necessary adjustments so that the layer can accommodate the bottom blobs. 

Reimplemented from \mbox{\hyperlink{classcaffe_1_1_loss_layer_abf00412194f5413ea9468ee44b0d986f}{caffe\+::\+Loss\+Layer$<$ Dtype $>$}}.

\mbox{\Hypertarget{classcaffe_1_1_multinomial_logistic_loss_layer_a979be47987712c02dfb57a88b2a69f11}\label{classcaffe_1_1_multinomial_logistic_loss_layer_a979be47987712c02dfb57a88b2a69f11}} 
\index{caffe\+::\+Multinomial\+Logistic\+Loss\+Layer@{caffe\+::\+Multinomial\+Logistic\+Loss\+Layer}!Reshape@{Reshape}}
\index{Reshape@{Reshape}!caffe\+::\+Multinomial\+Logistic\+Loss\+Layer@{caffe\+::\+Multinomial\+Logistic\+Loss\+Layer}}
\subsubsection{\texorpdfstring{Reshape()}{Reshape()}\hspace{0.1cm}{\footnotesize\ttfamily [2/2]}}
{\footnotesize\ttfamily template$<$typename Dtype $>$ \\
void \mbox{\hyperlink{classcaffe_1_1_multinomial_logistic_loss_layer}{caffe\+::\+Multinomial\+Logistic\+Loss\+Layer}}$<$ Dtype $>$\+::Reshape (\begin{DoxyParamCaption}\item[{const vector$<$ \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}}$<$ Dtype $>$ $\ast$$>$ \&}]{bottom,  }\item[{const vector$<$ \mbox{\hyperlink{classcaffe_1_1_blob}{Blob}}$<$ Dtype $>$ $\ast$$>$ \&}]{top }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [virtual]}}



Adjust the shapes of top blobs and internal buffers to accommodate the shapes of the bottom blobs. 


\begin{DoxyParams}{Parameters}
{\em bottom} & the input blobs, with the requested input shapes \\
\hline
{\em top} & the top blobs, which should be reshaped as needed\\
\hline
\end{DoxyParams}
This method should reshape top blobs as needed according to the shapes of the bottom (input) blobs, as well as reshaping any internal buffers and making any other necessary adjustments so that the layer can accommodate the bottom blobs. 

Reimplemented from \mbox{\hyperlink{classcaffe_1_1_loss_layer_abf00412194f5413ea9468ee44b0d986f}{caffe\+::\+Loss\+Layer$<$ Dtype $>$}}.

Here is the call graph for this function\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=350pt]{classcaffe_1_1_multinomial_logistic_loss_layer_a979be47987712c02dfb57a88b2a69f11_cgraph}
\end{center}
\end{figure}


The documentation for this class was generated from the following files\+:\begin{DoxyCompactItemize}
\item 
build/install/include/caffe/layers/multinomial\+\_\+logistic\+\_\+loss\+\_\+layer.\+hpp\item 
src/caffe/layers/multinomial\+\_\+logistic\+\_\+loss\+\_\+layer.\+cpp\end{DoxyCompactItemize}
